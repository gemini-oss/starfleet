{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to \u2728Starfleet\u2728","text":"<p>Welcome to the Starfleet project! Starfleet is a totally awesome whole-AWS infrastructure automation tool built off of AWS Lambda and Python.</p> <p></p> <p>Starfleet is a tool that runs automation against an entire AWS infrastructure. The primary goal is to address gaps that exist with AWS Organizations.</p> <p>This works by running Lambda functions to operate in the context of an AWS account. Starfleet consists of worker \"ships\" that receive a templated payload to implement a desired infrastructure state. The \"ship\" will perform the actions necessary to ensure that the infrastructure state conforms to the template. Think of this like an IaC but for an entire AWS infrastructure. This allows you to place properly configured infrastructure resources where you need them.</p> <p>Starfleet's primary audience are cloud infrastructure and security engineers that have a need to support medium to large and growing AWS infrastructures.</p>"},{"location":"#why-use-starfleet","title":"Why use Starfleet?","text":"<p>We designed Starfleet to address the infrastructure needs of multi-account AWS users. In multi-account environments there is a need to configure cloud infrastructure that spans the entirety of the cloud footprint. In some cases, some accounts need to have differently configured resources than other accounts. Sometimes this is needed at a regional level too.</p> <p>Cloud infrastructure and security engineers need a place where they can easily design and implement features in a manner that is:</p> <ol> <li>Easy to understand; human readable</li> <li>Located in one convenient place</li> <li>Flexible to the address the realities of medium to large and diverse AWS infrastructures</li> <li>Infrastructure defined as code (IaC)</li> <li>Detects AND prevents drift for incorrectly configured components</li> <li>First-class understanding of multi-account and multi-regional workloads (or some combination thereof)</li> <li>Dynamically and automatically operate across your AWS infrastructure as new accounts get provisioned and deleted</li> </ol> <p>A lot of existing tools come close for implementing some of these features, but don't quite meet the mark unless a lot of tooling is developed to address the shortcomings.</p>"},{"location":"#clear-and-simple-templates","title":"Clear and Simple Templates","text":"<p>Starfleet relies on simple, easy to read YAML templates that provide worker Lambda functions with the context required to operate across an AWS infrastructure. The design of these templates follows the following philosophy:</p> <ol> <li>Control structures like loops and if statements belong in code, not templates</li> <li>There is a time and place for Jinja; just not all of the times in all of the places</li> </ol> <p>The worker ships do all the heavy lifting so that templates are easy to read and parse. Easily readable templates provide context faster and reduce the likelihood of errors. This is especially important when operating at scale. We believe complexity should happen in the code; not N times in templates (the concept of Don't Repeat Yourself, only for real).</p> <p>At the end of the day, Starfleet is what you make of it. It provides the platform for running AWS account-aware Lambda functions that can operate anywhere in your infrastructure.</p>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<p>For more information please review the Architecture page for how this all works, but below is a sample diagram of the architecture: </p>"},{"location":"#video-overview","title":"Video Overview","text":"<p>Starfleet was presented at fwd:cloudsec 2023. The video is here:</p>"},{"location":"Attributions/","title":"Attributions","text":"<ol> <li>Space ship icons/logos<ul> <li>The spaceship icons are from the VERY COOL The Ur-Quan Masters project: https://sc2.sourceforge.net/</li> <li>The Starfleet open source project has no relation to The Ur-Quan Masters project</li> <li>The icons were scaled up for size</li> <li>The content -- \u2026 graphics, \u2026 -- are copyright (C) 1992, 1993, 2002 Toys for Bob, Inc. or their respective creators.   The content may be used freely under the terms of the Creative Commons Attribution-NonCommercial-ShareAlike 2.5 license (available at https://creativecommons.org/licenses/by-nc-sa/2.5/).</li> <li>The icons are distributed with no warranties of any kind</li> </ul> </li> </ol>"},{"location":"Links/","title":"Links and other resources","text":""},{"location":"Links/#attributions","title":"Attributions","text":"<p>See the attributions page for additional attributions for this OSS project.</p>"},{"location":"Links/#github","title":"GitHub","text":"<ol> <li>Main repository link: https://github.com/gemini-oss/starfleet</li> <li>Other cool Gemini OSS projects: https://github.com/gemini-oss</li> </ol>"},{"location":"architecture/AccountIndex/","title":"Account Index","text":"<p>Starfleet has the concept of an account index. This is an inventory of all AWS accounts that Starfleet can operate over. For simplicity and clarity of documentation, we are going to make the assumption that you are a user of AWS Organizations and have exactly one AWS Organization with many accounts under it.</p> <p>The account index keeps a list of accounts that at a minimum need to keep track of:</p> <ol> <li>AWS account IDs</li> <li>Enabled regions for accounts</li> <li>AWS account names</li> <li>AWS account tags</li> <li>Organization Units (if applicable)</li> <li>Organization Roots (if applicable)</li> </ol> <p>The payload templates will specify the account identifiers listed above for <code>ACCOUNT</code> or <code>ACCOUNT-REGION</code> payload templates (via the <code>IncludeAccounts</code> or <code>ExcludeAccounts</code> directives as documented here). The account indexer allows Starfleet to figure out which accounts (or accounts/regions) need to be tasked with a given payload.</p> <p>The Account Indexer is also a \"ship\" in Starfleet (i.e. it's a plugin). The name of the plugin must be present within the <code>STARFLEET</code> configuration under the field <code>AccountIndex</code>. Example: <pre><code>AccountIndex: StarfleetDefaultAccountIndex\n</code></pre></p> <p>Note</p> <p>Starfleet can support any number of accounts and organizations. As long as your account indexer can index it, it can support it!</p>"},{"location":"architecture/AccountIndex/#default-account-indexer","title":"Default Account Indexer","text":"<p>Starfleet includes with an account index generator worker ship (<code>AccountIndexGeneratorShip</code>) that lists all the accounts in AWS Organizations, fetches their enabled regions, tags, and parent OUs, and then saves this as a JSON file to an S3 bucket.</p> <p>In addition to the worker ship for generating the index, Starfleet also ships with an account index plugin (<code>StarfleetDefaultAccountIndex</code>) that leverages the saved JSON from the <code>AccountIndexGeneratorShip</code> to provide Starfleet with the account index capabilities.</p> <p>This is described in much more detail in the User Guide.</p>"},{"location":"architecture/Alerts/","title":"Alerts &amp; Notifications","text":"<p>Starfleet supports emitting alerts and notifications to external systems. As of today, we include a Slack plugin that allows you to emit notifications to Slack. More details on this is in the User and Developer Guides.</p>"},{"location":"architecture/CLI/","title":"Command Line Interface (CLI)","text":"<p>This will be covered more in the User and Developer Guides, but is mentioned here that Starfleet worker ships expose a CLI so that they can be invoked locally. This is useful for debugging issues or if you just need to run a given payload in one AWS account.</p> <p>The CLIs are based on the excellent Python Click framework.</p>"},{"location":"architecture/Configuration/","title":"Configuration","text":"<p>Starfleet needs a configuration to inform it how to run and where to find foundational components.  The User Guide will have additional details and a TL;DR summary of what you should set to get things going. This section goes into depth about the fields and what they do.</p>"},{"location":"architecture/Configuration/#location","title":"Location","text":"<p>The configuration files reside within the Starfleet code tree. Below is a sample of where it's located:</p> <pre><code>starfleet\n\u251c\u2500\u2500 src\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 starfleet\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 configuration_files  # &lt;-- This is where the configuration YAML files go.\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 config_file_one.yaml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 config_file_two.yaml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ...\n\u251c\u2500\u2500 ...\n</code></pre> <p>All the configuration files are YAML files that reside in the <code>src/starfleet/configuration_files</code> directory path. The YAML files in this path are packaged into the Lambda function that is deployed to AWS.</p>"},{"location":"architecture/Configuration/#format-and-schema","title":"Format and Schema","text":"<p>The configuration files are loaded on start up. All of the files are walked through in the directory path and are compiled into one big configuration map (a Python Dictionary). You can have 1 file or many. Choice is yours.</p> <p>The configuration is set up in sections. Each section describes a component of Starfleet that needs to reference a configuration. The configurations must conform to a schema (Python Marshmallow) which is validated on startup. It is highly recommended that for consistency, that fields are in UpperCamelCase.</p>"},{"location":"architecture/Configuration/#configuration-sections","title":"Configuration Sections","text":"<p>There are a number of important sections to the configuration file for key parts of Starfleet.</p> <p>Here is an example configuration file, and the sections will be explained below:</p> <pre><code>STARFLEET:\n    DeploymentRegion: us-east-2\n    TemplateBucket: starfleet-templates-YOUR-ACCOUNT-ID\n    FanOutQueueUrl: https://sqs.DEPLOYEMENT-REGION.amazonaws.com/ACCOUNT-ID/starbase-fanout-queue\n    LogLevel: DEBUG\n    SecretsManager:\n        SecretId: Starfleet\n        SecretRegion: us-east-2\n    SlackEnabled: True\n    ThirdPartyLoggerLevels:\n        botocore: CRITICAL\n        'urllib3.connectionpool': CRITICAL\n\nAccountIndexGeneratorShip:\n    Enabled: True\n    TemplatePrefix: AccountIndexGenerator/Payload.yaml\n    InvocationQueueUrl: https://sqs.DEPLOYEMENT-REGION.amazonaws.com/ACCOUNT-ID/starfleet-account-index-generator\n    InvocationSources:\n        - S3\n        - EVENTBRIDGE_TIMED_EVENT\n    EventBridgeTimedFrequency: HOURLY\n    OrgAccountAssumeRole: starfleet-worker-role\n    OrgAccountId: \"YOUR-ORGANIZATION-ROOT-ACCOUNT-ID-HERE\"\n    OrgRootId: YOUR-ORG-ROOT-ID\n    DescribeRegionsAssumeRole: starfleet-worker-role\n\nStarfleetDefaultAccountIndex:\n    IndexBucket: your-template-s3-bucket-replace-me\n    BucketRegion: your-template-s3-bucket-region\n    IndexObjectPath: accountIndex.json\n</code></pre>"},{"location":"architecture/Configuration/#starfleet-base-configuration-required","title":"Starfleet Base Configuration - Required","text":"<p>The base configuration configures the primary Starfleet components. This is in the <code>STARFLEET</code> section, which is required. This section has some very important fields:</p>"},{"location":"architecture/Configuration/#required-fields","title":"Required Fields","text":"<ul> <li><code>DeploymentRegion</code> - This is the AWS region that Starfleet is deployed in. This is used by some foundational components, like the Starbase (described in later sections).</li> <li><code>TemplateBucket</code> - This is the S3 bucket that holds all the payload templates that are provided to the worker ships on invocation. The region for this bucket is the same as the <code>DeploymentRegion</code>. If you deploy with the included AWS SAM template, then all you need to do is add in the AWS account ID that Starfleet is deployed in and you are good to go!</li> <li><code>FanOutQueueUrl</code> - This is the SQS queue url for the fan out queue. This is used by the Starbase component described in later sections. This is an SQS queue that will be used drive the given worker ship's fan out strategy so that the worker can be tasked accordingly. If you are deploying with the Starfleet AWS SAM template, then all you need to do is add in the account ID and region to this string and you are good to go!</li> <li><code>AccountIndex</code> - This is the name of the Account Index plugin that Starfleet will use for getting an inventory of AWS accounts. This is outlined in more detail later, but is required. By default, this will use the <code>StarfleetDefaultAccountIndex</code> plugin which relies on the <code>AccountIndexGeneratorShip</code> worker ship to generate an AWS account inventory for an AWS Organization. That is also described later, but for now just know that Starfleet needs to know which plugin to consult with to obtain an index or inventory of AWS accounts and their enabled regions.</li> </ul>"},{"location":"architecture/Configuration/#optional-fields","title":"Optional Fields","text":"<ul> <li><code>ScopeToRegions</code> - This is a set of AWS regions that should be scoped for <code>ACCOUNT_REGION</code> worker templates. This is useful if you have an SCP that restricts the regions that are allowed to be operated in. This ensures that <code>ACCOUNT_REGION</code> workers can only operate in those regions specified in this list. By default this is not set.</li> <li><code>LogLevel</code> - This is the Python log level to make use of. The valid fields are the Python log level names. The default value is <code>INFO</code>.</li> <li><code>ThirdPartyLoggerLevels</code> - This is a dictionary of Python logger name, and the corresponding log level for it. By default we silence the loggers for <code>botocore</code> and <code>urllib3.connectionpool</code>, because they can be noisy when making <code>boto3</code> API calls. Feel free to add or modify this section as you see fit.</li> <li><code>SecretsManager</code> - This is a dictionary that outlines the ID of an AWS Secrets Manager secret. This allows Starfleet workers to reference secrets. If specified, this contains 2 required fields: <code>SecretId</code> and <code>SecretRegion</code>. The ID is the name of the secret and the region is the region for it. The secret should reside in the same AWS account as Starfleet. Note: if you make use of Slack alerts, then you will need to have this configured.</li> <li><code>SlackEnabled</code> - This is a boolean that specifies if Slack alerting is enabled. There is an entire section on Slack alerts, but for now, just note that if you want to enable alerts to Slack, then you need to set this field to <code>True</code> and you also need to configure SecretsManager as indicated in the item above. AWS Secrets Manager will securely hold the Slack application token.</li> </ul>"},{"location":"architecture/Configuration/#worker-ship-configurations","title":"Worker Ship Configurations","text":"<p>Each worker ship must have a configuration entry. The configuration entry has a number of required fields that every worker ship needs. But, each worker ship can extend their own schemas as they see fit. You should consult with the documentation for each worker ship to know what it should look like.</p>"},{"location":"architecture/Configuration/#minimum-required-fields","title":"Minimum Required Fields","text":"<ul> <li><code>Enabled</code> - Each worker ship needs to have this field, which is set to the boolean of <code>True</code> or <code>False</code>. This specifies if the worker ship plugin is enabled or not.</li> <li><code>TemplatePrefix</code> - As described in the Worker Ship section, this specifies where in the S3 bucket the worker ship's payload templates are located.</li> <li><code>InvocationQueueUrl</code> - As described in the Worker Ship section, this is the SQS queue URL for where the Lambda's invocation will happen. The AWS SAM template has an example of what this should be. If you rely on the SAM template, than simply swap out the account ID and region, and you are good to go!</li> <li><code>InvocationSources</code> - As described in the Worker Ship section, this defines when the given worker gets invoked. This is used to inform the Starbase component when to task the worker.</li> </ul>"},{"location":"architecture/Configuration/#optional-worker-fields","title":"Optional Worker Fields","text":"<ul> <li><code>AlertConfiguration</code> - This is an encompassing dictionary that specifies a Slack channel ID and a message priority for sending alerts to Slack from that worker. This is documented more in the Developer and User guides around Notifications.<ul> <li><code>ChannelId</code> - This is the Slack Channel ID that messages should be sent to</li> <li><code>AlertPriority</code> - This is the <code>AlertPriority</code> enum string (documented in the Developer and User guides). Acceptable values are: <code>NONE</code>, <code>PROBLEM</code>, <code>IMPORTANT</code>, <code>SUCCESS</code>, and <code>INFORMATIONAL</code>.</li> </ul> </li> </ul> <p>Note</p> <p>Each worker has it's own schema and can define other required and optional components. The fields above are applicable for all worker ships.</p>"},{"location":"architecture/Overview/","title":"Starfleet Architecture Overview","text":"<p>This page discusses the components in the Starfleet architecture and what they do.</p>"},{"location":"architecture/Overview/#note-many-components-are-still-in-progress-of-being-implemented","title":"Note: Many components are still in progress of being implemented","text":""},{"location":"architecture/Overview/#diagram","title":"Diagram","text":""},{"location":"architecture/Overview/#general-gist","title":"General Gist","text":"<p>The general gist is as follows:</p> <ul> <li>There is 1 AWS account that houses all the Starfleet components</li> <li>Lambda functions (called worker \"ships\") execute tasks in your environment with a payload that provides context on what to do</li> <li>An IAM role exists in all your AWS accounts that the worker \"ship\" Lambda functions can assume so it can operate in the AWS account in question</li> <li>The Lambda functions are tasked by a component called the <code>Starbase</code> - this generates the payload and tasks the worker ship to execute</li> <li>An AWS account index/inventory exists to inform the <code>Starbase</code> on which accounts need to be tasked</li> <li>Serverless and idempotent; highly parallelized</li> </ul>"},{"location":"architecture/Overview/#components","title":"Components","text":"<ol> <li>Worker Ship Lambdas - These are Lambda functions that go out and actually perform the desired workload. Worker ship Lambdas are tasked from an SQS queue with the payload describing the workload to be performed in the account (or account/region) in question. The Starbase generates the payload for the given worker ship and places it in the worker's SQS queue. Each worker ship also has a unique configuration that can be set.</li> <li>Payload Template YAML files - These are the YAML templates that will be provided to the worker ships to describe what an infrastructure state should look like. The worker is supposed to use the template to know what actions to be performed in the target destination.</li> <li>Starbase - This is a Lambda function that tasks workers for jobs to run.</li> <li>Payload Template S3 Bucket - This is an S3 bucket that holds the payload template YAMLs. This bucket is configured to have notifications (to be implemented) that invoke the Starbase. The Starbase is then able to task the desired worker ship with the template payload to execute. The event system allows for CI/CD.</li> <li>AWS Account Index - This is an index or inventory of all AWS accounts that Starfleet should operate on. By default, Starfleet ships with a worker ship that automatically generates a JSON file based on AWS Organizations. This JSON file is used by the Starbase to know which accounts exist and when to task the worker ships.</li> <li>EventBridge Time Based events - The Starbase can be invoked with EventBridge timed events. This allows for CRON-like invocation of workers. Worker ships can be configured to get invoked on a time schedule.</li> <li>Resident IAM role - This is an IAM role that exists in all AWS accounts that Starfleet operates in. This role (or roles) allows the Starfleet worker ships to assume into a destination account and then operate within it. Starfleet uses a hub-spoke type of model (octopus) to perform tasks in your infrastructure. Note: Starfleet is a security sensitive application and as such should reside in a limited-access AWS account!</li> <li>Dedicated worker SQS queues - Not yet implemented - these are SQS queues (or topics?) that will be used to directly invoke a worker ship through the Starbase.</li> </ol>"},{"location":"architecture/Overview/#next-sections","title":"Next Sections","text":"<p>The next sections go into detail about what each component does and why.</p>"},{"location":"architecture/PayloadTemplates/","title":"Payload YAML Templates","text":"<p>Each worker ship is provided with a payload that provides it with context on the specific job it needs to perform. This payload is a YAML file that lives in S3. The YAML needs to conform to a Python Marshmallow schema that the worker defines, and each worker's documentation should outline what those are and why.</p> <p>All templates must end in <code>.yaml</code> and reside in the template S3 bucket. Different types of workers will have different template types, as described below. It is also highly recommended that for consistency, all field names exist in UpperCamelCase.</p>"},{"location":"architecture/PayloadTemplates/#general-template-philosophy","title":"General Template Philosophy","text":"<p>We have a general philosophy around how templates should be designed and implemented. That is:</p> <ol> <li>Control structures like loops and if statements belong in code, not templates</li> <li>There is a time and place for Jinja; just not all the times in all the places</li> </ol> <p>Starfleet workers should do the heavy lifting so that templates are easy to read and parse. Human readable templates provide context faster, and reduce the likelihood of errors. This is especially important when operating at scale. This is why we chose YAML and chose sophisticated schema backends so that the complexity happens once; in the code; and not N times in templates (the concept of Don't Repeat Yourself, only for real.)</p> <p>Special Note</p> <p>The details below are provided for you for free when making Starfleet workers. You do not need to worry about writing this code. Starfleet's code does all this work for you so you can focus on where the job needs to run and what it needs to do.</p>"},{"location":"architecture/PayloadTemplates/#some-samples","title":"Some Samples","text":"<p>Some sample templates are here:</p> <p>Sample for the <code>AccountIndexGeneratorShip</code> - a worker ship that generates an AWS account index: <pre><code>TemplateName: AccountIndexGeneratorShip\nTemplateDescription: The Account Index Generator Worker template\nAccountInventoryBucket: some-s3-bucket-to-hold-the-account-index\nInventoryBucketRegion: us-east-2\n</code></pre> This YAML informs the <code>AccountIndexGeneratorShip</code> which S3 bucket to save the inventory to and also the region to save it in. The worker also has an optional field for the name of the saved report, which by default, this value is set to <code>accounts.json</code>. If you want more than 1 inventory report saved to different S3 buckets or locations, you can simply create more payload templates to specify that!</p> <p>More examples will be provided when those worker ships are developed.</p>"},{"location":"architecture/PayloadTemplates/#base-template","title":"Base Template","text":"<p>Each template has some fields that must be present in all payloads. There are just 2:</p> <ol> <li><code>TemplateName</code> - This is a friendly name for the template.</li> <li><code>TemplateDescription</code> - This is just a friendly description for what the template does.</li> </ol>"},{"location":"architecture/PayloadTemplates/#account-worker-templates","title":"Account Worker Templates","text":"<p>If a worker has an <code>ACCOUNT</code> fan out strategy, then it will require the same things mentioned above in the base template, but requires you to specify the AWS accounts the template applies for. You can specify AWS accounts to include in the template (<code>IncludeAccounts</code>) or accounts to exclude from the template (<code>ExcludeAccounts</code>). The account resolution logic will always ensure that the account exclusion takes precedence. Both <code>IncludeAccounts</code> and <code>ExcludeAccounts</code> are dictionaries. There is also another field called <code>OperateInOrgRoot</code>, which is a flag that allows Starfleet to operate in the Organization Root account (it won't by default).</p>"},{"location":"architecture/PayloadTemplates/#account-inclusion","title":"Account Inclusion","text":"<p>To include accounts for the template to operate in, there is a field called <code>IncludeAccounts</code>. This field has its own schema. It has nested components to define a combination on AWS accounts to target for a template.</p> <p>You can target accounts by:</p> <ol> <li>All AWS Accounts</li> <li>By Account ID</li> <li>By Account Name or Alias</li> <li>By Tags</li> <li>By Organization Unit</li> <li>The Org Root*</li> </ol> <p>*Special note about the Organization Root account</p> <p>The Organization Root is a very special account. By default, Starfleet will not run in the organization root account unless you explicitly tell it to by setting <code>OperateInOrgRoot</code> set to <code>True</code> AND if the Org Root account is included the other <code>IncludeAccounts</code> fields.</p> <p>These are described in further detail below.</p>"},{"location":"architecture/PayloadTemplates/#all-aws-accounts","title":"All AWS Accounts","text":"<p>To have a template run across ALL AWS accounts, you would specify an <code>IncludeAccounts</code> that sets the <code>AllAccounts</code> flag to <code>True</code>. This looks like this: <pre><code>IncludeAccounts:\n    AllAccounts: True\n</code></pre> By default this field is <code>False</code>.</p> <p>Danger</p> <p>If you set this field to <code>True</code>, then you cannot set the other fields for <code>IncludeAccounts</code>. Starfleet will throw an error if this is set.</p>"},{"location":"architecture/PayloadTemplates/#by-account-ids","title":"By Account IDs","text":"<p>To have a template run across specific AWS accounts by account ID (12 digit string), you would specify an <code>IncludeAccounts</code> that sets <code>ByIds</code> to a list of AWS account numbers. This looks like this: <pre><code>IncludeAccounts:\n    ByIds:\n        - \"111111111111\"\n        - \"222222222222\"\n        - \"333333333333\"\n</code></pre></p> <p>By default this is an empty list. This field can be used in combination with all other fields except <code>AllAccounts</code> set to <code>True</code>. In the example above, this would only run in accounts with IDs <code>111111111111</code>, <code>222222222222</code>, and <code>333333333333</code>.</p> <p>Danger</p> <p>AWS account IDs are STRINGS, not Numbers! As a result, please wrap account IDs in quotes <code>\"\"</code> to prevent the leading <code>0</code> in an account ID getting stripped off!</p>"},{"location":"architecture/PayloadTemplates/#by-account-names","title":"By Account Names","text":"<p>To have a template run across specific AWS accounts by an account name, you would specify an <code>IncludeAccounts</code> that sets <code>ByNames</code> to a list of AWS names. An account name in this context is what you would have an account named in AWS Organizations. This looks like this: <pre><code>IncludeAccounts:\n    ByNames:\n        - Dev Account\n        - Staging Account\n        - Production Account\n</code></pre></p> <p>By default this is an empty list. This field can be used in combination with all other fields except <code>AllAccounts</code> set to <code>True</code>. Account names are case-insensitive - internally Starfleet handles everything as lowercase strings. In this example, this template would only apply to accounts that are named <code>Dev Account</code>, <code>Staging Account</code>, and <code>Production Account</code>. (Account names are unique in your environment)</p> <p>Warning</p> <p>Be mindful of whitespaces. You can always wrap in <code>\"\"</code> quotes.</p> <p>TODO: We may implement a feature to operate on an Account Alias -- which would basically be a tag on the account with a list of names to use. We have not settled on this yet though.</p>"},{"location":"architecture/PayloadTemplates/#by-account-tags","title":"By Account Tags","text":"<p>To have a template run across specific AWS accounts by how an account is tagged, you would specify an <code>IncludeAccounts</code> that sets <code>ByTags</code> to a list of tag name/value pairs. An account tag in this context is what you would have an account tagged as in AWS Organizations. This looks like this: <pre><code>IncludeAccounts:\n    ByTags:\n        - Name: Environment\n          Value: Dev\n        - Name: Environment\n          Value: Test\n        - Name: Business Unit\n          Value: Marketing\n</code></pre></p> <p>By default this is an empty list. This field can be used in combination with all other fields except <code>AllAccounts</code> set to <code>True</code>. Tag names and values are case-sensitive. The account logic resolution for this is inclusive, or logical <code>OR</code>. The example above would run against AWS accounts that are tagged with tag name <code>Environment</code> with tag values <code>Dev</code> or <code>Test</code>, and it would also include accounts tagged with tag name <code>Business Unit</code> set to the value of <code>Marketing</code>.</p> <p>Warning</p> <p>Be mindful of whitespaces. You can always wrap in <code>\"\"</code> quotes.</p> <p>Warning</p> <p>This uses inclusive OR logic. It will include any accounts that have the tag name/value pairs set.</p>"},{"location":"architecture/PayloadTemplates/#by-organization-unit","title":"By Organization Unit","text":"<p>To have a template run across specific AWS accounts based on Organization Unit (OU) residency, you would specify an <code>IncludeAccounts</code> that sets <code>ByOrgUnits</code> to a list either OU name or OU ID. This looks like this: <pre><code>IncludeAccounts:\n    ByOrgUnits:\n        - Some Org Unit\n        - Some Other Org Unit\n        - ou-1234-5678910\n</code></pre></p> <p>By default this is an empty list. This field can be used in combination with all other fields except <code>AllAccounts</code> set to <code>True</code>. OU values are case-insensitive. The account logic resolution for this is inclusive, or logical <code>OR</code>. The example above would run against AWS accounts that exist in any of the specified OUs. In this example, it would include accounts that reside in <code>Some Org Unit</code>. or <code>Some Other Org Unit</code>, or <code>ou-1234-5678910</code>.</p> <p>Warning</p> <p>Be mindful of whitespaces. You can always wrap in <code>\"\"</code> quotes.</p>"},{"location":"architecture/PayloadTemplates/#account-exclusion","title":"Account Exclusion","text":"<p>If you need to explicitly avoid an account from being acted upon, then you need to specify the <code>ExcludeAccounts</code> dictionary. By default this is not set. The <code>ExcludeAccounts</code> dictionary is exactly the same as the <code>IncludeAccounts</code> dictionary, except that it lacks the <code>AllAccounts</code> flag. <code>AllAccounts</code> only applies to <code>IncludeAccounts</code>.</p> <p>By default, the Organization Root is not worked on unless it is included in <code>IncludeAccounts</code> and also if the <code>OperateInOrgRoot</code> flag is set to <code>True</code>.</p>"},{"location":"architecture/PayloadTemplates/#some-examples","title":"Some Examples","text":"<p>In addition to the examples above, here are some examples where everything comes together:</p> <p>Here is an example of specifying that a template should apply to all accounts except the organization root and accounts that are tagged as <code>Environment: Production</code>: <pre><code>IncludeAccounts:\n    AllAccounts: True\nExcludeAccounts:\n    ByTags:\n        - Name: Environment\n          Value: Production\n</code></pre></p> <p>Here is an example of applying to all accounts, including the org root: <pre><code>IncludeAccounts:\n    AllAccounts: True\nOperateInOrgRoot: True\n</code></pre></p> <p>Here is an example of applying to the <code>Infsec Staging</code> account, all accounts in the <code>DevOps</code>, <code>Financial</code>, and <code>Marketing</code> OUs and excluding accounts named <code>DevOps Prod</code>, and <code>Financial Prod</code>. <pre><code>IncludeAccounts:\n    ByNames:\n        - InfoSec Staging\n    ByOrgUnits:\n        - DevOps\n        - Financial\n        - Marketing\nExcludeAccounts:\n    ByNames:\n        - DevOps Prod\n        - Financial Prod\n</code></pre></p>"},{"location":"architecture/PayloadTemplates/#account-region-worker-templates","title":"Account-Region Worker Templates","text":"<p>This is very similar to the account worker templates because it is an account worker template but has some additional properties to include and exclude regions to operate in. All of the account worker options are true for account-region worker templates.</p> <p>The big difference is that account-region worker templates have 2 additional fields:</p> <ol> <li><code>IncludeRegions</code> - This is a list of AWS regions to operate on --OR-- a list where the only entry is the word <code>ALL</code> to operate for all regions (See example below).</li> <li><code>ExcludeRegions</code> - This is a list of AWS regions to NOT operate on.</li> </ol> <p>Very Important</p> <p>There is a configuration property in the <code>STARFLEET</code> configuration stanza that sets an override for the specific regions that can be operated on named <code>ScopeToRegions</code>. This is useful for restricting the regions that Starfleet can operate on if you, for example, have an SCP enabled to disable regions at the organization level.</p> <p>The Starbase will resolve accounts where the following properties are true:</p> <ol> <li>Accounts are specified in the template and are not excluded</li> <li>There are regions specified to operate over and are not excluded</li> <li>The account is enabled in the regions specified</li> <li>If the <code>ScopeToRegions</code> configuration field is set, then the regions specified are within the <code>ScopeToRegions</code> list</li> </ol>"},{"location":"architecture/PayloadTemplates/#some-examples_1","title":"Some Examples","text":"<p>Here are some examples where everything comes together:</p> <p>Here is an example of a template that will operate on every single account in every single enabled region (including the root account): <pre><code>IncludeAccounts:\n    AllAccounts: True\nIncludeRegions:\n    - ALL\nOperateInOrgRoot: True\n</code></pre></p> <p>Here is an example of only running in 3 regions in 3 specific accounts: <pre><code>IncludeAccounts:\n    ByNames:\n        - InfoSec Staging\n        - Marketing Staging\n        - DevOps Staging\nIncludeRegions:\n    - us-east-1\n    - us-east-2\n    - ca-central-1\n</code></pre></p> <p>Here is an example of applying to the <code>Infsec Staging</code> account, all accounts in the <code>DevOps</code>, <code>Financial</code>, and <code>Marketing</code> OUs and excluding accounts named <code>DevOps Prod</code>, and <code>Financial Prod</code>, and all enabled regions except <code>us-west-1</code>. <pre><code>IncludeAccounts:\n    ByNames:\n        - InfoSec Staging\n    ByOrgUnits:\n        - DevOps\n        - Financial\n        - Marketing\nExcludeAccounts:\n    ByNames:\n        - DevOps Prod\n        - Financial Prod\nIncludeRegions:\n    - ALL\nExcludeRegions:\n    - us-west-1\n</code></pre></p>"},{"location":"architecture/ResidentIAMRole/","title":"Resident IAM Role","text":"<p>For Starfleet worker ships to function, there must be an IAM role (or roles) in all of the accounts that it can assume with the permissions to allow the worker to do the things that it needs to do.</p> <p>Starfleet is deployed to 1 AWS account, which is a security sensitive account and the IAM roles for the Starfleet worker ships will need <code>sts:AssumeRole</code> permissions to perform their workloads.</p> <p>The User Guide contains more details on how to set this up, but just know that the account resident IAM Roles exist for Starfleet to work.</p>"},{"location":"architecture/Secrets/","title":"Secrets Management","text":"<p>Starfleet has an internal component for managing secrets that may be used throughout the application. This makes use of AWS Secrets Manager to securely store sensitive data, like tokens, keys, and passwords that a worker may need to utilize.</p> <p>If making use of Slack alerts, then the Slack token will need to be stored here.</p> <p>More details on the secrets management is in the User and Developer guides.</p>"},{"location":"architecture/Starbase/","title":"Starbase","text":"<p>Now that you understand what the Worker ships are and what they do, the configuration and the payload templates, the next phase is to understand the heart of Starfleet, and that's the Starbase.</p> <p>The Starbase is the component of Starfleet that invokes all the worker ships. As a matter of design, the Starbase is the primary way for a worker ship to be invoked. The Starbase does the heavy lifting of needing to:</p> <ol> <li>Determine which worker ships need to run</li> <li>Task the worker ships with the necessary payload for the AWS account to run in</li> </ol> <p>Each worker ship provides details to the Starbase so that it knows how to task it. The worker defines:</p> <ol> <li>Which \"source\" of invocation it should be tasked with</li> <li>How to divvy out the workloads (single, per-account, per-account/region pair)</li> <li>The location of the payload YAML in the template S3 bucket</li> <li>The SQS queue to place the payload for invocation</li> </ol> <p>The Starbase uses a combination of the details above and the account index. The payload (YAML) is written according to a special schema specified by the given worker ship. The Starbase renders the payload schema and attaches the account and regional details (if required) before invoking the worker. The worker is invoked by placing the rendered payload onto an SQS queue that the worker ship is configured to invoke from.</p>"},{"location":"architecture/Starbase/#invocation-sources","title":"Invocation Sources","text":"<p>These are the mechanisms that the Starbase is invoked by. This affects how and when the Starbase tasks workers.  The Starbase is invoked 3 ways that you should care about*:</p> <ol> <li>EventBridge Timed Events</li> <li>Template S3 Bucket Events</li> <li>SNS for a given worker ship (Not yet implemented)</li> </ol> <p>*See the in the weeds section below for the 4th way - this is not something you need to care about.</p> <p>Tip</p> <p>A worker ship can specify multiple invocation sources</p>"},{"location":"architecture/Starbase/#eventbridge-timed-events","title":"EventBridge Timed Events","text":"<p>Each worker can be invoked by EventBridge timed events for a CRON like functionality. The worker ship configuration specifies this. At a minimum, it needs:</p> <pre><code>InvocationSources:\n  - EVENTBRIDGE_TIMED_EVENT\nEventBridgeTimedFrequency: HOURLY  # This is for an hourly job. See below for the types.\n</code></pre> <p>The general gist is that worker ship's configuration specifies that it is to be invoked by an <code>EVENTBRIDGE_TIMED_EVENT</code> and it specifies the <code>EventBridgeTimedFrequency</code> for which timed event to get invoked by.</p> <p>As mentioned, the worker ship's configuration also contains a path in the Payload Template S3 Bucket that stores the worker ship's payload templates. The Starbase will list all the payload YAMLs associated with the worker ship, and then render the payloads for the AWS accounts they are specified to run against. All of these get tasked to the worker ship to perform it's job.</p>"},{"location":"architecture/Starbase/#event-frequencies","title":"Event Frequencies","text":"<p>The following is a list of supported frequencies that a worker can be timed for. These are the exact string values that need to be in the worker's configuration:</p> <pre><code>FIVE_MIN        # Every 5 min\nFIFTEEN_MIN     # Every 15 min\nTHIRTY_MIN      # Every 30 min / half-hourly\nHOURLY          # Every 60 min / hourly\nSIX_HOURLY      # Every 6 hours\nTWELVE_HOURLY   # Every 12 hours / half-daily\nDAILY           # Once a day / every 24 hours\n</code></pre> <p>A worker can only specify one event frequency.</p>"},{"location":"architecture/Starbase/#template-s3-bucket-events","title":"Template S3 Bucket Events","text":"<p>Each worker can be invoked whenever it's configured template (or template in path) is created or updated. This is useful for CI/CD operations where placing a template in the bucket automatically triggers a payload execution.</p> <p>The worker ship configuration specifies this. At a minimum, it needs:</p> <pre><code>InvocationSources:\n  - S3\n</code></pre> <p>The Starbase will receive this event, fetch the template from S3, render it in conjunction with the account index (if applicable) and then task the worker to run.</p>"},{"location":"architecture/Starbase/#sns-for-a-given-worker-ship-tbd","title":"SNS for a given worker ship -- TBD","text":"<p>This section is still TBD and will be ironed out in the future.</p>"},{"location":"architecture/Starbase/#in-the-weeds","title":"In the weeds","text":"<p>Note</p> <p>Timed event invocations actually happen in 2 parts, where the Starbase will actually task itself. This is explained here:</p>"},{"location":"architecture/Starbase/#part-1-find-the-associated-worker-ships","title":"Part 1 - Find the associated worker ships","text":"<p>In part 1 of the timed event invocation, the Starbase locate the workers that are configured for the timed event in question. It will list all the template YAMLs in S3 associated with the worker, and it will then put the details of the Starfleet Worker Ship and the corresponding template YAML path into an SQS queue that the Starbase will invoke from. Then part 2 begins.</p>"},{"location":"architecture/Starbase/#part-2-fan-out-and-task-the-workers-for-the-template","title":"Part 2 - Fan out and task the workers for the template","text":"<p>In part 2 of the timed event invocation, the Starbase will receive a message on it's SQS queue informing it of the name of the Starfleet worker to task and the template YAML in S3 to render. The Starbase will then render the template in conjunction with the account index, and then task the worker ship with the payloads and account details.</p>"},{"location":"architecture/Starbase/#why","title":"Why??","text":"<p>This may seem overly complicated (maybe it is?), but this is done to prevent the Starbase from timing out when putting SQS messages onto the worker queues. This is done so that the Starbase can parallelize the tasking of workers, which when needing to task workers for every account or every account/region pair, that could be a lot of Lambda functions to task. This keeps things fast and scalable.</p>"},{"location":"architecture/WorkerShips/","title":"Worker Ships","text":"<p>The first component of Starfleet to discuss are the Worker Ships. These are Lambda functions that go out and do the work that is needed in each account, account/region pair, or non-AWS account. The choice is yours!</p> <p>A worker ship has the following components:</p> <ol> <li>The logic to do the work</li> <li>A configuration that outlines important details required to make it functional</li> <li>A payload template(s) and corresponding schema that informs the worker what to do and where to do it</li> <li>A \"Fan Out\" strategy</li> <li>An Invocation SQS queue</li> <li>An \"invocation source\" -- this is outlined more in the Starbase section</li> </ol>"},{"location":"architecture/WorkerShips/#the-logic","title":"The Logic","text":"<p>The workers are just AWS Lambda functions written in Python. They do whatever they are coded to do. For AWS related activities, these are largely going to be <code>boto3</code> calls to the AWS API.</p> <p>Note</p> <p>Starfleet Lambda functions are designed to be idempotent and stateless. If a failure occurs, the Lambda function should retry the payload. As mentioned below, a DLQ is set to capture failed payloads after several failed attempts (should they occur).</p>"},{"location":"architecture/WorkerShips/#the-configuration","title":"The Configuration","text":"<p>The next section of the documentation goes into more detail about Starfleet's configuration. But the long and the short of it is that there is a YAML configuration in the Starfleet directory tree that describes how a worker is to be configured. Each worker defines the required items in the configuration via a schema (using the Python Marshmallow schema framework).</p> <p>For now, just know that workers require a configuration entry that details what is required for it to execute properly.</p>"},{"location":"architecture/WorkerShips/#the-sqs-queue","title":"The SQS Queue","text":"<p>Each worker ship has an SQS queue and a corresponding dead-letter queue (DLQ). The SQS queue for the worker is used for invoking the Lambda function. SQS is used for a variety of reasons, namely it scales Lambda invocations very nicely, has great retry-capabilities, and DLQ integration. The DLQ is used to help debug why given payloads have failed.</p>"},{"location":"architecture/WorkerShips/#invocation-source","title":"Invocation Source","text":"<p>A worker also needs an Invocation Source. This is discussed in much more detail later when the Starbase component is explored. Instead of bouncing you back and forth, we are just going to leave a TL;DR summary of what this is: the Invocation Source is what will determine when the worker ship gets invoked. The worker ship can be invoked by a CRON-like event (<code>EVENTBRIDGE_TIMED_EVENT</code>), or by an update to the worker's template in S3 (<code>S3</code>).</p> <p>If using a CRON-like syntax, the configuration will need something that looks like this: <pre><code>InvocationSources:\n  - EVENTBRIDGE_TIMED_EVENT\nEventBridgeTimedFrequency: HOURLY  # This is for an hourly job. See the Starbase section for more details.\n</code></pre></p> <p>If getting invoked by updates to the payload template in S3, it needs: <pre><code>InvocationSources:\n  - S3\n</code></pre></p> <p>Or a mixture of both: <pre><code>InvocationSources:\n  - EVENTBRIDGE_TIMED_EVENT\n  - S3\nEventBridgeTimedFrequency: HOURLY  # This is for an hourly job. See the Starbase section for more details.\n</code></pre></p> <p>The <code>InvocationSources</code> is a list and thus the worker can be invoked by a variety of sources if it is developed to do so.</p> <p>Warning</p> <p>There are other invocation sources that are being considered, like SNS or SQS, but that has not yet been ironed out or implemented. At this time the <code>InvocationSources</code> configuration is subject to change.</p>"},{"location":"architecture/WorkerShips/#the-fan-out-strategy","title":"The Fan Out Strategy","text":"<p>All workers have what is called a Fan Out Strategy. This describes how a worker should be tasked. This defines whether or not a worker should be tasked to operate as a single invocation, or if there should be a worker dedicated to each AWS account, or a worker dedicated to each AWS account and region pair.</p> <p>This is a property of the worker ship itself and defined in the code for it. The developer guide has more details, but for now a worker can be coded for one of the following 3 options:</p> <pre><code># This means that there is 1 Lambda function required to complete the task. No AWS account context is provided to the worker.\n- SINGLE_INVOCATION\n\n# This means that there should be 1 Lambda function for each AWS account to complete the task. Most workers would likely require this.\n# This will provide the AWS account ID to the worker that it should operate in. The worker would assume an IAM role in that account in order\n# to operate within in.\n- ACCOUNT\n\n# This means that there is 1 Lambda function for each account AND enabled AWS region. This is very similar to the ACCOUNT fan out, but this one\n# also includes context on the region to operate in as well (only if that region is enabled for the given AWS account).\n# This will spawn the most Lambda invocations.\n- ACCOUNT_REGION\n</code></pre> <p>A worker can only be configured to have one fan out strategy.</p>"},{"location":"architecture/WorkerShips/#the-payload-template","title":"The Payload Template","text":"<p>More information is provided about the payload YAML templates in the next sections, but the key thing to note is that each worker ship has at least 1 YAML payload template. The template is intended to inform the worker what it needs to do in an invocation. Each worker defines it's own template schema (using the Python Marshmallow). A worker can be configured to support many templates. An example would be a worker that synchronizes IAM roles; in this example, there would be 1 template for each IAM role that Starfleet maintains.</p> <p>All of the templates are stored in an S3 bucket (referred to loosely as the Template Bucket or Template Payload Bucket). It is required that the worker's configuration specify where in the template S3 bucket it's template files exist. This can either be a path to a single file, or to a directory-like prefix where many files reside.</p> <p>Here is what that configuration looks like:</p> <pre><code># For a single template file:\nTemplatePrefix: NAME-OF-WORKER-SHIP/worker_template.yaml\n\n# -- OR -- for many templates within a prefix (standard S3 prefix syntax):\nTemplatePrefix: NAME-OF-WORKER-SHIP/\n</code></pre> <p>Note</p> <p>All templates must be YAML files that end in <code>.yaml</code>. Starfleet relies on S3 object listing to find the templates, so nested directory paths will also be looked at automatically.</p>"},{"location":"architecture/WorkerShips/#next-sections","title":"Next sections","text":"<p>Now that you understand the general gist of the worker ships, the next sections will provide more clarity about how to configure the workers, make payload templates, and also how the workers get tasked.</p>"},{"location":"blog/","title":"The Starfleet Blog","text":"<p>This is the main go-to for announcements on the Starfleet project. Follow this for updates on new features, bug fixes, etc.</p>"},{"location":"blog/2024/04/08/ecrdockerized-lambda-support/","title":"ECR/Dockerized Lambda Support","text":"<p>We made a small update to the docs to highlight deploying Starfleet with a Dockerized Lambda. This was necessary as Starfleet's dependencies made it larger than the <code>.zip</code> file size limit for Lambda.</p> <p>The main steps to convert to this from a non-ECR set up is to:</p> <ol> <li>Create the Private ECR repo in the same account/region you have Starfleet deployed in.</li> <li>Update the <code>samconfig.toml</code> file.</li> <li>Update the SAM template.</li> <li>Re-build and deploy.</li> </ol> <p>The Dockerized Lambda is built with the included <code>Dockerfile</code>, which should have everything needed and ready to go. You can test that the container builds by running <code>docker build .</code> from within the Starfleet directory.</p>"},{"location":"blog/2024/04/08/ecrdockerized-lambda-support/#update-sam-config","title":"Update SAM Config","text":"<p>Once you create your ECR Repo, you then need to update your <code>samconfig.toml</code> file to include the line: <pre><code>image_repository = \"ACCOUNT_ID.dkr.ecr.REGION.amazonaws.com/REPONAME\"\n</code></pre> ... under your <code>.deploy.parameters</code> sections.</p>"},{"location":"blog/2024/04/08/ecrdockerized-lambda-support/#update-your-sam-template","title":"Update your SAM Template","text":"<p>The SAM template also needs to be updated. Included now are 2 sample SAM Templates: <code>test_sam_template.yaml</code>, which is the ECR sample template, and <code>test_sam_template_NO_ECR.yaml</code>, which is the original non-ECR version.</p> <p>You would need to update all the function entires to change it from: <pre><code>  StarbaseEventBridgeFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: ./src\n      Handler: starfleet.starbase.entrypoints.eventbridge_timed_lambda_handler\n      Runtime: python3.12\n</code></pre> over to:</p> <pre><code>  StarbaseEventBridgeFunction:\n    Type: AWS::Serverless::Function\n    Metadata:\n      DockerTag: starfleet\n      DockerContext: ./\n      Dockerfile: Dockerfile\n    Properties:\n      PackageType: Image\n      ImageConfig:\n        Command:\n          - starfleet.starbase.entrypoints.eventbridge_timed_lambda_handler\n</code></pre> <p>Update all the Lambda definitions to include the <code>Metadata</code> section as shown above (this is the same for all the functions) and update the <code>Properties</code> section to have the fields above. Remove the old fields. Note: the <code>Command</code> field is where you place the Lambda handler path - this is unique to each Lambda function.</p> <p>For more information see the ECR setup documentation and also AWS's documentation here.</p>"},{"location":"blog/2023/07/19/starfleet-presented-at-fwdcloudsec-2023/","title":"Starfleet Presented at fwd:cloudsec 2023","text":"<p>Starfleet was presented at fwd:cloudsec 2023 in the talk titled Rolling out AWS Infrastructure Everywhere with Space Ships.</p> <p>Watch it here:</p>"},{"location":"blog/2023/07/20/iam-role-worker/","title":"IAM Role Worker","text":"<p>We have developed a Starfleet worker for syncing IAM roles. This worker wraps the excellent IAMbic library to perform the heavy lifting of the actual IAM work. If you haven't checked out IAMbic yet, please take a look at it. It's a full-featured IaC that unifies IAM management across the AWS world (and other identity providers) with lots of features and capabilities.</p> <p>Most of the documentation for this worker resides in our User Guide.</p>"},{"location":"blog/2023/07/20/iam-role-worker/#how-does-this-work","title":"How does this work?","text":"<p>The long and the short of it, we are simply embedding an IAMbic template within a Starfleet template. Starfleet performs the heavy lifting of tasking worker lambdas with the AWS account context to operate in. Starfleet then embeds the current account context within the IAMbic template that gets passed into the IAMbic library to sync the role.</p> <p>Here is a sample role template:</p> <pre><code>TemplateName: DevOpsAutomationRole\nTemplateDescription: This is a role for DevOps automation to do DevOps things\nIncludeAccounts:\n  ByNames:\n    - DevOpsTest\n    - DevOpsProd\nIambicRoleTemplate:  # &lt;----- The IAMbic template gets embedded into here\n  properties:\n    role_name: DevOpsAutomationRole\n    description: 'The DevOpsRole for DevOpsAutomation in {{ var.account_name }}'\n    assume_role_policy_document:\n      statement:\n        - action: sts:AssumeRole\n          effect: Allow\n          principal:\n            service: ec2.amazonaws.com\n      version: '2012-10-17'\n    managed_policies:\n      - policy_arn: arn:aws:iam::aws:policy/ReadOnlyAccess\n    inline_policies:\n      - policy_name: DevOpsThings\n        statement:\n          - sid: DevOpsThings\n            effect: Allow\n            action:\n              - ec2:*\n              - elasticloadbalancing:*\n              - iam:PassRole\n            resource: '*'\n            version: '2012-10-17'\n\n      # Give the DevOpsTest account access to the DevOpsTest S3 Bucket:\n      - StarfleetIncludeAccounts:\n          ByNames:\n            - DevOpsTest\n        policy_name: ArtifactBucket\n        statement:\n          - effect: allow\n            action:\n              - s3:Get*\n              - s3:List*\n              - s3:PutObject\n            resource:\n              - aws:s3:::some-devops-bucket-devopstest\n              - aws:s3:::some-devops-bucket-devopstest/*\n        version: '2012-10-17'\n\n      # Give the DevOpsProd account access to the DevOpsProd S3 Bucket:\n      - StarfleetIncludeAccounts:\n          ByNames:\n            - DevOpsProd\n        policy_name: ArtifactBucket\n        statement:\n          - effect: allow\n            action:\n              - s3:Get*\n              - s3:List*\n              - s3:PutObject\n            resource:\n              - aws:s3:::some-devops-bucket-devopsprod\n              - aws:s3:::some-devops-bucket-devopsprod/*\n        version: '2012-10-17'\n</code></pre>"},{"location":"blog/2023/07/20/iam-role-worker/#what-is-different-between-this-and-vanilla-iambic","title":"What is different between this and vanilla IAMbic?","text":"<p>Starfleet is simply wrapping the IAMbic library so that you use Starfleet instead of vanilla IAMbic. The primary benefit is that if you are already using Starfleet, then you can start rolling out IAM roles where you need it with drift prevention. You just need to familiarize yourself with the IAMbic template format to begin using it.</p> <p>There are however, some caveats. This is documented more in the User Guide.</p>"},{"location":"blog/2023/07/20/iam-role-worker/#other-iambic-features","title":"Other IAMbic features","text":"<p>IAMbic has a lot of other standalone features, like support for other cloud provider identities, the ability to import existing IAM principals into IAMbic templates, and also the ability to implement time-limited policies that are not presently supported in Starfleet. The Starfleet worker is ideal if you don't have a need for those features and you just want to define an IAM role that must be consistently deployed in all the places you need it.</p>"},{"location":"blog/2023/07/20/iam-role-worker/#other-iam-capabilities","title":"Other IAM capabilities?","text":"<p>At the time of writing, the IAM role worker is the main need we have, but we would love to add more IAM features in the future. IAMbic makes this really easy for us to do. Of course, if you would like to contribute, we would love to help!</p>"},{"location":"developerGuide/CheckList/","title":"Development Check List","text":"<p>This page is a simple check list to double-check that you have done all the steps you needed.</p> <ul> <li> You set up the virtual environment and are inside of the virtual environment - Link</li> <li> You installed the requirements - Link</li> <li> You created (or your deployment script places) your Worker Ship Python package under <code>src/starfleet/worker_ships/plugins/</code> - Link</li> <li> Your Worker Ship Plugin has a configuration schema that is a subclass of <code>WorkerShipBaseConfigurationTemplate</code> - Link</li> <li> Your Worker Ship Plugin has a payload template schema that is a subclass of <code>WorkerShipPayloadBaseTemplate</code> (this includes the account and account/region base classes) - Link</li> <li> Your Worker Ship Plugin contains a class that subclasses <code>StarfleetWorkerShip</code> and configures it with all the required components, like the schemas, and also implements the <code>execute</code> function to do the thing that needs to be done - Link</li> <li> You created a <code>lambda_handler</code> function that is wrapped by the <code>@worker_lambda</code> decorator - Link</li> <li> You created a <code>click.group</code> decorated function, and also some CLI commands for that group - Link</li> <li> In your plugin package's <code>__init__.py</code>, you defined both <code>WORKER_SHIP_PLUGINS</code> set to a list of the <code>StarfleetWorkerShip</code> classes you defined - Link</li> <li> In your plugin package's <code>__init__.py</code>, you defined both <code>CLICK_CLI_GROUPS</code> set to a list of the <code>click.group()</code> decorated functions you defined - Link</li> <li> You made extensive pytest tests for your Worker Ship Plugin with nice fixtures 100% test coverage. Yes \ud83d\udcaf% test coverage! See the existing tests for details on how to make good tests.</li> <li> You created (or your deployment script places) your Starfleet configuration with the proper configuration entries in <code>src/starfleet/configuration</code> - Link</li> <li> You made the necessary changes to the SAM Template for your Lambdas to get deployed (don't forget to update the configuration to include the SQS URLs!) - Link</li> <li> Your payload template resides in the template S3 bucket where your worker expects it</li> <li> Make sure your Lambda has enough time and memory to run. You'll need to monitor the logs to see how much RAM and time it takes to run your workload to make adjustments in the SAM template.</li> </ul> <p>There are probably more but this should help you isolate and detect issues should they arise.</p>"},{"location":"developerGuide/GeneratingDocs/","title":"Generating the Documentation","text":"<p>This page outlines how to generate the lovely docs you are currently reading!</p> <p>The docs are generated via <code>mkdocs</code> with Material for MkDocs. All of the docs are markdown files that reside in the <code>mkdocs/</code> directory, and the docs site is configured via the <code>mkdocs.yml</code> file.</p>"},{"location":"developerGuide/GeneratingDocs/#dependencies","title":"Dependencies","text":"<p>All of the dependencies to build the docs are installed as part of the test dependencies (defined in <code>pyproject.toml</code>). This is obtained by running:</p> <pre><code>source venv/bin/activate  # Make sure you are in your venv\npip install -e .\"[tests]\"\n</code></pre>"},{"location":"developerGuide/GeneratingDocs/#running-mkdocs","title":"Running mkdocs","text":"<p>You can run <code>mkdocs</code> locally by running:</p> <pre><code>source venv/bin/activate  # Make sure you are in your venv\nmkdocs serve\n</code></pre> <p>... and then opening your web browser to <code>http://localhost:8000</code>. Errors and warnings will appear in the console output. Please make sure there are none before submitting documentation updates.</p>"},{"location":"developerGuide/GeneratingDocs/#building-the-docs","title":"Building the docs","text":"<p>The docs are built by running:</p> <pre><code>source venv/bin/activate  # Make sure you are in your venv\nmkdocs build -d docs/\n</code></pre> <p>Doing this will generate the docs to the <code>site/</code> directory. You need to rename this directory to <code>docs/</code>. This directory is not included in the main branch of the repository. Instead, we have another branch called <code>gh-pages</code> where this is committed to. This is what GitHub uses to host the site you are reading right now.</p>"},{"location":"developerGuide/Overview/","title":"Developer Guide","text":"<p>This section is to guide you in being able to develop features for Starfleet. This will go into depth on how Starfleet is architected and how to develop worker ships and other plugins.</p>"},{"location":"developerGuide/Overview/#basic-overview","title":"Basic Overview","text":"<p>Starfleet is built on Python 3 and is run on AWS Lambda. Starfleet has some major dependencies:</p> <ol> <li>Marshmallow - For defining schemas and validating Starfleet configurations and payload templates<ul> <li>In case you are wondering, we chose Marshmallow over pydantic because Marshmallow has excellent flexibility capabilities that greatly benefits a project like Starfleet vs. raw performance and simplicity where pydantic really shines</li> </ul> </li> <li>Click - For making the Starfleet CLIs</li> <li>pytest - The unit testing framework</li> <li>pyproject.toml - For defining the Python package itself</li> <li>tox - Tool for automating the run of our unit tests and linting</li> <li>black - To make our code look very nice</li> <li>AWS SAM For deploying Starfleet and it's components to AWS</li> <li>Mkdocs and Material for Mkdocs - The docs you are looking at right now :)</li> </ol>"},{"location":"developerGuide/Overview/#general-advice","title":"General Advice","text":"<p>Starfleet's code can look very intimidating because there are a bunch of distributed items. The best way to get to learn Starfleet is to dig into the code for existing plugins, add some breakpoints, and then run the tests in debug mode. We strongly recommend using PyCharm to do this.</p> <p>You may also want to review some of the dependencies, like Marshmallow and pytest (especially pytest fixtures), to get a better feel for what the code is really doing.</p>"},{"location":"developerGuide/Overview/#some-etiquette-and-terminology","title":"Some Etiquette and Terminology","text":"<p>Throughout this guide, we will interchangeably refer to paths of files in the Python import format like: <code>some.package.in.python.file.resource</code> vs. <code>src/starfleet/some/package/in/python/file.py</code>. We will use the latter format when we are specifically referring to non-python specific paths.</p>"},{"location":"developerGuide/Overview/#common-themes","title":"Common Themes","text":"<p>There are a number of common themes throughout the codebase that you may notice. We are a big fan of the singleton pattern, and use it extensively throughout the code for providing major components like the:</p> <ul> <li>Logger</li> <li>Configuration Manager</li> <li>Account Index</li> <li>Worker Ships Registry</li> <li>CLIs</li> </ul> <p>Additionally, we are also a very big fan of plugins. We try to make everything in Starfleet a plugin because this is an open source project, and making everything a plugin means we (and you!) can extend Starfleet's capabilities with ease.</p> <p>The next section discusses the major singleton components that are used throughout the code base and how to make use of them.</p>"},{"location":"developerGuide/Overview/#getting-started","title":"Getting Started","text":"<p>To get started you will need to have a proper Python 3 environment set up. We recommend using pyenv. You'll also need to install the AWS SAM CLI, which you will also want to install Docker too when building the Starfleet Lambdas that get deployed to AWS.</p> <p>These docs are making an assumption that you are running macOS or Linux.</p> <p>Starfleet uses the latest version of Python 3 that is supported by AWS Lambda. You will want to have that installed and configured.</p>"},{"location":"developerGuide/Overview/#set-up-virtual-environment","title":"Set Up Virtual Environment","text":"<p>Always make use of a python virtual environment with Starfleet. Always.</p> <p>To get started you will make a virtual environment:</p> <pre><code># Git clone the repo ... (recommended you make a fork on GitHub and pull from that for development -- you\n#                         can also add the upstream repository as a remote with\n#                         `git remote add upstream git@github.com:gemini-oss/starfleet.git` followed by `git fetch --all`)\ncd starfleet/\npython3 -m venv venv\nsource venv/bin/activate\n</code></pre> <p>After running the above you now have a working virtual environment.</p> <p>Warning</p> <p>Make sure that everything you run is within this virtual environment! You can always get back into it by running <code>source venv/bin/activate</code>.</p>"},{"location":"developerGuide/Overview/#install-the-dependencies","title":"Install The Dependencies","text":"<p>Once you have your virtual environment created and activated, you are now ready to install the package and the dependencies:</p> <pre><code># Install the main starfleet components with dependencies:\npip install -e .\n\n# Install the test components:\npip install -e .\"[tests]\"\n</code></pre>"},{"location":"developerGuide/Overview/#test-it","title":"Test It!","text":"<p>You can test that it's all working by running <code>tox</code>:</p> <p><pre><code>tox\n# ... a lot of output ...\n</code></pre> If you see errors about tests failing then there is a problem! The command at the end should say something along the lines of:</p> <pre><code>  py39: OK (10.14=setup[3.61]+cmd[6.53] seconds)\n  lint: OK (9.69=setup[2.83]+cmd[0.83,0.40,5.63] seconds)\n  congratulations :) (19.88 seconds)\n</code></pre>"},{"location":"developerGuide/Overview/#requirements-and-updates","title":"Requirements and Updates","text":"<p>The Starfleet primary requirements are set in <code>src/requirements.txt</code>. This is placed here so that AWS SAM knows where to find and install the dependencies. The requirements for unit tests reside in the <code>pyproject.toml</code> file under the <code>[project.optional-dependencies]</code> section.</p>"},{"location":"developerGuide/Overview/#packaging-deployment-considerations","title":"Packaging &amp; Deployment Considerations","text":"<p>In this section, we discuss some considerations when packaging and deploying your internal code.</p>"},{"location":"developerGuide/Overview/#internal-repo","title":"Internal Repo","text":"<p>You will want to make an internal repository that holds all your configuration and internal plugins. We recommend that you have something simple that clones the Starfleet upstream, and then copies over your specific configuration details into the <code>starfleet</code> directory paths. From there you would want to run your SAM commands to build and deploy your \"baked\" Starfleet deployment which would be ready to go.</p>"},{"location":"developerGuide/Overview/#worker-development","title":"Worker Development","text":"<p>When developing your worker, you'll likely want to develop it against the upstream since that will make it easy to debug and get a local working version. However, and this can't be stressed enough:</p> <p>Don't pull-request your internal code!!</p> <p>Always copy your code out of the upstream and into your internal repo!</p> <p>Another strategy is to have an internal repo that pulls from upstream via a git submodule or even if you just maintain your local copy. There are many different ways to package and deploy for your own internal purposes. Pick the approach that works best for your organization.</p> <p>Keep your tests separate from your logic</p> <p>You will want to keep your tests separate from your logic as well. This will help reduce the size of the packaged .zip file that is packaged with your Lambda function.</p> <p>We highly recommend running <code>tox</code> against the unified code to make sure that all the tests pass and everything looks copasetic.</p>"},{"location":"developerGuide/Overview/#contributing-back","title":"Contributing Back","text":"<p>We just love to get contributions from the community! Make sure you thoroughly test your code. Remember: this is code that will run potentially EVERYWHERE in your infrastructure so 100% test coverage is not a bad idea, even if it seems excessive. The last thing you want to see is an exception in your logs because you referenced a variable that wasn't declared yet in a certain <code>if</code> statement, or logging out the value of something that was wrong. The more tests, the less hair-pulling once deployed.</p>"},{"location":"developerGuide/Overview/#next-sections","title":"Next Sections","text":"<p>The next sections provide an in-depth look at the primary components of Starfleet. The worker ships guide is a separate section as it requires a lot of depth!</p>"},{"location":"developerGuide/SAMConfiguration/","title":"AWS SAM Configuration","text":"<p>Last but certainly not least is the AWS SAM specification. We provide a sample AWS SAM template to make things easy to deploy. We recommend setting up ECR to have a Dockerized Lambda function since the Starfleet dependencies may blow past the Lambda filesize limit. All examples below assume we are using ECR.</p> <p>At a minimum, you'll need to have a defined Lambda function, IAM permissions (typically to assume a role -- with a target role that permits the access), and that's basically it.</p> <p>The <code>AccountIndexGeneratorShip</code> is always a great example:</p> <pre><code># The DLQ:\nAccountIndexGeneratorDLQ:\n  Type: AWS::SQS::Queue\n  Properties:\n    QueueName: starfleet-account-index-generator-dlq\n    RedriveAllowPolicy:\n      redrivePermission: allowAll\n\n# The main event SQS Queue\nAccountIndexGeneratorQueue:\n  Type: AWS::SQS::Queue\n  Properties:\n    QueueName: starfleet-account-index-generator\n    VisibilityTimeout: 300  # This needs to be the same as the Lambda function timeout.\n    RedrivePolicy:\n      deadLetterTargetArn: !GetAtt AccountIndexGeneratorDLQ.Arn\n      maxReceiveCount: 4\n\n# The Lambda function:\nAccountIndexGenerator:\n  Type: AWS::Serverless::Function\n  Metadata:\n    DockerTag: starfleet\n    DockerContext: ./\n    Dockerfile: Dockerfile\n  Properties:\n    PackageType: Image\n    ImageConfig:\n      Command:\n        - starfleet.worker_ships.plugins.account_index_generator.ship.lambda_handler\n    Architectures:\n      - arm64\n    MemorySize: 256\n    Events:\n      SQSEvent:\n        Type: SQS\n        Properties:\n          Queue: !GetAtt AccountIndexGeneratorQueue.Arn\n          BatchSize: 2\n    Environment:\n      Variables:\n        STARFLEET_COMMIT: True\n    Policies:\n      # Grant permissions to read from the inventory S3 bucket:\n      - S3ReadPolicy:\n          BucketName: !FindInMap\n            - EnvMap\n            - !Ref 'EnvironmentName'\n            - AccountInventoryBucket\n      - S3WritePolicy:\n          BucketName: !FindInMap\n            - EnvMap\n            - !Ref 'EnvironmentName'\n            - AccountInventoryBucket\n\n# ...\n\n# Finally, the Starbase Fanout Function:\nStarbaseFanoutFunction:\n  Type: AWS::Serverless::Function\n  DependsOn:\n    - AccountIndexGeneratorQueue\n  Metadata:\n    DockerTag: starfleet\n    DockerContext: ./\n    Dockerfile: Dockerfile\n  Properties:\n    PackageType: Image\n    ImageConfig:\n      Command:\n        - starfleet.starbase.entrypoints.fanout_payload_lambda_handler\n    Architectures:\n      - arm64\n    Events:\n      # Make one for each timed event:\n      SQSEvent:\n        Type: SQS\n        Properties:\n          Queue: !GetAtt StarbaseFanoutQueue.Arn\n          BatchSize: 1  # Important! We only want 1 to ensure we don't hit timeouts.\n    Policies:\n      # Grant permissions to read from the Template S3 bucket:\n      - S3ReadPolicy:\n          BucketName: !Ref StarfleetTemplateBucket\n      - SQSSendMessagePolicy:\n          QueueName: !GetAtt AccountIndexGeneratorQueue.QueueName\n\n# Common worker ship components here:\nAssumeRoleManagedPolicy:\n  Type: AWS::IAM::ManagedPolicy\n  DependsOn:\n    - AccountIndexGenerator\n  Properties:\n    Description: Grants Starfleet workers assume role permissions to common Starfleet worker IAM roles\n    ManagedPolicyName: StarfleetWorkerAssumeRoles\n    PolicyDocument:\n      Version: \"2012-10-17\"\n      Statement:\n        - Effect: Allow\n          Action: 'sts:AssumeRole'\n          Resource:\n            - !Sub\n              - 'arn:aws:iam::*:role/${RoleName}'\n              - RoleName: !FindInMap\n                  - EnvMap\n                  - !Ref 'EnvironmentName'\n                  - BaseRoleName\n    Roles:\n      - !Ref AccountIndexGeneratorRole  # AccountIndexGeneratorRole is created automatically by SAM and can be referenced\n</code></pre> <p>Some important things to note are:</p> <ul> <li>We set the <code>STARFLEET_COMMIT</code> environment variable to True, which in the case of the <code>AccountIndexGeneratorShip</code> will result in it writing to the S3 buckets that are permitted in the policies section (we use a map and define TEST and PROD S3 buckets -- see <code>test_sam_template.yaml</code> in the code for more details)</li> <li>We always have an SQS queue and corresponding DLQ</li> <li>The Starbase fan out Lambda function needs to be able to publish events onto the worker's main event queue</li> <li>We made a sample managed policy for role assumption and we attach it to the worker's IAM role (this is automatically generated; it's the name of the YAML dictionary name, followed by <code>Role</code>.</li> <li>So for the <code>AccountIndexGeneratorShip</code>, SAM will make an IAM role named <code>AccountIndexGeneratorRole</code></li> </ul> <p>Note</p> <p>The Queue URL of the main event Queue as shown above needs to be in the configuration for the worker.</p>"},{"location":"developerGuide/SAMConfiguration/#sam-config","title":"SAM Config","text":"<p>We strongly recommend that you make a SAM configuration environment (<code>samconfig.toml</code>) that sets up the SAM S3 bucket and all the build details required. We include an example <code>samconfig.toml</code>, which is pasted below:</p> <pre><code>version = 0.1\n[TEST]\n[TEST.deploy]\n[TEST.deploy.parameters]\nstack_name = \"starfleet\"\ns3_bucket = \"REPLACE-ME\"  # The SAM CLI will generate this with a \"guided\" deploy option -- or you can just make this yourself.\ns3_prefix = \"starfleet\"\nregion = \"REPLACEME\"\nconfirm_changeset = true\ncapabilities = [\"CAPABILITY_IAM\", \"CAPABILITY_NAMED_IAM\"]  # Important -- you need these capabilities defined since this creates IAM roles\nparameter_overrides = \"EnvironmentName=\\\"TEST\\\"\"\nimage_repository = \"REPLACE ME - IF YOU ARE  NOT USING ECR DELETE THIS LINE\"\n\n[TEST.validate.parameters]\nregion = \"REPLACEME\"\nlint = true\n\n[TEST.build.parameters]\nuse_container = true\ntemplate_file = \"test_sam_template.yaml\"  # Feel free to replace with your own filename\n\n\n[PROD]\n[PROD.deploy]\n[PROD.deploy.parameters]\nstack_name = \"starfleet\"\ns3_bucket = \"REPLACE-ME\"  # The SAM CLI will generate this with a \"guided\" deploy option -- or you can just make this yourself.\ns3_prefix = \"starfleet\"\nregion = \"REPLACEME\"\nconfirm_changeset = true\ncapabilities = [\"CAPABILITY_IAM\", \"CAPABILITY_NAMED_IAM\"]  # Important -- you need these capabilities defined since this creates IAM roles\nparameter_overrides = \"EnvironmentName=\\\"PROD\\\"\"\nimage_repository = \"REPLACE ME - IF YOU ARE  NOT USING ECR DELETE THIS LINE\"\n\n[PROD.validate.parameters]\nregion = \"REPLACEME\"\nlint = true\n\n[PROD.build.parameters]\nuse_container = true\ntemplate_file = \"prod_sam_template.yaml\"  # Feel free to replace with your own filename\n</code></pre> <p>With a <code>samconfig.toml</code> like that you can then run <code>sam build --config-env TEST</code> to build your test Starfleet deployment and <code>sam deploy --config-env TEST</code> to deploy it. Swap out <code>TEST</code> with <code>PROD</code> for your production build and deployment.</p>"},{"location":"developerGuide/primaryComponents/AccountIndexer/","title":"Account Indexer","text":"<p>The Account Index plugin is loaded by the Starbase and optionally other worker ships if they need it. As mentioned, the purpose is to provide an inventory of AWS accounts that Starfleet can operate on.</p> <p>An Account Indexer is required for the Starbase to function, and for your account and account/region based workers to function. Starfleet requires the name of an account index plugin to be provided in the <code>STARFLEET</code> stanza of the configuration with the field <code>AccountIndexer: AccountIndexPluginNameHere</code>.</p>"},{"location":"developerGuide/primaryComponents/AccountIndexer/#default-account-index","title":"Default Account Index","text":"<p>By default, Starfleet will leverage the <code>StarfleetDefaultAccountIndex</code> plugin. This plugin leverages the generated account index JSON that is produced by the <code>AccountIndexGeneratorShip</code> plugin saved to S3. You will first need to have that index generator run before any other workers can be used with this account index.</p> <p>If the default account index is not sufficient for your use case, then you are welcome to make your own. See below.</p>"},{"location":"developerGuide/primaryComponents/AccountIndexer/#account-index-plugin-residency","title":"Account Index Plugin Residency","text":"<p>Account index plugins need to reside in the <code>src/starfleet/account_index/plugins/</code> directory. This is exactly the same pattern that is used for worker ship plugins.</p> <p>At a minimum, you'll need a <code>__init__.py</code> file. We'll cover more about this file in the Worker Ship Loader portion. For now, just now that you will need a directory that looks like this:</p> <pre><code>...\naccount_index\n\u2514\u2500\u2500 plugins\n    \u2514\u2500\u2500 your_plugin\n            \u2514\u2500\u2500 __init__.py\n            \u2514\u2500\u2500 some_other_python_file.py\n            \u2514\u2500\u2500 ...\n</code></pre> <p>See the Developer Guide Overview page on more details on packaging non-OSS and internal worker ship plugins.</p>"},{"location":"developerGuide/primaryComponents/AccountIndexer/#base-class","title":"Base Class","text":"<p>Like with worker ships, there is a base class named <code>AccountIndex</code> that resides in <code>starfleet.account_index.schematics</code> that you need to sub-class. This class has a number of methods that resolve AWS account IDs. The plugin needs to interact with whatever AWS account inventory system you use to pull out the requested details. Generally, the methods will return a Python set of AWS Account ID strings back out. The Starbase will heavily rely on Python <code>set</code> logic for coming up with the proper list of accounts to iterate over.</p>"},{"location":"developerGuide/primaryComponents/AccountIndexer/#registering-the-plugin","title":"Registering the Plugin","text":"<p>Similar to the worker ships, the account index plugin needs to have a <code>__init__.py</code> file that has a list named <code>ACCOUNT_INDEX_PLUGINS</code> equal to a list of <code>AccountIndex</code> sub-classes.</p> <p>The <code>StarfleetDefaultAccountIndex</code> is a great example: <pre><code>from starfleet.account_index.plugins.starfleet_default_index.ship import StarfleetDefaultAccountIndex\n\nACCOUNT_INDEX_PLUGINS = [StarfleetDefaultAccountIndex]\n</code></pre></p>"},{"location":"developerGuide/primaryComponents/AccountIndexer/#configuration","title":"Configuration","text":"<p>For Starfleet to use your account index plugin, you need to have it configured to use it. At a minimum, you need to set the name of the plugin class in the <code>STARFLEET</code> configuration stanza's <code>AccountIndex</code> field. I.e. if your class is named <code>class FooAccountIndexPlugin</code>, then you will want to have <code>AccountIndex: FooAccountIndexPlugin</code> in your <code>STARFLEET</code> configuration stanza.</p> <p>As far as Marshmallow schemas are concerned, we do not require you to define one, however you are welcome to should you desire. If you do this, then add the logic in your plugin's <code>init()</code> function call. See the <code>StarfleetDefaultAccountIndex</code> plugin's code in <code>starfleet.account_index.plugins.starfleet_default_index</code> for details.</p>"},{"location":"developerGuide/primaryComponents/AccountIndexer/#loader","title":"Loader","text":"<p>Account index plugins are loaded and exposed via the <code>ACCOUNT_INDEX</code> singleton. The account index plugins are registered and the configured (see above) plugin is instantiated by the singleton by calling the <code>ACCOUNT_INDEX.index</code> property to get the loaded and ready-to-go account index object back out.</p> <p>The singleton has an pytest fixture named <code>test_index</code> in <code>tests.account_index.conftest</code> that overrides the path for the plugins to load plugins from <code>tests.account_index.testing_plugins</code>.</p> <p>This otherwise works exactly like the worker ship loader.</p> <p>Tip</p> <p>We recommend that if you make an account index plugin that it be as fast as possible. Reducing network IO would be desireable. But, also keep memory usage in mind since you don't want to run out of memory for your Lambda.</p>"},{"location":"developerGuide/primaryComponents/ConfigurationManager/","title":"Configuration Manager","text":"<p>It is very important to understand the configuration! Make sure you first review the Architecture section for Configuration before reading this section. The configuration is provided as a singleton object in <code>starfleet.utils.configuration</code> and is used like this:</p> <pre><code># Import the configuration manager:\nfrom starfleet.utils.configuration import STARFLEET_CONFIGURATION\n\n# ...\n\n# Use the configuration\nsome_config_entry = STARFLEET_CONFIGURATION.config[\"STARFLEET\"]  # Fetch the dictionary under the STARFLEET configuration section\nsome_other_config_entry = STARFLEET_CONFIGURATION.config[\"AccountIndexGeneratorShip\"]  # Fetch the dictionary under the AccountIndexGeneratorShip worker ship definition\n</code></pre> <p>All of the configuration is obtained by using <code>STARFLEET_CONFIGURATION.config</code>. <code>config</code> is a dictionary that is lazy loaded property that contains a dictionary of all the configuration YAML data. The configuration is loaded once on startup by it going to the <code>src/starfleet/configuration_files/</code> path, loading all the nested <code>.yaml</code> files and then merging them into one large dictionary.</p>"},{"location":"developerGuide/primaryComponents/ConfigurationManager/#configuration-schemas","title":"Configuration Schemas","text":"<p>There are Marshmallow schemas for configuration, however these are loaded piecemeal and not all at once. This can be confusing so we'll tackle this in parts to make this more clear.</p>"},{"location":"developerGuide/primaryComponents/ConfigurationManager/#base-configuration-schema","title":"Base Configuration Schema","text":"<p>There is a <code>BaseConfigurationSchema</code> that resides in <code>starfleet.utils.config_schema</code>, which defines the schema for the <code>STARFLEET</code> section of the configuration. This schema is used when loading the initial configuration, and verifies that the <code>STARFLEET</code> section is correct.</p>"},{"location":"developerGuide/primaryComponents/ConfigurationManager/#worker-ship-configurations","title":"Worker Ship Configurations","text":"<p>The worker ship configurations are documented later in detail. However, for now we'll mention that the worker ship configurations are validated against the worker ship defined schemas when the worker ship plugins are loaded later on during startup.</p>"},{"location":"developerGuide/primaryComponents/ConfigurationManager/#unit-testing-configuration","title":"Unit Testing Configuration","text":"<p>Mocking out the configuration is extremely important for running unit tests. We have defined a pytest fixture that sets the configuration manager's <code>config</code> property to a testing dictionary suitable for all the unit tests. The really nice thing about this is that this sets the testing configuration for all the unit tests as long as the <code>test_configuration</code> fixture is used during the tests (or inherited from another fixture you are using). This is another reason why we really like using Singletons - it makes mocking things out very easy and globally for the code when testing.</p> <p>The <code>test_configuration</code> fixture is defined in <code>tests.conftest</code>. Unit tests have configuration YAML files stored in a separate location under <code>tests/test_configuration_files/</code>. The configuration manager is configured by the fixture to load files from that location instead of <code>src/starfleet/configuration_files</code> to make testing clean and isolated. This is a pattern that is frequently used throughout Starfleet.</p> <p>As you develop features, you will want to make changes to the configuration to include the details you need for testing the code you are writing. You can easily do that by making a pytest fixture that looks like this:</p> <pre><code>@pytest.fixture\ndef my_worker_ship_configuration(test_configuration: Dict[str, Any]) -&gt; None:\n    \"\"\"This will inject my code's configuration into the configuration manager for use throughout the app.\"\"\"\n    my_apps_config = {\"some_field\": \"some_value\", \"some_other_field\": \"some_other_value\"}\n\n    test_configuration[\"MyWorkerShip\"] = my_apps_config\n\n# ...\n\ndef test_my_ships_configuration(my_worker_ship_configuration: None) -&gt; None:\n    \"\"\"This tests that the configuration manager has the configuration set by my fixture loaded within it.\"\"\"\n    from starfleet.utils.configuration import STARFLEET_CONFIGURATION\n\n    assert STARFLEET_CONFIGURATION.config[\"MyWorkerShip\"] == {\"some_field\": \"some_value\", \"some_other_field\": \"some_other_value\"}\n    # ^^ This will be True\n</code></pre> <p>Tip</p> <p>You will want to really understand how pytest fixtures work. We use them extensively. Please review the pytest documentation for more details.</p>"},{"location":"developerGuide/primaryComponents/Loggers/","title":"Loggers","text":"<p>We have a common logger that you should make use of throughout Starfleet. This is configured on startup whenever any Python file imports it.</p> <p>To use the logger you need to import it and the interact with it using <code>LOGGER</code>:</p> <pre><code># Import the logger:\nfrom starfleet.utils.logging import LOGGER\n\n# ...\n\n# Use the Logger:\nLOGGER.info(\"[\ud83d\udef8] something to log...\")\n</code></pre> <p>The logger is configured to log out everything in a nice format that appears in the Lambda CloudWatch Logs and should appear nicely in any log aggregation system you want to make use of. Things like the log level and 3rd party loggers to ignore is set in the configuration (details here).</p> <p>Tip</p> <p>One thing you will commonly see throughout the Starfleet codebase are log entries with emojis wrapped in brackets. We just \u2764\ufe0f Emojis here (and believe it or not, it makes it easier to locate entires in a log system \ud83e\udd23)</p> <p>Protip: make a bookmark for https://emojipedia.org/</p> <p>If you want to see the raw code for the logger take a look at <code>starfleet.utils.logging</code>.</p>"},{"location":"developerGuide/primaryComponents/Notifications/","title":"Notifications &amp; Alerts","text":"<p>Starfleet provides a mechanism (via Slack) to emit alerts and notifications. For configuring Slack itself, please reference the User Guide section on that. There are a few components that make this work.</p>"},{"location":"developerGuide/primaryComponents/Notifications/#slack-singleton","title":"Slack Singleton","text":"<p>Like most other major features of Starfleet, we have a singleton that will do most of the work for you for setting up a Slack client. The <code>SLACK_CLIENT</code> object in <code>starfleet.utils.slack</code> interacts with Slack (requires the Secrets Manager component for accessing the <code>SLACK_TOKEN</code>).</p> <p>Don't use the singleton directly</p> <p>Do not use the singleton to interact with Slack. Interacting with Slack for alerts has a different mechanism that is abstracted by the <code>StarfleetWorkerShip</code> class. However, this section defines how this singleton works. The next section <code>Posting Alerts</code> will have the details on how you should be interacting with Slack.</p> <p>Starfleet abstracts (perhaps over abstracts?) the messages that are sent to Slack by sending messages in the following categories:</p> <ol> <li>Information Messages - \u2139\ufe0f - <code>post_info()</code></li> <li>Success Messages - \u2705 - <code>post_success()</code></li> <li>Important Messages - \ud83d\udce3 - <code>post_important()</code></li> <li>Problem Messages - \ud83d\udea8 - <code>post_problem()</code></li> </ol> <p>The code for all of them are effectively the same. How this works is that we will send a markdown formatted message (notice the emojis above) with a title that is prefixed with the emojis above. The singleton's functions (also above) receives the Slack channel ID, the title as a string, and the markdown formatted message to send over. The Slack application token needs to be configured to post messages to the channel ID in question.</p>"},{"location":"developerGuide/primaryComponents/Notifications/#posting-alerts","title":"Posting Alerts","text":"<p>As mentioned, don't use the singleton to interact with Slack. The way that you should be interacting with Slack is by the mechanism built-in to the Starfleet worker ship class (<code>StarfleetWorkerShip</code>). The worker class has a method called <code>send_alert</code>, which takes in a <code>message_priority</code>, <code>title</code>, and the markdown of the body in <code>body_markdown</code>. The code for this is in <code>starfleet.worker_ship.ship_schematics</code> within the <code>StarfleetWorkerShip</code> class.</p> <p>Alerts are only sent out if the user sets up the configuration for the worker to emit the message of a desired priority to a selected Slack channel.</p>"},{"location":"developerGuide/primaryComponents/Notifications/#message-priority","title":"Message Priority","text":"<p>Starfleet's alerting logic is somewhat similar to the Python logging structure, that is to say, that it fits into a hierarchy. The values are defined in the <code>AlertPriority</code> <code>Enum</code> in <code>starfleet.worker_ships.ship_schematics</code>.</p> <p>Here are the values of that enum and the meaning:</p> <pre><code>NONE            # Do not alert anything\nPROBLEM         # Only alert on errors or other items of significance to note (typically used for \"bad\" things)\nIMPORTANT       # For information that is important but not necessarily an error\nSUCCESS         # For information that would highlight that something was successful\nINFORMATIONAL   # For purely informational messages\n</code></pre> <p>The priority is based on the order in the list above. The deeper in the list, the more verbose. This means that if a message alert is coded for <code>IMPORTANT</code>, the worker is configured for <code>PROBLEM</code>, then the alert will not be sent out. Conversely, if the message is coded for <code>IMPORTANT</code>, but the worker is configured for <code>INFORMATIONAL</code>, then the alert will be sent out. By default, a worker is configured for <code>NONE</code>, so no messages are sent out.</p>"},{"location":"developerGuide/primaryComponents/Notifications/#configuration","title":"Configuration","text":"<p>All workers have a configuration entry that allows you to configure Slack alerts that must be present for alerts to be set. This needs to be set for each worker. Each worker has a unique configuration entry for this so that we can have alerts in multiple channels with different priorities set.</p> <p>Each worker Configuration has an optional field called <code>AlertConfiguration</code> that needs to outline the <code>ChannelId</code> and the <code>AlertPriority</code>. Below is copyied and pasted this section from the Configuration section.</p> <ul> <li><code>AlertConfiguration</code> - This is an encompassing dictionary that specifies a Slack channel ID and a message priority for sending alerts to Slack from that worker. This is documented more in the Developer and User guides around Notifications.<ul> <li><code>ChannelId</code> - This is the Slack Channel ID that messages should be sent to</li> <li><code>AlertPriority</code> - This is the <code>AlertPriority</code> enum string. Acceptable values are: <code>NONE</code>, <code>PROBLEM</code>, <code>IMPORTANT</code>, <code>SUCCESS</code>, and <code>INFORMATIONAL</code>.</li> </ul> </li> </ul> <p>If you omit this section, then no Slack alerts will be emitted.</p>"},{"location":"developerGuide/primaryComponents/Notifications/#configuration-example","title":"Configuration Example:","text":"<pre><code>GitHubSyncWorkerShip:\n  Enabled: True\n  TemplatePrefix: GitHubSyncWorkerShip/\n  InvocationQueueUrl: https://sqs.us-east-2.amazonaws.com/SOMEACCOUNTID/starfleet-github-sync-worker\n  InvocationSources:\n    - EVENTBRIDGE_TIMED_EVENT\n    - S3\n  EventBridgeTimedFrequency: FIVE_MIN\n  AlertConfiguration:  # &lt;--- Send messages to Slack\n    ChannelId: C.......\n    AlertPriority: INFORMATIONAL\n</code></pre>"},{"location":"developerGuide/primaryComponents/Notifications/#examples","title":"Examples","text":"<p>Here is an example of this in use:</p> <pre><code>try:\n    worker.execute(commit=commit)\nexcept Exception:\n    message_text = (\n        f\"*Error processing AWS Config template: {worker.payload['template_name']}*\\n\"\n        + f\"*Unable to update the AWS Config configuration in: {worker.payload['starbase_assigned_account']}/{worker.payload['starbase_assigned_region']}.*\\n\\n\"\n        + f\"The exception details are below:\\n```\\n{traceback.format_exc()}```\"\n    )\n    worker.send_alert(AlertPriority.PROBLEM, f\"Problem updating AWS Config properties for template: {worker.payload['template_name']}\", message_text)\n    raise\n</code></pre> <p>In this example, we have the following code:</p> <pre><code>worker.send_alert(AlertPriority.PROBLEM, f\"Problem updating AWS Config properties for template: {worker.payload['template_name']}\", message_text)\n</code></pre> <p>The worker object has the <code>send_alert()</code> function that is inherited from the base <code>StarfleetWorkerShip</code> class. In this example, we are sending an alert to Slack if there was an unhandled exception when executing the AWS Config worker. The <code>message_text</code> is a markdown formatted string. We also pass in the <code>AlertPriority.PROBLEM</code> priority. If the user configures the worker to receive a <code>PROBLEM</code> or above, then the message will be sent to Slack.</p> <p>Here is an example of a Slack alert for a <code>SUCCESS</code> message made by the AWS Config worker: </p> <p>And another example of an <code>IMPORTANT</code> message GitHubSync worker adding files to the template S3 bucket: </p>"},{"location":"developerGuide/primaryComponents/SecretsManager/","title":"Secrets Manager","text":"<p>Starfleet includes a singleton component for interacting with AWS Secrets Manager. This allows you to securely store sensitive details that Starfleet workers can access.</p>"},{"location":"developerGuide/primaryComponents/SecretsManager/#secrets-format","title":"Secrets Format","text":"<p>The secrets are stored as a JSON string in Secrets Manager. It generally follows this format:</p> <pre><code>{\n    \"STARFLEET\": {\n        \"SlackToken\": \"the-token-here\"\n    },\n    \"WORKER_NAME\": \"Any value - this can be a string, nested Dict, etc.\",\n    \"...More Workers Here...\"\n}\n</code></pre> <p>The secret entire secret as shown above is stored as a string in Secrets Manager. A singleton, <code>SECRETS_MANAGER</code> resides in <code>starfleet.utils.secrets</code>, and it will lazy load the secrets when you reference the <code>SECRETS_MANAGER.secrets</code> property, which is a simple Python dictionary.</p> <p>You will also note the <code>SlackToken</code> above under the <code>STARFLEET</code> section of the JSON. That is where the Slack token is used for Slack alerts. Here is a small code snippet of the Slack component referencing the Slack token secret:</p> <pre><code>if not self._web_client:\n    self._web_client = WebClient(token=SECRETS_MANAGER.secrets[\"STARFLEET\"][\"SlackToken\"])\n</code></pre> <p>You simply reference the secret out of the dictionary in the same way that you would for the Starfleet configuration.</p>"},{"location":"developerGuide/primaryComponents/SecretsManager/#configuration-requirement","title":"Configuration Requirement","text":"<p>If you are making use of the Secrets Management component, you have to make sure that the Starfleet configuration is configured to point to it. Under the main <code>STARFLEET</code> stanza of the configuration you need to have the following:</p> <pre><code>  SecretsManager:\n    SecretId: Starfleet        # This is the name of the AWS Secrets Manager secret. The secret must reside in the same AWS account as Starfleet.\n    SecretRegion: us-east-2    # This is the AWS region for where the secret resides.\n</code></pre> <p>IAM Permissions</p> <p>If you make use of the secret, you will need to make sure that the Starfleet worker in question has IAM permissions to access the secret. See the included SAM template for an example of what this should look like.</p> <p>Cached Data Notice</p> <p>Like the other singletons in Starfleet, the loaded data will persist in memory on subsequent runs of the Lambda function. This has the benefit of not needing to make repeated AWS Secrets Manager API calls, which saves money. The downside to this is that AWS will persist the secrets value in memory as long as the container running your Lambda function remains operational (this happens on the AWS backend; you don't have control over it). If you make an update to the secret string, subsequent Lambda calls may not yet see it and you could operate off of the old cached secrets value.</p> <p>AWS will periodically rotate the Lambda container out every few hours if no code has changed. The only way for you to force your Lambda function's container to rotate out is to actually update the code for your Lambda function.</p>"},{"location":"developerGuide/primaryComponents/workerShips/CLI/","title":"CLI - Command Line Interface Plugins","text":"<p>We provide a CLI in Starfleet so that we are able to invoke the workers on demand locally. This assists with debugging and the occasional need to invoke a workload.</p> <p>To make expose CLIs, you need to make use of Click <code>Group</code>s. The <code>AccountIndexGeneratorShip</code> provides an example:</p> <pre><code>@click.group()\ndef account_inventory() -&gt; None:\n    \"\"\"This is the worker ship for generating an S3 account inventory\"\"\"\n\n\n@account_inventory.command()\n@click.option(\"--payload\", required=True, type=click.File(\"r\"), callback=load_payload, help=\"This is the worker payload YAML\")\n@click.option(\"--commit\", is_flag=True, default=False, show_default=True, help=\"Must be supplied for changes to be made\")\ndef generate(payload: Dict[str, Any], commit: bool) -&gt; None:\n    \"\"\"This will generate an AWS account inventory from the organizations API\"\"\"\n    if not commit:\n        LOGGER.warning(\"[\u26a0\ufe0f] Commit flag is disabled: not saving report to S3\")\n\n    worker = AccountIndexGeneratorShip()\n    worker.load_template(payload)\n    worker.execute(commit=commit)\n\n    LOGGER.info(\"[\u2705] Done!\")\n</code></pre> <p>Tip</p> <p>You will really want to get familiar with Click's documentation for groups and commands.</p>"},{"location":"developerGuide/primaryComponents/workerShips/CLI/#the-click-group","title":"The Click <code>Group</code>","text":"<p>All CLI commands are to be a part of a <code>click</code> group. The groups are a collection of commands. The general gist for this is that when the CLI is used, it's going to be: <code>starfleet GROUP COMMAND ARGS</code>.</p> <p>We first make a function that is named as the command group we want. In the example above, we wrap a function named <code>account_inventory</code> with a <code>@click.group()</code> decorator. This will make it so that <code>starfleet account-inventory</code> is a command available (<code>click</code> will substitute underscores (<code>_</code>) with hyphens (<code>-</code>) automatically for you).</p> <p>You can make as many groups as you want. We will discuss later how to make it so that these are loaded on start up.</p>"},{"location":"developerGuide/primaryComponents/workerShips/CLI/#the-click-commands","title":"The Click <code>Command</code>s","text":"<p>You will define the commands themselves with Click commands that are a part of the <code>Group</code>. This is done by making a function that is wrapped with the group function as a decorator like in the example:</p> <pre><code>@account_inventory.command()\n# ...\ndef generate(payload: Dict[str, Any], commit: bool) -&gt; None:\n    # ...\n</code></pre> <p>Put together it's:</p> <p><pre><code>@click.group()\ndef your_group() -&gt; None:\n    pass\n\n@your_group.command()\ndef your_command() -&gt; None:\n    pass\n</code></pre> In this example, the command to execute it is <code>starfleet your-group your-command</code>. You can add in as many commands as you want.</p>"},{"location":"developerGuide/primaryComponents/workerShips/CLI/#recommended-options","title":"Recommended Options","text":"<p>We recommend that you always add a <code>--commit</code> flag to your commands. Please copy and paste:</p> <pre><code>@click.option(\"--commit\", is_flag=True, default=False, show_default=True, help=\"Must be supplied for changes to be made\")\n</code></pre> <p>... and decorate your command with it.</p> <p>We also provide a convenience option for loading a payload YAML file to supply to your worker ship. To use it, copy and paste:</p> <p><pre><code>@click.option(\"--payload\", required=True, type=click.File(\"r\"), callback=load_payload, help=\"This is the worker payload YAML\")\n</code></pre> The main thing here is the <code>callback=load_payload</code>, which does a some work to load the payload. Note: this does not validate the payload; you will still need to do that.</p>"},{"location":"developerGuide/primaryComponents/workerShips/CLI/#general-usage","title":"General Usage","text":"<p>In general, you will want to just copy and paste what we have in the <code>AccountIndexGeneratorShip</code>, which for commands you will always want something that will instantiate the worker ship, load the payload template, and then execute the workload.</p> <p>See above for the example.</p>"},{"location":"developerGuide/primaryComponents/workerShips/LambdaEntrypoints/","title":"Lambda Entrypoints","text":"<p>For the worker ship to do anything, it needs to define the entrypoint for AWS Lambda to invoke it. This is effectively just a function that AWS Lambda will call.</p> <p>We have defined some convenience functions that make this an easy(ier) process. For this, we will take the <code>AccountIndexGeneratorShip</code> as an example:</p> <pre><code>@worker_lambda(AccountIndexGeneratorShip)\ndef lambda_handler(event: Dict[str, Any], context: object, worker: AccountIndexGeneratorShipInstance, commit: bool) -&gt; None:  # noqa pylint: disable=W0613\n    \"\"\"This is the Lambda entrypoint for the AccountIndexGeneratorShip event from the Starbase.\"\"\"\n    for record in event[\"Records\"]:\n        # Load the payload:\n        payload = json.loads(record[\"body\"])\n        LOGGER.debug(f\"[\u2699\ufe0f] Processing Payload: {payload}\")\n        worker.load_template(payload)\n\n        # Process it!\n        worker.execute(commit=commit)\n\n    LOGGER.info(\"[\ud83c\udfc1] Completed generating the account index.\")\n</code></pre> <p>There are a bunch of things to unpack. First: AWS Lambda needs a <code>lambda_handler</code> function. This is what Lambda will call when it wants to invoke your Lambda function. For consistency we should always name our Lambda handler function <code>lambda_handler</code>. There is usually some boilerplate work associated with Lambda and also with Starfleet. It's hard to fully abstract this away, however we are able to make it easy to copy and paste :).</p>"},{"location":"developerGuide/primaryComponents/workerShips/LambdaEntrypoints/#the-decorator","title":"The Decorator","text":"<p>You'll notice in the code above that we make use of a decorator called <code>@worker_lambda</code>. You must use this decorator for your Lambda handler function. What does this do? This is defined in the <code>starfleet.worker_ships.lambda_utils</code> package. This does a number of very nice things for you:</p> <ol> <li>This will automatically load the Starfleet configuration when your worker starts up, and verify that worker's configuration is configured properly</li> <li>This instantiates the worker class</li> <li>This handles the <code>commit</code> flag parsing (see note on that below)</li> <li>This calls out to your Lambda handler function with the AWS Lambda provided event, <code>context</code> object, and your instantiated worker class.</li> </ol> <p>The code for it even has a nice example in the doc strong on how to use this (copying here for convenience):</p> <pre><code>YourWorkerShipInstance = TypeVar(\"YourWorkerShipInstance\", bound=YourStarfleetWorkerShipClass)\n\n\n@worker_lambda(WorkerShipClass)\ndef lambda_handler(event: Dict[str, Any], context: object, worker: YourWorkerShipInstance, commit: bool) -&gt; None:\n    for record in event[\"Records\"]:\n        payload = json.loads(record[\"body\"])\n\n        # Validate the payload: (don't worry about the exception handling -- that is done in the decorator!)\n        LOGGER.debug(f\"[\u2699\ufe0f] Processing Payload: {payload}\")\n        worker.load_template(payload)\n\n        # Process it!\n        worker.execute(commit=commit)\n</code></pre> <p>An important note is that when you wrap your <code>lambda_handler</code> function with the decorator, you need to supply the class (not the instantiation!) into the decorator. I.e. if you have a worker ship class named <code>FooWorkerShip</code>, then your lambda handler will look like this:</p> <pre><code>FooWorkerShipInstance = TypeVar(\"FooWorkerShipInstance\", bound=FooWorkerShip)\n\n@worker_lambda(FooWorkerShip)  # &lt;-- Pass in the worker ship class here\ndef lambda_handler(event: Dict[str, Any], context: object, worker: FooWorkerShipInstance, commit: bool) -&gt; None:\n    # ...\n</code></pre> <p>Once you do that, you get all the benefits you need!</p>"},{"location":"developerGuide/primaryComponents/workerShips/LambdaEntrypoints/#copy-and-paste-time","title":"Copy and Paste Time!","text":"<p>Once you do have the decorated function correct, then you will just want to copy and paste in the <code>for</code> loop, as is. This will handle multiple events being provided by Lambda (you can also configure that in AWS SAM later), and it will verify and load the payload template, and then execute the workload.</p>"},{"location":"developerGuide/primaryComponents/workerShips/Loader/","title":"Worker Ship and CLI Loaders","text":"<p>This section covers how we make it all work! At this point you would have set up a worker ship plugin complete with all the configuration and payload schemas. Great! \ud83c\udf89 But, Starfleet won't yet know about your ship yet. This is where the worker ship loader comes in.</p>"},{"location":"developerGuide/primaryComponents/workerShips/Loader/#make-starfleet-see-your-worker-and-clis","title":"Make Starfleet See Your Worker and CLIs","text":"<p>In your worker ship Python package, you will have an <code>__init__.py</code> file. In that file you must to define the following:</p> <pre><code>WORKER_SHIP_PLUGINS = [YOUR, PLUGIN, CLASSES, HERE]\n</code></pre> <p>If you want to expose CLIs, then in that same <code>__init__</code>.py file, file you must to define the following:</p> <pre><code>CLICK_CLI_GROUPS = [YOUR, CLICK, GROUPS, HERE]\n</code></pre> <p>A great example is the <code>AccountIndexGeneratorShip</code>'s <code>__init__.py</code>, which looks like this:</p> <pre><code>from starfleet.worker_ships.plugins.account_index_generator.ship import AccountIndexGeneratorShip, account_inventory\n\nWORKER_SHIP_PLUGINS = [AccountIndexGeneratorShip]  # NEED TO DEFINE THIS FOR STARFLEET TO KNOW ABOUT YOUR PLUGIN!\nCLICK_CLI_GROUPS = [account_inventory]  # NEED TO DEFINE THIS FOR STARFLEET TO KNOW ABOUT YOUR CLI!\n</code></pre> <p>The <code>WORKER_SHIP_PLUGINS</code> is a list of the worker ship plugin classes that you want Starfleet to see. You can add in as many plugins as you want. Starfleet will locate this list and then register the worker ships to the worker ship loader so that is can be interacted with. This is what will allow the Starbase to actually find your worker ship plugin, and task it.</p> <p>The <code>CLICK_CLI_GROUPS</code> works the exact same way! Only for that, you are adding in the list of Click <code>Group</code> functions. On startup, there is a CLI loader that will pick this up and register all the commands associated with it dynamically.</p>"},{"location":"developerGuide/primaryComponents/workerShips/Loader/#the-worker-ship-loader","title":"The Worker Ship Loader","text":"<p>You don't need to know the full context of this, but it's here should you be interested in knowing.</p> <p>Starfleet has a singleton defined in <code>starfleet.worker_ships.loader</code> called <code>STARFLEET_WORKER_SHIPS</code>. This is a class that will lazy load all the worker ships and verify that worker ship is configured properly and enabled. It does this by iterating through the Python packages that reside in <code>starfleet.worker_ships.plugins</code></p> <p>Calling the <code>STARFLEET_WORKER_SHIPS.get_worker_ships()</code> method returns a dictionary of the worker ship name and the enabled and instantiated worker ship object for interaction.</p> <p>Feel free to dig around the code in <code>starfleet.worker_ships.loader</code> for more details on what that's doing. During unit testing we have a pytest fixture mock out the location of where the worker ships reside to <code>tests.worker_ship_utils.testing_plugins</code>. Take a look at the code in those locations for other examples of very basic Starfleet worker ship plugins.</p>"},{"location":"developerGuide/primaryComponents/workerShips/Loader/#the-cli-loader","title":"The CLI Loader","text":"<p>You also don't need to know the full context of this, but it's provided here for context.</p> <p>This is super similar in concept to the Worker Ship Loader, but is used to register all the Click commands. Starfleet leverages Python entrypoints in combination with Click's support for it. This is defined in <code>pyproject.toml</code> with:</p> <pre><code>[project.scripts]\nstarfleet = \"starfleet.cli.entrypoint:cli\"\n</code></pre> <p>The CLI loader has a class defined in <code>starfleet.cli.entrypoint</code>. This is the main Click group that is used. This is the <code>starfleet ...</code> command. This command group uses a custom class to load up all the CLIs named <code>StarfleetClickGroup</code>. <code>StarfleetClickGroup</code> is a class that sub-classes <code>click.Group</code> (defined in <code>starfleet.cli.components</code>), and it will, on startup:</p> <ol> <li>Output our awesome Starfleet text logo</li> <li>Set up the Starfleet configuration, load it, and verify it's all good</li> <li>Load up all the worker ships, and verify they are all good</li> <li>And then register all the CLI groups and commands to Click</li> </ol> <p>At this point Click will then do the logic required to run your command. All of this is done very quickly and seamlessly for you!</p>"},{"location":"developerGuide/primaryComponents/workerShips/Overview/","title":"Worker Ship Plugins Developer Guide","text":"<p>Worker ship development is such an important section that we made a dedicated section for it!</p> <p>Note</p> <p>Throughout this section we will often refer to the <code>AccountIndexGeneratorShip</code> worker ship plugin that resides in <code>starfleet.worker_ships.plugins.account_index_generator.ship</code> as it's an existing plugin that you can reference that demonstrates all the concepts.</p>"},{"location":"developerGuide/primaryComponents/workerShips/Overview/#worker-ship-residency","title":"Worker Ship Residency","text":"<p>The worker ship plugins must ultimately land in the <code>src/starfleet/worker_ships.plugins/</code> directory (<code>starfleet.worker_ships.plugins.YOUR_PLUGIN</code>).</p> <p>At a minimum, you'll need a <code>__init__.py</code> file. We'll cover more about this file in the Worker Ship Loader portion. For now, just now that you will need a directory that looks like this:</p> <pre><code>...\nworker_ships\n\u2514\u2500\u2500 plugins\n    \u2514\u2500\u2500 your_plugin\n            \u2514\u2500\u2500 __init__.py\n            \u2514\u2500\u2500 some_other_python_file.py\n            \u2514\u2500\u2500 ...\n</code></pre> <p>See the Developer Guide Overview page on more details on packaging non-OSS and internal worker ship plugins.</p>"},{"location":"developerGuide/primaryComponents/workerShips/Overview/#additional-requirements","title":"Additional Requirements","text":"<p>If your worker needs to have additional Python requirements installed, then don't forget you will need to have those added to the <code>requirements.txt</code> file under <code>src/requirements.txt</code>. See the Developer Guide Overview page on more details on packaging non-OSS and internal components.</p>"},{"location":"developerGuide/primaryComponents/workerShips/Overview/#worker-ship-schematics","title":"Worker Ship Schematics","text":"<p>Worker ships are the Lambda functions that go out and do all the work. For them to do this there are a number of components that they define and use. We call these the \"schematics\".</p> <p>All of the Worker Ship Schematics reside in <code>starfleet.worker_ships.ship_schematics</code>. This file defines a bunch of things. We'll go over them one-by-one, but first understand that each \"worker ship\" is nothing more than a plugin. They are plugins that inherit from a Python class and implement an entrypoint for AWS Lambda to invoke it.</p>"},{"location":"developerGuide/primaryComponents/workerShips/Overview/#the-worker-ship-class","title":"The Worker Ship Class","text":"<p>All Starfleet Worker Ship plugins must sub-class the <code>StarfleetWorkerShip</code> class. This class is very simple and serves a few main purposes:</p> <ol> <li>It's used to define the name of the ship - this is the value that is used to locate the ship's configuration entry</li> <li>It's used to define the ship's fan out strategy - i.e. does this worker need to run in all AWS accounts or regions?</li> <li>It's used to define the configuration Marshmallow schema</li> <li>It's used to define the payload Marshmallow schema</li> <li>It has a function to load (and verify) the payload template</li> <li>It has a function that executes a payload</li> </ol>"},{"location":"developerGuide/primaryComponents/workerShips/Overview/#configuration","title":"Configuration","text":"<p>Each worker ship must define a configuration Marshmallow schema. The Marshmallow schema must either directly use or sub-class the <code>WorkerShipBaseConfigurationTemplate</code> class.</p> <p>There are fields here that are required for ALL worker ships, like for example the <code>Enabled</code> field. These are discussed in detail in in the configuration architecture section.</p> <p>You are able to define whatever fields your worker class needs to have a proper configuration. A great example is with the <code>AccountIndexGeneratorShip</code>, which extends the base schema:</p> <pre><code>class AccountIndexGeneratorShipConfigurationTemplate(WorkerShipBaseConfigurationTemplate):\n    \"\"\"The configuration for the AccountIndexGeneratorShip. This largely defines where the Organization root is and the role to assume to query for accounts.\"\"\"\n\n    org_account_assume_role = fields.String(required=True, data_key=\"OrgAccountAssumeRole\")\n    org_account_id = fields.String(required=True, data_key=\"OrgAccountId\")\n    org_root_id = fields.String(required=True, data_key=\"OrgRootId\")  # Needed to list all the OUs. Get from the AWS Orgs console. Starts with `r-...`\n    describe_regions_assume_role = fields.String(required=True, data_key=\"DescribeRegionsAssumeRole\")\n\n# ...\n\nclass AccountIndexGeneratorShip(StarfleetWorkerShip):\n    \"\"\"This is a worker that will periodically dump out a summary of the AWS Organizations accounts to S3.\"\"\"\n    # ...\n    configuration_template_class = AccountIndexGeneratorShipConfigurationTemplate\n</code></pre> <p>In the case of the <code>AccountIndexGeneratorShip</code>, we add configuration options to define which IAM role name we need to assume. We also identify which AWS account is the organization root so that we can assume a role to that account and make the AWS organization API calls.</p> <p>The configuration will be validated when the worker ship plugin is loaded. This is discussed later.</p>"},{"location":"developerGuide/primaryComponents/workerShips/Overview/#fan-out-strategy","title":"Fan Out Strategy","text":"<p>Each worker must define the fan out strategy that it uses. I.e. is this a workload that just needs to run once? Then it should be set for <code>FanOutStrategy.SINGLE_INVOCATION</code>. If it needs to be set per-account, then it needs to be set to <code>FanOutStrategy.ACCOUNT</code>. If this needs to run on every account/region pair then it should be set to <code>FanOutStrategy.ACCOUNT_REGION</code>.</p> <p>By default the base worker class sets this to <code>FanOutStrategy.SINGLE_INVOCATION</code>.</p>"},{"location":"developerGuide/primaryComponents/workerShips/Overview/#payload-template","title":"Payload Template","text":"<p>The payload template is used to inform the worker on how to do the actual job in question. This is a necessity when running in multiple accounts or regions where there are unique things to do.</p> <p>Each worker ship must define a payload Marshmallow schema. The Marshmallow schema must either directly use or sub-class one of the Base Payload Template classes, which are located in <code>starfleet.worker_ships.base_payload_schemas</code>. All the schemas will ultimately sub-class <code>WorkerShipPayloadBaseTemplate</code>.</p> <p>If you are making a Starfleet worker that needs to have a Fan-Out Strategy of <code>SINGLE_INVOCATION</code>, then having your payload template schema sub-class off of <code>WorkerShipPayloadBaseTemplate</code> is appropriate. However, if you are using <code>ACCOUNT</code>, then your payload template schema must sub-class off of <code>BaseAccountPayloadTemplate</code>, or <code>BaseAccountRegionPayloadTemplate</code> for <code>ACCOUNT_REGION</code>.</p> <p>Like with the configuration, you can define whichever fields you want for your worker to do the job. A great example is with the <code>AccountIndexGeneratorShip</code>, which extends the <code>WorkerShipPayloadBaseTemplate</code> schema as it's a <code>SINGLE_INVOCATION</code> worker:</p> <pre><code>class AccountIndexGeneratorShipPayloadTemplate(WorkerShipPayloadBaseTemplate):\n    \"\"\"The payload for the AccountIndexGeneratorShip. This largely defines the S3 buckets to dump the report to.\"\"\"\n\n    account_inventory_bucket = fields.String(required=True, data_key=\"AccountInventoryBucket\")\n    inventory_bucket_region = fields.String(required=True, data_key=\"InventoryBucketRegion\")\n    inventory_object_prefix = fields.String(required=False, data_key=\"InventoryObjectPrefix\", load_default=\"accountIndex.json\")\n\n# ...\n\nclass AccountIndexGeneratorShip(StarfleetWorkerShip):\n    \"\"\"This is a worker that will periodically dump out a summary of the AWS Organizations accounts to S3.\"\"\"\n    # ...\n    payload_template_class = AccountIndexGeneratorShipPayloadTemplate\n</code></pre>"},{"location":"developerGuide/primaryComponents/workerShips/Overview/#payload-execution","title":"Payload Execution","text":"<p>Before a payload can be executed (AKA do the work that is tasked), the worker ship needs to be instantiated with a validated payload.</p> <p>We'll discuss how the worker class gets instantiated in the next section, but for now know that when a worker is instantiated, it will validate the payload by calling the super class <code>load_template(payload)</code> method, which will keep the payload stored as an attribute that is accessible by calling <code>self.payload</code>. The payload will be a regular Python dictionary that is indexed by the Python snake_case field names. The <code>load_template</code> method de-serializes the Marshmallow schema into a dictionary. As mentioned below in the important notes section, the payload is intended to have whatever Marshmallow mutations you want to have on it for the convenience of the developer making the worker ship plugins.</p> <p>Important</p> <p>The worker references its payload attributes based on what the Python template field names (snake_case) are vs. the YAML field names (UpperCamelCase). This is because the stored payload for the worker is the deserialized Marshmallow dictionary. We decided to do this so that the payload schema can perform whatever modifications and mutations are needed to be usable by the worker ship.</p> <p>Once the template is loaded, then the code in the <code>execute</code> method an be performed. This is where all the logic should reside to do the job that is needed to be done. The <code>execute</code> method takes in a <code>commit</code> boolean flag argument. It is highly desireable for you to design your workloads with both a read-only and write-mode capability. If the <code>commit</code> flag passed in is false, then your code should not make any changes and just output what it would do if the <code>commit=True</code> flag were set.</p>"},{"location":"developerGuide/primaryComponents/workerShips/Overview/#exception-handling","title":"Exception Handling?","text":"<p>Because Starfleet is based on Lambda with SQS invocation, we want our functions to be as stateless and idempotent as possible. That doesn't mean you have to make them stateless, but we strongly recommend it. It's totally OK to allow exceptions encountered to be raised to the top so that the Lambda can re-try. It's normal for you to sometimes have an unhealthy Lambda invocation. Fortunately, if you design your Lambda payload execution to be stateless and idempotent, then it will happily retry and should hopefully work well on the next invocation.</p>"},{"location":"developerGuide/primaryComponents/workerShips/Overview/#important-notes","title":"Important Notes","text":"<p>Configuration or Payload Template?</p> <p>When should you use the configuration or the payload template to define something the worker needs? This is something you may be thinking about.</p> <p>Our guidance is that if this is something that each and every Lambda invocation needs to do its job properly, then it should reside in the configuration YAML. Otherwise, it should reside in the payload template.</p> <p>Also, the configuration should not contain Marshmallow mutations. The configuration is referenced based on what the values look like in the YAML. The configuration is merely validated and loaded. However, the Payload is referenced based on what the values are in the loaded schema. Feel free to make whatever Marshmallow mutations you want on the payload.</p> <p>Styling the Configuration and Payloads</p> <p>We want to be consistent with styling our templates. We want YAML field names to be written in UpperCamelCase, but the raw Python code to be written in snake_case.</p> <p>This is easily achievable in Marshmallow templates. Define the fields in snake_case but then in the <code>fields.TYPE()</code> call, set the <code>data_key=</code> key word argument to the UpperCamelCase name. For example: <code>org_account_assume_role = fields.String(required=True, data_key=\"OrgAccountAssumeRole\")</code></p> <p>Special Note</p> <p>When you are specifying the schemas that the worker ship class uses for both the configuration and the payload, you are setting the value to a class not an instantiation of the class. For example:</p> <pre><code># Correct \u2705\npayload_template_class = AccountIndexGeneratorShipPayloadTemplate    # &lt;-- You are referencing the class itself\n\n# Wrong \u274c\npayload_template_class = AccountIndexGeneratorShipPayloadTemplate()  # &lt;-- We are not instantiating yet\n</code></pre>"},{"location":"installation/IAM/","title":"Set up IAM Roles","text":"<p>Starfleet needs IAM roles present in all accounts that it needs to operate in. Starfleet operates in a hub-spoke type of model where Starfleet Lambda functions are deployed with IAM roles that can assume role to the target account Starfleet worker roles.</p> <p>At this time, we recommend the use of CloudFormation StackSets to set up the initial IAM role that Starfleet will need to use organization wide. We provide an example below of a CloudFormation StackSet template that deploys an IAM role Starfleet workers are able to assume across all your accounts in your organization.</p>"},{"location":"installation/IAM/#starfleet-account-resident-roles","title":"Starfleet Account Resident Roles","text":"<p>You don't need to worry too much about this until the SAM deployment, but for now, we'll describe what IAM permissions the Starfleet worker roles need. The gist is that it mostly needs to be able to <code>sts:AssumeRole</code> on <code>arn:aws:iam::*:starfleet*</code>. The SAM template provides this via a Managed Policy that is attached to each SAM created worker role like this:</p> <pre><code>  AssumeRoleManagedPolicy:\n    Type: AWS::IAM::ManagedPolicy\n    DependsOn:\n      - AccountIndexGenerator\n    Properties:\n      Description: Grants Starfleet workers assume role permissions to common Starfleet worker IAM roles\n      ManagedPolicyName: StarfleetWorkerAssumeRoles\n      PolicyDocument:\n        Version: \"2012-10-17\"\n        Statement:\n          - Effect: Allow\n            Action: 'sts:AssumeRole'\n            Resource:\n              - !Sub\n                - 'arn:aws:iam::*:role/${RoleName}'\n                - RoleName: !FindInMap\n                    - EnvMap\n                    - !Ref 'EnvironmentName'\n                    - BaseRoleName\n      Roles:\n        - !Ref AccountIndexGeneratorRole  # AccountIndexGeneratorRole is created automatically by SAM and can be referenced\n        # -!Ref YourWorkerRoleHere # Add your worker roles here to get the policy attached\n</code></pre> <p>Don't worry too much about the specifics of the above policy. The main point to know is that the worker Lambda functions need IAM roles in all the accounts, which the worker Lambdas can assume, that contain the required permissions in those accounts to perform the actions that need to be performed. We recommend utilizing CloudFormation StackSets to do this. An example of a CloudFormation StackSet template to create the account resident roles is below (we assume that you do this for the rest of the guide):</p> <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nDescription: CloudFormation StackSet for the base Starfleet IAM worker roles deployed to all accounts\nResources:\n  StarfleetWorkerBasicTestRole:\n      Type: AWS::IAM::Role\n      Properties:\n        AssumeRolePolicyDocument:\n          Version: '2012-10-17'\n          Statement:\n            - Effect: Allow\n              Principal:\n                AWS:\n                  - arn:aws:iam::STARFLEET-PRODUCTION-ACCOUNT:root  # ADD THE STARFLEET PROD ACCOUNT ID IN\n                  - arn:aws:iam::STARFLEET-TEST-ACCOUNT:root        # ADD THE STARFLEET TEST ACCOUNT ID IN\n              Action: sts:AssumeRole\n              Condition:\n                ArnLike:\n                  aws:PrincipalArn:\n                    - 'arn:aws:iam::STARFLEET-PRODUCTION-ACCOUNT:role/starfleet*'  # SAME\n                    - 'arn:aws:iam::STARFLEET-TEST-ACCOUNT:role/starfleet*'        # SAME\n                    - 'SOME-ARN-TO-AN-IAM-ROLE-YOU-WANT-TO-ASSUME-FOR-LOCAL-DEVELOPMENT-AND-CLI-DEBUGGING-HERE'  # SEE NOTE BELOW\n        Description: Account-resident role for the Test Starfleet stack to assume - permissions are only read-only\n        RoleName: starfleet-worker-basic-test-role\n        Policies:\n            # The policies below are used for the AccountIndexGenerator to obtain all the regions that an AWS account supports.\n          - PolicyName: ec2\n            PolicyDocument:\n              Version: '2012-10-17'\n              Statement:\n                - Sid: GetEnabledRegions\n                  Effect: Allow\n                  Action: ec2:DescribeRegions\n                  Resource: '*'\n        Tags:\n          - Key: ADD-HERE\n            Value: Add whatever tags you want here.\n\n  StarfleetWorkerBasicProdRole:\n      Type: AWS::IAM::Role\n      Properties:\n        AssumeRolePolicyDocument:\n          Version: '2012-10-17'\n          Statement:\n            - Effect: Allow\n              Principal:\n                AWS:\n                    - arn:aws:iam::STARFLEET-PRODUCTION-ACCOUNT:root   # ADD THE STARFLEET PROD ACCOUNT ID IN\n              Action: sts:AssumeRole\n              Condition:\n                ArnLike:\n                  aws:PrincipalArn:\n                    - 'arn:aws:iam::STARFLEET-PRODUCTION-ACCOUNT:role/starfleet*'  # SAME\n                    - 'SOME-ARN-TO-AN-IAM-ROLE-YOU-WANT-TO-ASSUME-FOR-LOCAL-DEVELOPMENT-AND-CLI-DEBUGGING-HERE'  # SEE NOTE BELOW\n        Description: Account-resident role for the Prod Starfleet stack to assume\n        RoleName: starfleet-worker-basic-prod-role\n        Policies:\n          - PolicyName: ec2\n            PolicyDocument:\n              Version: '2012-10-17'\n              Statement:\n                - Sid: GetEnabledRegions\n                  Effect: Allow\n                  Action: ec2:DescribeRegions\n                  Resource: '*'\n        Tags:\n          - Key: ADD-HERE\n            Value: Add whatever tags you want here.\n</code></pre> <p>Important Tip about the Organization Root Account</p> <p>If you do decide to go with the CloudFormation StackSets route, you need to keep in mind that StackSets will NOT deploy to the Organization Root account. If you do choose to use StackSets, you will need to manually create an IAM role in the organization root account that has the exact same permissions as what is documented in the StackSet YAML above.</p> <p>Note</p> <p>If you leverage the <code>AccountIndexGeneratorShip</code> worker ship for your AWS account inventory (recommended), you will need to make sure that the Starfleet IAM roles in the Organization Root account has the following permissions (in addition to the permissions you grant to the other worker roles):</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                [\n                  \"organizations:Describe*\",\n                  \"organizations:List*\"\n                ]\n            ]\n            \"Resource\": \"*\"\n        }\n    ]\n}\n</code></pre> <p>When using StackSets, you will want to ensure that this is applied to all accounts and to automatically create the apply the stack to newly added accounts in the organization (see AWS documentation here).</p> <p>IAM is a global resource within an AWS account, as such, you should only have the StackSet target 1 region, like <code>us-east-1</code>.</p> <p>Local Development Credentials</p> <p>In the StackSet YAML above, you will see: <pre><code>SOME-ARN-TO-AN-IAM-ROLE-YOU-WANT-TO-ASSUME-FOR-LOCAL-DEVELOPMENT-AND-CLI-DEBUGGING-HERE\n</code></pre></p> <p>This should be some IAM role/user/whatever that you are able to obtain credentials for that is allowed to <code>sts:AssumeRole</code> this role. You will need this to run the Starfleet CLI since that will need to perform the role assumption logic to perform whatever the worker does in AWS, but locally on your computer.</p> <p>If you use AWS SSO, and have permissions set named <code>Administrator</code>, and it's applied to your account with <code>sts:AssumeRole</code> permissions to either <code>arn:aws:iam::*:starfleet*</code> or just <code>*</code>, then the ARN above would be something along the lines of: <pre><code>arn:aws:iam::STARFLEET-ACCOUNT-ID:role/aws-reserved/sso.amazonaws.com/AWSReservedSSO_Administrator_*\n</code></pre></p>"},{"location":"installation/IAM/#deployment-with-aws-sam","title":"Deployment with AWS SAM","text":"<p>Once you have sorted out which AWS account(s) you want to use for Starfleet, and have rolled out base worker IAM roles in all accounts, you then need to update the configuration, prep the account index, and then use AWS SAM to deploy all the resources. This is documented in the next sections.</p> <p>At this point, you should have the following before you can move forward:</p> <ul> <li> Enable AWS Organizations if you haven't already done so and move some accounts into it</li> <li> Pick out an AWS account for deploying a testing version of Starfleet</li> <li> Work on getting a read-only Starfleet IAM role deployed with the permissions outlined above in all your AWS accounts. This role is not very permissive and is only able to describe the enabled regions for an account.<ul> <li> In the organization root, it has permissions to list the Organizations accounts.</li> <li> If you use StackSets then you need to manually make the role in the org root since StackSets won't operate in the org root.</li> <li> Important: Make sure that you have some IAM principal that you can use locally that can assume all these roles. This will be needed to run the Starfleet CLI. If you use AWS SSO, then use the ARN for the permissions set provisioned administrative role in the Starfleet account. See the note above for an example.</li> </ul> </li> <li> Starfleet worker IAM roles deployed everywhere</li> </ul>"},{"location":"installation/MakeAccountIndex/","title":"Make the Account Index","text":"<p>It's now time to make the account index via the Starfleet CLI. After you run the CLI to get the account index working, Starfleet should just work.</p> <p>The instructions below are very similar to what's in the Developer Guide, but are pasted here for convenience.</p>"},{"location":"installation/MakeAccountIndex/#set-up-python-environment","title":"Set Up Python Environment","text":"<p>You'll need a proper Python 3 environment set up. We recommend using pyenv. Starfleet uses the latest version of Python 3 that is supported by AWS Lambda. You will want to have that installed and configured.</p>"},{"location":"installation/MakeAccountIndex/#set-up-virtual-environment","title":"Set Up Virtual Environment","text":"<p>Always make use of a python virtual environment with Starfleet. Always.</p> <p>To get started you will make a virtual environment:</p> <pre><code># Git clone the repo ... (recommended you make a fork on GitHub and pull from that for development -- you\n#                         can also add the upstream repository as a remote with\n#                         `git remote add upstream git@github.com:gemini-oss/starfleet.git` followed by `git fetch --all`)\ncd starfleet/\npython3 -m venv venv\nsource venv/bin/activate\n</code></pre> <p>After running the above you now have a working virtual environment.</p> <p>Warning</p> <p>Make sure that everything you run is within this virtual environment! You can always get back into it by running <code>source venv/bin/activate</code>.</p>"},{"location":"installation/MakeAccountIndex/#install-the-dependencies","title":"Install The Dependencies","text":"<p>Once you have your virtual environment created and activated, you are now ready to install the package and the dependencies:</p> <pre><code># Install the main starfleet components with dependencies:\npip install -e .\n\n# Install the test components:\npip install -e .\"[tests]\"\n</code></pre>"},{"location":"installation/MakeAccountIndex/#test-it","title":"Test It!","text":"<p>You can test that it's all working by running <code>tox</code>:</p> <p><pre><code>tox\n# ... a lot of output ...\n</code></pre> If you see errors about tests failing then there is a problem! The command at the end should say something along the lines of:</p> <pre><code>  py39: OK (10.14=setup[3.61]+cmd[6.53] seconds)\n  lint: OK (9.69=setup[2.83]+cmd[0.83,0.40,5.63] seconds)\n  congratulations :) (19.88 seconds)\n</code></pre>"},{"location":"installation/MakeAccountIndex/#run-the-cli","title":"Run the CLI","text":"<p>Once you are in the virtual environment then you are now ready to run Starfleet's account index generator. For reference:</p> <pre><code>(venv) your_username starfleet % starfleet account-inventory generate --help\nUsage: starfleet account-inventory generate [OPTIONS]\n\n  This will generate an AWS account inventory from the organizations API\n\nOptions:\n  --payload FILENAME  This is the worker payload YAML  [required]\n  --commit            Must be supplied for changes to be made  [default:\n                      False]\n  --help              Show this message and exit.\n</code></pre> <ol> <li>Remember we mentioned that you should have IAM credentials that allow you to assume the Starfleet roles? You need to obtain those credentials and export them into your environment. This is required so that you can run as Starfleet!</li> <li>Remember you made that payload template for the Account Index generator? You are going to use that now!</li> <li>Remember you set up the configuration for Starfleet? It comes into play here!</li> <li>Run the cli!:     <pre><code># Activate your virtual environment: source venv/bin/activate\n# export your AWS credentials...\nstarfleet account-inventory generate --payload path/to/your/payload.yaml --commit\n</code></pre></li> </ol> <p>If it's all working, then you should see: <pre><code>2023-03-17 14:39:21,073 - INFO - [\ud83e\udea3] Saving the report as accountIndex.json in starfleet-templates-YOUR-ACCOUNT-ID - /path/to/starfleet\n2023-03-17 14:39:21,932 - INFO - [\u2705] Done! - /path/to/starfleet\n</code></pre></p> <p>Once this is in S3, then the last step is for you to upload that payload YAML to your S3 bucket in the prefix that is configured in your <code>configuration.yaml</code>.</p> <p>At this point you should be done with test and you would want to repeat the steps for prod. All these things should be done:</p> <ul> <li> Enable AWS Organizations if you haven't already done so and move some accounts into it</li> <li> Pick out an AWS account for deploying a testing version of Starfleet</li> <li> Work on getting a read-only Starfleet IAM role deployed with the permissions outlined above in all your AWS accounts. This role is not very permissive and is only able to describe the enabled regions for an account.<ul> <li> In the organization root, it has permissions to list the Organizations accounts.</li> <li> If you use StackSets then you need to manually make the role in the org root since StackSets won't operate in the org root.</li> <li> Important: Make sure that you have some IAM principal that you can use locally that can assume all these roles. This will be needed to run the Starfleet CLI. If you use AWS SSO, then use the ARN for the permissions set provisioned administrative role in the Starfleet account. See the note above for an example.</li> </ul> </li> <li> AWS Account identified for deployment</li> <li> Starfleet worker IAM roles deployed everywhere</li> <li> The <code>configuration.yaml</code> file in <code>src/starfleet/configuration_files</code> modified with values unique to your environment</li> <li> A payload template (not stored as a configuration file) in a different place than your configuration that describes what the Starfleet Account Index Generator is supposed to do</li> <li> AWS SAM:<ul> <li> SAM's administrative resources deployed</li> <li> SAM's TEST deployment configuration all set up</li> <li> Starfleet deployed in your environment</li> </ul> </li> <li> And now: You set up a local development environment</li> <li> And now: You now have an account index JSON file in the account index S3 bucket</li> <li> Your test Starfleet deploying is all set and working! (hopefully)</li> </ul> <p>The next steps are to wrap things up.</p>"},{"location":"installation/Overview/","title":"Installation Guide","text":"<p>Warning</p> <p>Starfleet is a very sophisticated tool geared towards security and infrastructure engineers with AWS and software development experience. A lot of the instructions are geared towards that audience and in some cases, you may need to roll up your sleeves.</p> <p>This page is a guide for installing Starfleet. Our instructions are generally geared around AWS SAM. If you haven't already, please install the AWS SAM CLI.</p> <p>There are other components that are not covered by SAM, like the Starfleet IAM role, which is also discussed.</p>"},{"location":"installation/Overview/#included-components","title":"Included components","text":"<p>Separate docs exist for each included worker ship, but for the purposes of installation, the following are the minimum installed components:</p> <ol> <li>Starfleet account resident IAM roles</li> <li>The Starbase Lambda Functions</li> <li>The <code>AccountIndexGeneratorShip</code>, which is a worker ship that generates an AWS account inventory by assuming a role in the Organization Root account, listing all the accounts, then fetching specific details about each account, and then finally saves the result as a JSON file to an S3 bucket.</li> <li>The <code>StarfleetDefaultAccountIndex</code>, which is an Account Indexer that relies on the generated JSON file produced by the <code>AccountIndexGeneratorShip</code>.</li> <li>AWS resources like the SQS Queues, the template S3 bucket, the account index bucket, the EventBridge events, and all the Starfleet Lambda IAM roles</li> </ol> <p>Most of these are created with AWS SAM template, but some sleeve rolling is required for several of the others.</p>"},{"location":"installation/Overview/#sam-template-summary","title":"SAM Template Summary","text":"<p>AWS SAM templates are YAML files that are effectively CloudFormation templates with some additional (very nice) abstractions. SAM will also manage the building and uploading of artifacts to S3 so that CloudFormation can properly deploy your Lambdas.</p> <p>Included in the base repository directory <code>starfleet/</code> is a sample SAM template named <code>test_sam_template.yaml</code>. The SAM template outlines the primary components, like the SQS queues, the template S3 bucket, the Starbase Lambdas, and the worker Lambda functions.</p> <p>However, before deploying anything with AWS SAM, please review the Prerequisites below.</p>"},{"location":"installation/Overview/#prerequisites","title":"Prerequisites","text":"<p>Before deployment you need to review the following 3 things:</p> <ol> <li>AWS Organizations is enabled and used</li> <li>The AWS account for Starfleet deployment</li> <li>IAM roles used by Starfleet</li> </ol>"},{"location":"installation/Overview/#starfleet-aws-accounts","title":"Starfleet AWS Account(s)","text":"<p>Starfleet is a security sensitive tool with powerful capabilities that can operate across your entire cloud infrastructure. As such, you will want to have this live in a security sensitive account with few co-tenant applications.</p> <p>It is also recommended to have an account for a test version of Starfleet. This guide assumes that you have 2 accounts, a separate testing and production account, that you can deploy a testing and production Starfleet to.</p> <p>Warning</p> <p>Starfleet is a very privileged application. It is intended to operate over your entire AWS cloud infrastructure. Please place it in an Account with limited access and few other deployed applications.</p> <p>Our default account inventory makes the assumption that you are making use of AWS organizations and have your accounts registered with it (seriously, you need to do this if you haven't already).</p> <p>Before you can move forward, you will need to do the following:</p> <ul> <li> Enable AWS Organizations if you haven't already done so and move some accounts into it</li> <li> Pick out an AWS account for deploying a testing version of Starfleet</li> </ul>"},{"location":"installation/PrepareConfiguration/","title":"Prepare Configuration For Installation","text":"<p>Starfleet needs a proper configuration to function properly. Let's revisit the main configuration for Starfleet. As mentioned in the Architecture section, all the configuration files are YAML files that reside in <code>src/starfleet/configuration_files/</code>.</p> <p>We include a sample <code>configuration.yaml</code> file that contains 3 stanzas, one for <code>STARFLEET</code>, one for the <code>AccountIndexGeneratorShip</code>, and one for the <code>StarfleetDefaultAccountIndex</code>. The included file is very heavily documented and it should be self-explanatory. The configuration file is set up to conform to what is included in the provided AWS SAM template.</p> <ol> <li>Open the <code>src/starfleet/configuration_files/configuration.yaml</code> file in your favorite text editor.</li> <li>Go through and update the values of that file accordingly. For the <code>TemplatePrefix</code> under the <code>AccountIndexGeneratorShip</code> we are going to make that file in the next section. The default value set is perfect: <code>AccountIndexGenerator/SaveAccountInventory.yaml</code>.</li> <li>Save the changes</li> </ol> <p>At this point you should now have:</p> <ul> <li> Enable AWS Organizations if you haven't already done so and move some accounts into it</li> <li> Pick out an AWS account for deploying a testing version of Starfleet</li> <li> Work on getting a read-only Starfleet IAM role deployed with the permissions outlined above in all your AWS accounts. This role is not very permissive and is only able to describe the enabled regions for an account.<ul> <li> In the organization root, it has permissions to list the Organizations accounts.</li> <li> If you use StackSets then you need to manually make the role in the org root since StackSets won't operate in the org root.</li> <li> Important: Make sure that you have some IAM principal that you can use locally that can assume all these roles. This will be needed to run the Starfleet CLI. If you use AWS SSO, then use the ARN for the permissions set provisioned administrative role in the Starfleet account. See the note above for an example.</li> </ul> </li> <li> Starfleet worker IAM roles deployed everywhere</li> <li> And now: the <code>configuration.yaml</code> file in <code>src/starfleet/configuration_files</code> modified with values unique to your environment</li> </ul>"},{"location":"installation/PreparePayload/","title":"Prepare a Payload Template","text":"<p>We are going to create a payload template for the <code>AccountIndexGeneratorShip</code> plugin so that we can generate the account index.</p> <p>Important Note for Now</p> <p>Starfleet will have a chicken and egg problem: it requires an account index to function. But there is also a worker that makes an account index. The account index worker can't run unless an account index exists.</p> <p>We will solve that problem by running the CLI to generate that index after we perform a deployment. For now don't worry about this and just focus on making a payload template. All of this will come together in the next sections! We promise! :)</p> <ol> <li>Open your favorite text editor and you are going to create a new file. We will revisit this file so keep it somewhere you can reference to later.</li> <li>We are going to name this file: <code>SaveAccountInventory.yaml</code></li> <li>In this file, copy and paste in the following, which is a payload template that will inform the <code>AccountIndexGeneratorShip</code> with additional details on how and where to save the account index:     <pre><code>TemplateName: AccountIndexGeneratorShip\nTemplateDescription: The Account Index Generator Worker Ship template\nAccountInventoryBucket: starfleet-account-index-DEPLOYMENT-ACCOUNT-ID\nInventoryBucketRegion: DEPLOYMENT-REGION\n</code></pre></li> <li>In that file, replace the <code>DEPLOYMENT-ACCOUNT-ID</code> and <code>DEPLOYMENT-REGION</code> with the AWS account ID for your deployment and region, and save the file.</li> </ol> <p>Why do we need the payload template for this?</p> <p>In case you are wondering \"why\" we need a payload template for this worker, the payload template tells the worker which S3 bucket to save the index to. It also tells the worker and what to call the index file (by default it uses <code>accountIndex.json</code>). This makes this super flexible. Let's say you want to dump multiple indexes to multiple S3 buckets and prefixes. You can do that! Just make a separate payload template to describe that action and it will be done!</p> <p>However, for now, we are just setting this up to be consistent with what the AWS SAM template is doing, which is going to address 99.99% of use cases.</p> <p>At this point you should now have:</p> <ul> <li> Enable AWS Organizations if you haven't already done so and move some accounts into it</li> <li> Pick out an AWS account for deploying a testing version of Starfleet</li> <li> Work on getting a read-only Starfleet IAM role deployed with the permissions outlined above in all your AWS accounts. This role is not very permissive and is only able to describe the enabled regions for an account.<ul> <li> In the organization root, it has permissions to list the Organizations accounts.</li> <li> If you use StackSets then you need to manually make the role in the org root since StackSets won't operate in the org root.</li> <li> Important: Make sure that you have some IAM principal that you can use locally that can assume all these roles. This will be needed to run the Starfleet CLI. If you use AWS SSO, then use the ARN for the permissions set provisioned administrative role in the Starfleet account. See the note above for an example.</li> </ul> </li> <li> AWS Account identified for deployment</li> <li> Starfleet worker IAM roles deployed everywhere</li> <li> The <code>configuration.yaml</code> file in <code>src/starfleet/configuration_files</code> modified with values unique to your environment</li> <li> And now: a payload template (not stored as a configuration file) in a different place than your configuration that describes what the Starfleet Account Index Generator is supposed to do</li> </ul>"},{"location":"installation/RunSAM/","title":"Run AWS SAM","text":"<p>Now you are ready to run AWS SAM and get the infrastructure components deployed! To do this you should follow the instructions to get the AWS SAM CLI installed on your system. Also note, you will also need to build Starfleet in a docker container to properly install all the dependencies (this is doable via the SAM CLI as we'll discuss below.)</p> <p>Help Wanted!</p> <p>This section could use some assistance from the community for simplifying the installation process and documentation. We would love for assistance on the creation of things like an installation script, for example that would set all of this up for you.</p>"},{"location":"installation/RunSAM/#the-test-template","title":"The Test Template","text":"<p>We include a file called <code>test_sam_template.yaml</code> (for ECR) and <code>test_sam_template_NO_ECR.yaml</code>(for non-ECR), so you can later clone it for production with production specific values in. The commands below will assume that the template is named <code>test_sam_template.yaml</code>.</p>"},{"location":"installation/RunSAM/#build-starfleet","title":"Build Starfleet","text":"<p>To build the code, in the main checked out directory you will run:</p> <p>If you are using ECR: <pre><code>sam build --template-file test_sam_template.yaml --parameter-overrides ParameterKey=EnvironmentName,ParameterValue=TEST\n</code></pre></p> <p>If you are not using ECR: <pre><code>sam build --use-container --template-file test_sam_template.yaml --parameter-overrides ParameterKey=EnvironmentName,ParameterValue=TEST\n</code></pre></p> <p>If all is good, it should say at the end: <code>Build Succeeded</code>.</p>"},{"location":"installation/RunSAM/#fetch-aws-credentials","title":"Fetch AWS Credentials","text":"<p>You will need administrative AWS credentials in your environment that is able to create resources. You will need a lot of permissions as this will create IAM roles and also create S3 buckets, along with other resources.</p> <p>You will need to ensure that these credentials are present in your environment, i.e. export the environment variables.</p>"},{"location":"installation/RunSAM/#prepare-sam-components","title":"Prepare SAM Components","text":"<p>SAM requires that there be some components in AWS. The best way to provide this is to follow the instructions for a <code>guided deploy</code>.</p>"},{"location":"installation/RunSAM/#first-time-running","title":"First time running","text":"<p>You can do that by running the command: <pre><code>sam deploy --guided --template-file test_sam_template.yaml --parameter-overrides ParameterKey=EnvironmentName,ParameterValue=TEST\n</code></pre></p> <p>During this stage, it will attempt to create a <code>samconfig.toml</code> file (more on that below). Follow the instructions and you will want to have the following values generally set:</p> <pre><code>        Setting default arguments for 'sam deploy'\n        =========================================\n        Stack Name [sam-app]: starfleet\n        AWS Region [us-east-1]: ADD YOUR REGION HERE\n        Parameter EnvironmentName [TEST]: TEST or PROD -- Use TEST for now\n        #Shows you resources changes to be deployed and require a 'Y' to initiate deploy\n        Confirm changes before deploy [y/N]: y  # Choose Yes (Y)\n        #SAM needs permission to be able to create roles to connect to the resources in your template\n        Allow SAM CLI IAM role creation [Y/n]:  # Choose Yes (Y)\n        #Preserves the state of previously provisioned resources when an operation fails\n        Disable rollback [y/N]: N  # Choose No (N)\n        Save arguments to configuration file [Y/n]:  # Choose Yes (Y)\n        SAM configuration file [samconfig.toml]:  # Just press enter for the default.\n        SAM configuration environment [default]: TEST  # TEST or PROD -- Use TEST for now\n</code></pre> <p>This should try to create an S3 bucket (if prompted, choose Yes). Let SAM create the AWS managed resources required. This will allow SAM to do whatever it needs to do to get your resources deployed. However, there will be an error when you deploy for the first time, this is expected because of an annoying CloudFormation issue: and that issue is <code>capabilities</code>.</p>"},{"location":"installation/RunSAM/#update-the-sam-configuration","title":"Update the SAM configuration","text":"<p>We need to update the SAM configuration, manually, to allow it to create IAM resources. You have to edit the <code>samconfig.toml</code> file, locate the <code>capabilities</code> variable and set it to:</p> <pre><code>[TEST.deploy.parameters]\n# ...\ncapabilities = [\"CAPABILITY_IAM\", \"CAPABILITY_NAMED_IAM\"]\nimage_repository = \"YOUR_ACCOUNT_ID.dkr.ecr.YOUR_REGION.amazonaws.com/REPO_NAME -- if you are using ECR\"\n\n[TEST.validate.parameters]\nregion = \"YOUR_REGION_HERE\"\ntemplate_file = \"test_sam_template.yaml\"\nlint = true\n\n[TEST.build.parameters]\nuse_container = true\ntemplate_file = \"test_sam_template.yaml\"\n</code></pre> <p>It's recommended that you copy and paste in the other fields above too.</p>"},{"location":"installation/RunSAM/#validate-its-all-good","title":"Validate It's All Good","text":"<p>You will next want to run a validation, which will do some stuff to kind of sort of validate the template, and it uses an IAM role that SAM creates to do it. After you updated the SAM config, you can now run:</p> <pre><code>sam validate --config-env TEST\n# Notice the --config-env parameter. This will rely on the TEST configuration section in samconfig.toml, which is nice\n</code></pre> <p>This should not show any errors.</p>"},{"location":"installation/RunSAM/#deploy-for-real-this-time","title":"Deploy For Real This Time","text":"<p>After you do this, go back and re-run the deploy command without adding <code>--guided</code> to it, so run:</p> <pre><code>sam deploy --config-env TEST\n</code></pre> <p>This should go through and generate the CloudFormation stack and attempt to deploy your resources. Follow any prompts that are provided. This should be deployed successfully. However, Starfleet won't function properly because the account index hasn't been built yet. We will solve that in the next section.</p> <p>Note</p> <p>You will need to re-run the guided deploy in production to have SAM create all the AWS resources it needs. Once that's done, then copy and paste as much as possible in the SAM configuration section below, since that will make managing the deployments very nice and simple.</p> <p>Unfortunately, the SAM CLI doesn't do any of this by default so you have to finagle with it a bit. Once you do this a few times, you will get the hang of it.</p>"},{"location":"installation/RunSAM/#sam-configuration","title":"SAM Configuration","text":"<p>When setting up SAM, it will create a configuration. A sample configuration has been provided here that you should use: <code>sample_samconfig.toml</code> - make a copy of this named as <code>samconfig.toml</code>.</p> <p>More details about this is described in the Developer Guide.</p> <p>Once you have the configuration set up, then you can run:</p> <pre><code># Build test:\nsam build --config-env TEST\n\n# Validate test:\nsam validate --config-env TEST\n\n# Validate test:\nsam deploy --config-env TEST\n\n# ... and for prod:\n\n# Build prod:\nsam build --config-env PROD\n\n# Validate prod:\nsam validate --config-env PROD\n\n# Validate prod:\nsam deploy --config-env PROD\n</code></pre> <p>At this point you will have the following:</p> <ul> <li> Enable AWS Organizations if you haven't already done so and move some accounts into it</li> <li> Pick out an AWS account for deploying a testing version of Starfleet</li> <li> Work on getting a read-only Starfleet IAM role deployed with the permissions outlined above in all your AWS accounts. This role is not very permissive and is only able to describe the enabled regions for an account.<ul> <li> In the organization root, it has permissions to list the Organizations accounts.</li> <li> If you use StackSets then you need to manually make the role in the org root since StackSets won't operate in the org root.</li> <li> Important: Make sure that you have some IAM principal that you can use locally that can assume all these roles. This will be needed to run the Starfleet CLI. If you use AWS SSO, then use the ARN for the permissions set provisioned administrative role in the Starfleet account. See the note above for an example.</li> </ul> </li> <li> AWS Account identified for deployment</li> <li> Starfleet worker IAM roles deployed everywhere</li> <li> The <code>configuration.yaml</code> file in <code>src/starfleet/configuration_files</code> modified with values unique to your environment</li> <li> A payload template (not stored as a configuration file) in a different place than your configuration that describes what the Starfleet Account Index Generator is supposed to do</li> <li> An optional ECR Repository set up to make dockerized Lambda builds</li> <li> And Now: AWS SAM:<ul> <li> SAM's administrative resources deployed</li> <li> SAM's TEST deployment configuration all set up</li> <li> Starfleet deployed in your environment</li> </ul> </li> </ul> <p>While it's now deployed, it won't work without an Account Index. The next section describes how to get it set up.</p>"},{"location":"installation/SetupECR/","title":"Set Up Private ECR (Elastic Container Registry)","text":"<p>This is not required but highly recommended as the Starfleet package may be too big for Lambda to accept it as a <code>.zip</code> file. As such, we recommend setting up Starfleet with a Dockerized Lambda hosted in a private ECR.</p> <p>The steps to do this will largely involve setting up ECR, which you can find in the AWS documentation here.</p> <p>When creating your registry please adhere to the following:</p> <ol> <li>You are creating a PRIVATE registry. DO NOT MAKE THIS PUBLIC!</li> <li>This must reside in the same account and region that you are deploying Starfleet to</li> <li>Recommend that you set up tag immutability</li> <li>Recommend that you set up a lifecycle policy to expire older images (recommend to expire any <code>Image count more than 3</code>)</li> </ol> <p>Public Access</p> <p>DO NOT make your ECR repository public!</p> <p>Once you have your ECR registry set up, there will be a URL associated with it. That URL is the where your image will be pushed to. You will need that in the next steps for AWS SAM.</p> <p>Note: ECR URL</p> <p>You will need the ECR URL for the next sections. This is in the format of <code>aws_account_id.dkr.ecr.region.amazonaws.com</code></p>"},{"location":"installation/SetupECR/#note-about-dockerizing-starfleet","title":"Note about Dockerizing Starfleet","text":"<p>Included in the main code base is a <code>Dockerfile</code> that is intended to build Starfleet. This file should be all good to go. This is configured to use the AWS official Lambda docker container for a specific Python version. This also:</p> <ol> <li>Copies the Starfleet code to the container in the <code>var/runtime</code> directory, which is where Lambda wants the code to live.</li> <li>Cleans up some unnecessary files.</li> <li>It runs <code>pip install</code> to install the Starfleet packages</li> <li>Lastly, and very importantly it removes the built-in <code>boto3</code> and <code>botocore</code> packages that is shipped by default with the container. This is necessary because Lambda will prefer to use the preloaded version of boto instead of the Starfleet packaged one. The pre-loaded version can be out of date and can result in very bizarre errors with unsupported boto APIs - this is because you may be using boto features that are newer than the included boto packages. Thus, we remove them so only the Starfleet included boto packages are there.</li> </ol> <p>For more information about Dockerizing Lambda functions, see the docs here.</p>"},{"location":"installation/SetupECR/#continuing","title":"Continuing","text":"<p>At this point you will have the following:</p> <ul> <li> Enable AWS Organizations if you haven't already done so and move some accounts into it</li> <li> Pick out an AWS account for deploying a testing version of Starfleet</li> <li> Work on getting a read-only Starfleet IAM role deployed with the permissions outlined above in all your AWS accounts. This role is not very permissive and is only able to describe the enabled regions for an account.<ul> <li> In the organization root, it has permissions to list the Organizations accounts.</li> <li> If you use StackSets then you need to manually make the role in the org root since StackSets won't operate in the org root.</li> <li> Important: Make sure that you have some IAM principal that you can use locally that can assume all these roles. This will be needed to run the Starfleet CLI. If you use AWS SSO, then use the ARN for the permissions set provisioned administrative role in the Starfleet account. See the note above for an example.</li> </ul> </li> <li> AWS Account identified for deployment</li> <li> Starfleet worker IAM roles deployed everywhere</li> <li> The <code>configuration.yaml</code> file in <code>src/starfleet/configuration_files</code> modified with values unique to your environment</li> <li> A payload template (not stored as a configuration file) in a different place than your configuration that describes what the Starfleet Account Index Generator is supposed to do</li> <li> An optional ECR Repository set up to make dockerized Lambda builds</li> <li> And Now: AWS SAM:<ul> <li> SAM's administrative resources deployed</li> <li> SAM's TEST deployment configuration all set up</li> <li> Starfleet deployed in your environment</li> </ul> </li> </ul> <p>While it's now deployed, it won't work without an Account Index. The next section describes how to get it set up.</p>"},{"location":"installation/WrapUp/","title":"Wrapping It Up","text":"<p>\ud83e\udd1eHopefully\ud83e\udd1e everything was successful in deploying and getting the account index working. If there were error messages you will want to review them and double-check that everything is set up properly.</p>"},{"location":"installation/WrapUp/#debugging","title":"Debugging","text":"<p>Debugging is best accomplished by reviewing the logs. You can review the logs in the AWS console for your Starfleet account by going to CloudWatch in the region Starfleet is deployed in, and reviewing the Log Groups for the Lambdas. AWS SAM will generally name these according to the entry in the SAM template YAML.</p> <p>You will want to verify that the <code>/aws/lambda/starfleet-StarbaseFanoutFunction-...</code>, <code>/aws/lambda/starfleet-StarbaseEventBridgeFunction-...</code> (this should be made when the EventBridge events are fired off), and the <code>/aws/lambda/starfleet-AccountIndexGenerator-...</code> exist.</p> <p>The logs are quite verbose and should contain a lot of details about errors that are caused. In general, you will want to check the EventBridge function's logs to see if there are issues with the Starbase EventBridge scheduling, the Starbase fan out function's logs for issues with fanning out workers, and the individual worker logs to see if there are issues with them.</p> <p>Tip</p> <p>By default, CloudWatch logs have no expiration. To save money, set a retention policy on the log groups to have logs automatically deleted after a certain period of time. You need to do this manually... or write a Starfleet worker to do this everywhere... \ud83d\ude0f</p>"},{"location":"installation/WrapUp/#deploy-to-production","title":"Deploy to Production","text":"<p>Deploying to production is basically the same exact steps as test, but you will want to replace the test values with production ones. Don't forget to re-run the SAM guided deploy in Prod and correct the SAM configuration so that it's identical to test with production values.</p>"},{"location":"installation/WrapUp/#deployment-considerations","title":"Deployment Considerations","text":"<p>Now that you have Starfleet up and running, you may be thinking about how to manage the templates and all your environment specific configurations (and even custom workers).</p> <p>The Developer Guide has some suggestions on how to set up a proper deployment package. The TL;DR is you want a script that would download the upstream Starfleet, and merge in your configuration YAMLs, run SAM, and then perform the deployment.</p>"},{"location":"userGuide/AccountIndexGenerator/","title":"Account Index Generator User Guide","text":"<p>This is the main user guide for the Account Index Generator worker plugin. Most of the user guide details for the Account Index Generator has been covered in the Architecture and Installation docs (and also in the developer guide). Thus, this page will not be very large.</p>"},{"location":"userGuide/AccountIndexGenerator/#how-to-use-it","title":"How to use it?","text":"<p>Read this first!</p> <p>Make sure that for the first time you are using Starfleet, that you have the configuration properly configured to point to the correct S3 bucket to generate the index JSON to, and that you also have the proper IAM roles present. Remember, you need an IAM Role for the Starfleet workers to assume into in all AWS accounts in your organization, and you also need to make sure that the organization root has this account as well.</p> <p>If you choose to leverage CloudFormation StackSets to deploy these roles, remember that StackSets doesn't operate in the organization root account. So you will need to either make a separate CloudFormation stack in the organization root account or just manually create the IAM roles in question.</p> <p>In all cases, the configuration needs to be set properly. See the Installation Guide for details.</p> <p>The primary things to keep in mind for using Account Index Generator is that:</p> <ol> <li>All of the components are actually deployed</li> <li>The IAM Roles are configured as depicted in the Installation Guide</li> <li>The payload template is configured to properly deploy to the S3 bucket</li> <li>The Starbase is configured properly</li> </ol> <p>Of course, please consult the logs for details on what's going on.</p>"},{"location":"userGuide/Overview/","title":"User Guide","text":"<p>This page outlines how to use Starfleet and provides a guide around using each included worker ship.</p> <p>As previously mentioned, the purpose of Starfleet is to augment AWS Organizations. It should be used to enable features that you need everywhere to help maintain a secure cloud infrastructure state.</p> <p>In this section of the documentation, we provide a general overview of how to use each included plugin, as well as some common troubleshooting.</p>"},{"location":"userGuide/Overview/#general-gist","title":"General Gist","text":"<p>In general Starfleet works based on a combination of:</p> <ol> <li>The Starbase</li> <li>Deployed Workers</li> <li>Configuration</li> <li>Payloads</li> </ol> <p>Each worker has its own Configuration and Payload definitions. You should be familiar with the Architecture and Installation Guide before moving on to this section because it will make a lot of the topics discussed familiar.</p>"},{"location":"userGuide/Overview/#general-troubleshooting","title":"General Troubleshooting","text":"<p>The Starbase and the worker ship plugins are Lambda functions and will output logs to CloudWatch LogGroups. Reviewing the logs in the log group will provide you with the best details on what's happening under the hood.</p>"},{"location":"userGuide/Overview/#command-line-interface","title":"Command Line Interface","text":"<p>Starfleet has a command line interface that is executable via the <code>starfleet</code> command once you are in an activate virtual environment. All plugins should expose some command groups that you can execute and then explore for additional details.</p> <p>In general, you will need AWS credentials for Starfleet to utilize to ensure that these commands can run. This is mostly documented in the Installation Guide.</p> <p>Each worker ship should have documentation on how to execute the respective commands.</p>"},{"location":"userGuide/Overview/#common-cli-components","title":"Common CLI Components","text":"<p>In general all worker ships utilize common components to expose their CLIs. All worker ships will have a the following fields in common:</p>"},{"location":"userGuide/Overview/#payload-payload","title":"Payload (<code>--payload</code>)","text":"<p>The payload flag (<code>--payload</code>) specifies where to load the payload YAML (<code>--payload path/to/payload/template</code>) for the worker ship CLI. This is used as follows:</p> <pre><code>starfleet account-index generate --payload some/path/to/your/payload.yaml\n</code></pre>"},{"location":"userGuide/Overview/#the-commit-flag-commit","title":"The Commit Flag (<code>--commit</code>)","text":"<p>The commit flag (<code>--commit</code>) must be added to inform the worker ship plugin that it should operate in a commit mode to make changes. Not including the flag will ensure that the worker ship runs in read-only mode.</p> <p>Omitting the <code>--commit</code> flag is analogous to running <code>terraform plan</code>, and adding the <code>--commit</code> flag is analogous to running <code>terraform apply</code>.</p> <p>Example of it's usage is:</p> <pre><code>starfleet account-index generate --payload some/path/to/your/payload.yaml --commit\n</code></pre>"},{"location":"userGuide/Overview/#account-id-account-id","title":"Account ID (<code>--account-id</code>)","text":"<p>In addition to the above, Account worker ships will also require an <code>--account-id</code> argument that takes in the 12-digit AWS Account ID of the AWS account to operate the payload template against. Here is an example of that being used:</p> <pre><code>starfleet some-account-worker some-command --payload some/path/to/the/payload.yaml --account-id 111111111111\n</code></pre>"},{"location":"userGuide/Overview/#region-region","title":"Region (<code>--region</code>)","text":"<p>Account/Region workers need both the <code>--account-id</code> and the <code>--region</code> flags passed in. The region is the name of the AWS region to operate in. Here is an example:</p> <pre><code>starfleet aws-config sync --payload some/path/to/the/payload.yaml --account-id 111111111111 --region us-east-1\n</code></pre>"},{"location":"userGuide/PayloadTemplates/","title":"Payload Templates","text":"<p>Each worker defines their own payload template schema. Please see the navigation on the left to find the respective worker's payload template schema.</p>"},{"location":"userGuide/PayloadTemplates/#base-template","title":"Base Template","text":"<p>All worker ships will have the following fields:</p> <pre><code>TemplateName: SomeNameForYourTemplate\nTemplateDescription: Some description that makes it easy for you to understand what this is for.\n</code></pre> <p>Each worker ship then defines additional fields as appropriate.</p>"},{"location":"userGuide/PayloadTemplates/#account-and-account-region-payload-reference","title":"Account and Account Region Payload Reference","text":"<p>The schemas for the Account and Account/Region worker ship payloads can be found here.</p>"},{"location":"userGuide/Secrets/","title":"Secrets Management in Starfleet","text":"<p>Starfleet relies on an optional AWS Secrets Manager component for storing sensitive data, like tokens, passwords, and encryption keys. If you don't have a need for this then you don't need to make use of this.</p> <p>The Developer Guide has the raw details on how this works programmatically, but for this guide, we are going to explore how to configure it and make use if it.</p> <p>Cached Data Notice</p> <p>Like the other components in Starfleet, the loaded data will persist in memory on subsequent runs of the Lambda function. This has the benefit of not needing to make repeated AWS Secrets Manager API calls, which saves money. The downside to this is that AWS will persist the secrets value in memory as long as the container running your Lambda function remains operational (this happens on the AWS backend; you don't have control over it). If you make an update to the secret string, subsequent Lambda calls may not yet see it and you could operate off of the old cached secrets value.</p> <p>AWS will periodically rotate the Lambda container out every few hours if no code has changed. The only way for you to force your Lambda function's container to rotate out is to actually update the code for your Lambda function.</p> <p>Slack</p> <p>If you make use of Slack for alerts, then you need to configure the Secrets Management in Starfleet. Continue reading this page for details.</p>"},{"location":"userGuide/Secrets/#the-secret","title":"The Secret","text":"<p>Starfleet uses an AWS Secrets Manager secret for storing sensitive data. The data in the secret is stored as a JSON string that looks like this:</p> <pre><code>{\n    \"STARFLEET\": {\n        \"SlackToken\": \"the-token-here\"\n    },\n    \"WORKER_NAME\": \"Any value - this can be a string, nested Dict, etc.\",\n    \"...More Workers Here...\"\n}\n</code></pre> <p>You will need to create a secret named <code>Starfleet</code> in AWS secrets manager in the same account and region as Starfleet. The initial value for this JSON should look like this: <pre><code>{\n    \"STARFLEET\": {}\n}\n</code></pre></p> <p>Once this is saved, you will need to ensure that all Starfleet components that need access to this secret have their AWS Lambda function IAM roles be given the following permissions to access the secret: <pre><code>{\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"secretsmanager:GetSecretValue\",\n            \"Resource\": \"arn:aws:secretsmanager:REGION:ACCOUNT:secret:SECRET-ID-HERE\"\n        }\n    ]\n}\n</code></pre></p> <p>We recommend making this a managed policy that is attached to all the worker IAM roles.</p>"},{"location":"userGuide/Secrets/#configuration","title":"Configuration","text":"<p>If you are making use of the Secrets Management feature, you have to make sure that the Starfleet configuration is configured to point to it. Under the main <code>STARFLEET</code> stanza of the configuration you need to have the following:</p> <ul> <li><code>SecretsManager</code> - This is a dictionary that outlines the ID of an AWS Secrets Manager secret. This allows Starfleet workers to reference secrets. If specified, this contains 2 required fields: <code>SecretId</code> and <code>SecretRegion</code>. The ID is the name of the secret and the region is the region for it. The secret should reside in the same AWS account as Starfleet.</li> </ul> <p>This is what that looks like:</p> <pre><code>STARFLEET:\n  # ... All the other stuff here ...\n  SecretsManager:\n    SecretId: Starfleet        # This is the name of the AWS Secrets Manager secret. The secret must reside in the same AWS account as Starfleet.\n    SecretRegion: us-east-2    # This is the AWS region for where the secret resides.\n\nWorkerName:\n  Enabled: True\n  # ... All the other stuff here ...\n</code></pre>"},{"location":"userGuide/Secrets/#example-secret-entry","title":"Example Secret Entry","text":"<p>An example of a secret JSON string for a Starfleet setup with Slack and a GitHub application for the <code>GitHubSyncWorkerShip</code> would look something like this:</p> <pre><code>{\n    \"STARFLEET\": {\n        \"SlackToken\": \"xoxb-REDACTED\"\n    },\n    \"GitHubSyncWorker\": {\n        \"GITHUB_ORG_NAME_HERE\": \"-----BEGIN RSA PRIVATE KEY-----\\nREDACTED\\nREDACTED\\nREDACTED\\n-----END RSA PRIVATE KEY-----\"\n    }\n}\n</code></pre>"},{"location":"userGuide/Slack/","title":"Slack Alerts","text":"<p>Starfleet supports emitting alerts and notifications in Slack. This requires that you:</p> <ol> <li>Set up a Slack application and configure it for your workspace</li> <li>Get a Slack token</li> <li>Configure the Secrets Manager for Starfleet and store the Slack token in the secret</li> <li>Invite the Slack app to the Slack channels that you want the alerts sent to</li> <li>Update the worker configurations to include the Slack channel ID and desired alert priority</li> <li>Deploy the updated worker</li> </ol>"},{"location":"userGuide/Slack/#create-a-slack-application","title":"Create a Slack Application","text":"<p>For this section, you will want to largely rely on Slack's documentation for registering a Slack Bot, configuring the proper permissions, and obtaining a Slack token. However</p> <p>Warning</p> <p>The Slack instructions and screenshots below are from June 2023 and could be outdated in the future. Please consider submitting a Pull Request to update if that happens!</p> <ol> <li>The general gist is you will go to <code>api.slack.com/apps</code>, sign into your Slack account, and you will create an app:</li> <li>You will want to select <code>From scratch</code></li> <li>On the next window, type in the app name of <code>Starfleet</code> and select the Slack workspace you want to install it in</li> </ol> <p>Once your app is created, you may need to have a Slack administrator approve the application for it to be installed in the workspace and usable. If that is the case, you will still be able to update the configuration while your app is being approved.</p>"},{"location":"userGuide/Slack/#configure-the-slack-application","title":"Configure the Slack Application","text":"<p>Once the app is created, you can begin configuring it and getting a token.</p> <p>Tip</p> <p>Before moving forward, make sure that you have the Secrets Manager secret made. If you don't yet have one, then you will want to create one in the AWS console.</p> <ol> <li>You will need to go to the <code>OAuth &amp; Permissions</code> page:</li> <li>Scroll down to Scopes. You will need to add the following OAuth scopes:<ol> <li><code>channels:read</code></li> <li><code>chat:write</code></li> </ol> </li> <li> <p>You will need to prepare the JSON for Secrets Manager. The <code>SlackToken</code> needs to reside under the <code>STARFLEET</code> section of the secret JSON string. Open an empty text editor with the following text:     <pre><code>{\n    \"STARFLEET\": {\n        \"SlackToken\": \"COPY THE SLACK TOKEN HERE\"\n    }\n}\n</code></pre>     ^^ This assumes that you haven't yet created a secret. If you already have a secret, then fetch that out of Secrets Manager, copy it to your text editor, and modify it with the Slack token added into it.</p> <p>The Slack token is found when scrolling up under the <code>OAuth Tokens for Your Workspace</code> section:</p> <p>Copy and paste the updated secret text into Secrets Manager's UI and save the updated secret string.</p> </li> <li> <p>Once this is all done, make any additional tweaks you want, like updating the Slack icon and description</p> </li> </ol>"},{"location":"userGuide/Slack/#invite-to-your-channels","title":"Invite to Your Channels","text":"<p>Once your app has been approved into the workspace, then the next step is to invite the newly created app to your Slack channels. In this example we named it <code>Starfleet</code>, so we can go to the Slack channels that we want Starfleet to announce alerts in and invite it by sending the message <code>@Starfleet</code>. As you are typing that in, you should see it pop up in the autocompletion box:</p> <p>Follow the prompts to invite it to the channel. Once it's in the channel, Starfleet is able to announce messages there!</p>"},{"location":"userGuide/Slack/#adjust-configurations","title":"Adjust Configurations","text":"<p>The last step is to make updates the Starfleet configuration to both enable Slack and also configure the workers to announce messages to the desired channels.</p>"},{"location":"userGuide/Slack/#enable-slack","title":"Enable Slack","text":"<p>You need to enable Slack in the <code>STARFLEET</code> section of the configuration by adding both the <code>SecretsManager</code> configuration and also the <code>SlackEnabled</code> flag set to <code>True</code>. Here is an example:</p> <pre><code>STARFLEET:\n  # ... all the the other stuff ...\n  SecretsManager:\n    SecretId: Starfleet                  # Or whatever you named your Secret\n    SecretRegion: SECRET-REGION-HERE     # Replace with the region of the secret\n  SlackEnabled: True\n</code></pre>"},{"location":"userGuide/Slack/#configure-the-worker","title":"Configure the Worker","text":"<p>Once Slack is enabled in the main <code>STARFLEET</code> stanza, you also need to update your worker's <code>AlertConfiguration</code> section with details on the Slack channel ID and the desired message priority you want to emit messages on (<code>ChannelId</code> and the <code>AlertPriority</code>).</p> <ul> <li><code>AlertConfiguration</code> - This is an encompassing dictionary that specifies a Slack channel ID and a message priority for sending alerts to Slack from that worker. This is documented more in the Developer and User guides around Notifications.<ul> <li><code>ChannelId</code> - This is the Slack Channel ID that messages should be sent to</li> <li><code>AlertPriority</code> - This is the <code>AlertPriority</code> enum string (documented in the Developer guide). Acceptable values are: <code>NONE</code>, <code>PROBLEM</code>, <code>IMPORTANT</code>, <code>SUCCESS</code>, and <code>INFORMATIONAL</code>.</li> </ul> </li> </ul> <p>For more details on how the message priority logic works, see this section in the Developer Guide.</p> <p>The Slack channel ID is obtained by right-clicking on your Slack channel name, then clicking on <code>View channel details</code>. Scroll all the way to the bottom, and you will see <code>Channel ID</code> and a copy button after the ID to copy it. Click that and copy that to your worker configuration.</p> <p>Your worker configuration should look like: <pre><code>WorkerName:\n  # ... all the other stuff ...\n  AlertConfiguration:  # &lt;--- Send messages to Slack\n    ChannelId: PASTE-CHANNEL-ID-HERE\n    AlertPriority: INFORMATIONAL  # Replace with the other acceptable values specified above\n</code></pre></p>"},{"location":"userGuide/Slack/#example-configuration","title":"Example Configuration","text":"<p>An example of a wrapped up configuration with everything all set up looks like this with the <code>AwsConfigWorkerShip</code> as an example: <pre><code>STARFLEET:\n  DeploymentRegion: REGION\n  TemplateBucket: BUCKET-HERE\n  FanOutQueueUrl: https://sqs.REGION.amazonaws.com/ACCOUNT-HERE/starbase-fanout-queue\n  AccountIndex: StarfleetDefaultAccountIndex\n  LogLevel: DEBUG\n  SecretsManager:\n    SecretId: Starfleet\n    SecretRegion: REGION\n  SlackEnabled: True\n  ThirdPartyLoggerLevels:\n    botocore: CRITICAL\n    'urllib3.connectionpool': CRITICAL\n\n# ... more stuff ...\n\nAwsConfigWorkerShip:\n  Enabled: True\n  TemplatePrefix: AwsConfigWorkerShip/\n  InvocationQueueUrl: https://sqs.REGION.amazonaws.com/ACCOUNT-HERE/starfleet-aws-config-worker\n  InvocationSources:\n    - EVENTBRIDGE_TIMED_EVENT\n    - S3\n  EventBridgeTimedFrequency: SIX_HOURLY\n  WorkerRoleToAssume: starfleet-worker-role\n  AlertConfiguration:\n    ChannelId: CHANNEL-ID-HERE\n    AlertPriority: INFORMATIONAL\n</code></pre></p> <p>At this point, Slack notifications should be all set.</p>"},{"location":"userGuide/Starbase/","title":"Starbase User Guide","text":"<p>This is the main user guide for the Starbase component. Most of the user guide details for the Starbase has been covered in the Architecture and Installation docs (and also in the developer guide).</p>"},{"location":"userGuide/Starbase/#how-to-use-it","title":"How to use it?","text":"<p>The Starbase is the heart of Starfleet. The only way to use it is to make sure that it's configured properly. The Starbase must also have a proper account inventory prepared, which we discussed in the installation guide.</p> <p>The primary things to keep in mind for using Starfleet is that:</p> <ol> <li>All of the components are actually deployed</li> <li>The account index needs to be available - without this the Starbase has no way of knowing which AWS accounts and/or regions to task the workers for</li> <li>The template S3 bucket needs to contain the payloads for the workers AND those payloads need to be properly conformant with the corresponding worker payload schemas</li> <li>The template file names end in <code>.yaml</code></li> <li>The Starbase IAM role need to have access to the template bucket and also the corresponding worker SQS queues</li> <li>The configuration for the Starbase (the <code>STARFLEET</code> section) and the workers have all the correct details on which SQS queues to use, the template bucket, and the template prefixes within the bucket</li> <li>The EventBridge timed events are enabled for the given timing task</li> <li>The Lambda function permissions and the SQS queue permissions are configured to allow Lambda to pull events off of them (this should not be a problem if you use the included AWS SAM templates)</li> <li>For the Starbase specifically, you will want to ensure that it will operate with an SQS batch size of 1 for fanouts (this is also configured in the SAM template)</li> </ol> <p>Other than that, the Starbase is mostly not something that you need to worry about, but is something that you should review the logs of if you aren't seeing a worker get tasked. The Starbase is split across 2 Lambda functions:</p> <ol> <li>The EventBridge Timed Event responder</li> <li>The worker Fan Out - this is also invoked directly by the template S3 bucket on template object uploads</li> </ol> <p>If you aren't seeing a worker get invoked, definitely review the logs of each one to see what's going on.</p>"},{"location":"userGuide/GitHubSync/CLI/","title":"GitHub Repo Sync Worker CLI","text":"<p>The GitHub Repo Sync worker has 3 commands. All commands require AWS credentials used by Starfleet to be exported into the environment. All commands are under the <code>sync-github</code> sub-command.</p> <p>All commands require a <code>--payload</code> parameter to point to the path of the YAML payload.</p> <pre><code>starfleet sync-github\nUsage: starfleet sync-github [OPTIONS] COMMAND [ARGS]...\n\n  This is the worker ship for syncing a GitHub repo with S3.\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  download                This is a helpful debugging command to download...\n  get-installation-token  This returns the installation token for the...\n  run                     This will run the syncing of the repository...\n</code></pre>"},{"location":"userGuide/GitHubSync/CLI/#the-get-installation-token-command","title":"The <code>get-installation-token</code> command","text":"<p>The <code>get-installation-token</code> command is used for debugging purposes. It outputs an ephemeral GitHub authorization bearer token for the GitHub App specified in the payload template. This token can be used to make authenticated API calls to GitHub. You can use this with curl or Postman to debug the GitHub App's ability to make authenticated calls to GitHub.</p> <p>Help text: <pre><code>starfleet sync-github get-installation-token --help\nUsage: starfleet sync-github get-installation-token [OPTIONS]\n\n  This returns the installation token for the given organization, application\n  id, and installation id provided in the payload template. This is mostly\n  used for local testing and debugging.\n\nOptions:\n  --payload FILENAME  This is the worker payload YAML  [required]\n  --commit            Must be supplied for changes to be made [does not do anything]\n  --help              Show this message and exit.\n</code></pre></p> <p>The <code>--commit</code> flag does not have any purpose for this command.</p> <p>Here is a sample command that would generate the token: <pre><code>starfleet sync-github get-installation-token --payload /path/to/payload.yaml\n</code></pre></p>"},{"location":"userGuide/GitHubSync/CLI/#the-download-command","title":"The <code>download</code> command","text":"<p>The <code>download</code> command simply downloads the GitHub repository to the local disk. It will extract the <code>.zip</code> file downloaded from GitHub if the payload specifies the <code>ExtractZipContents</code> flag set to <code>True</code>. This is mostly used for debugging purposes.</p> <p>Help text: <pre><code>starfleet sync-github download --help\nUsage: starfleet sync-github download [OPTIONS]\n\n  This is a helpful debugging command to download the repository. This will\n  extract the contents if the payload specifies the `ExtractZipContents` flag\n  set to `True`. You simply provide the payload template and the location for\n  where you want the repo to be downloaded (and optionally extracted), and it\n  will be saved to that path as `REPO_NAME.zip` (and extracted as `REPO_NAME-\n  COMMIT-HASH/`).\n\n  The commit flag doesn't do anything for this command.\n\nOptions:\n  --save-dir PATH     A local directory to save the zip in.  [required]\n  --payload FILENAME  This is the worker payload YAML  [required]\n  --commit            Must be supplied for changes to be made [does not do anything]\n  --help              Show this message and exit.\n</code></pre></p> <p>The <code>--commit</code> flag does not have any purpose for this command.</p> <p>Here is a sample command that would save the repo to the Desktop: <pre><code>starfleet sync-github get-installation-token --payload /path/to/payload.yaml --save-dir ~/Desktop/\n</code></pre></p>"},{"location":"userGuide/GitHubSync/CLI/#the-run-command","title":"The <code>run</code> command","text":"<p>The <code>run</code> command performs the full function of the workload where it will download the repo, optionally extract the contents, and attempt to sync with S3. This works the same way the Lambda function in the cloud would. This optionally allows you to specify a download directory to persist the downloaded components.</p> <p>Help text: <pre><code>starfleet sync-github run --help\nUsage: starfleet sync-github run [OPTIONS]\n\n  This will run the syncing of the repository against the payload's specified\n  S3 bucket.\n\nOptions:\n  --save-dir PATH     An optional local directory to save and retain the\n                      contents within. If not supplied, then this will create\n                      a temporary directory and delete it.\n  --payload FILENAME  This is the worker payload YAML  [required]\n  --commit            Must be supplied for changes to be made\n  --help              Show this message and exit.\n</code></pre></p> <p>The <code>--commit</code> flag will attempt to make changes to the S3 bucket's files if there is a change that needs to run.</p> <p>Here is a sample command that would save the repo to the Desktop, and also attempt to sync the changes to S3. Commit enabled: <pre><code>starfleet sync-github run --payload /path/to/payload.yaml --save-dir ~/Desktop/ --commit\n</code></pre></p>"},{"location":"userGuide/GitHubSync/ConfigureGitHubApp/","title":"Configure the GitHub Application Components","text":"<p>The GitHub Repo Sync worker leverages a GitHub App to interact with GitHub repos. In this case, we need to have permissions to download a given repository in question. We use GitHub Apps in place of Personal Access Tokens (PATs).</p> <p>Warning</p> <p>The GitHub instructions and screenshots below are from June 2023 and could be outdated in the future. Please consider submitting a Pull Request to update if that happens!</p>"},{"location":"userGuide/GitHubSync/ConfigureGitHubApp/#create-the-app","title":"Create the App","text":"<p>We are going to create a GitHub App for Starfleet. You will be creating an app in each organization that contains the (private) repos that you need to access. If you are accessing a public repo, you will still need the App made, but it need not live in the same GitHub org. The instructions for both should be the same.</p> <p>Tip</p> <p>Before moving forward, make sure that you have the Secrets Manager secret made. If you don't yet have one, then you will want to create one in the AWS console.</p> <p>Note</p> <p>To create the App, you will need to have Owner permissions on the GitHub organization in question.</p> <ol> <li>Go to your GitHub organization page (<code>https://github.com/ORGNAME</code>)</li> <li>Scroll down on the left-hand side to <code>Developer Settings</code>, and click on <code>GitHub Apps</code></li> <li>Click on <code>New GitHub App</code></li> <li>On the <code>Register new GitHub App</code> page, you will need to fill out the following details:<ol> <li><code>GitHub App name</code>: This is globally unique, so come up with a name for your Starfleet app that doesn't exist elsewhere. You can call this whatever you like.</li> <li><code>Homepage URL</code>: Make this whatever you want.</li> <li>Uncheck <code>Expire user authorization tokens</code> - we don't use them</li> <li>Uncheck <code>Active</code> for webhook - we don't use them</li> <li>Select the following <code>Repository</code> permissions:<ol> <li><code>Metadata</code>: <code>Read-only</code></li> <li><code>Contents</code>: <code>Read-only</code></li> </ol> </li> <li>You don't need any additional permissions</li> <li>Lastly -- and very important, for <code>Where can this GitHub App be installed?</code>, select <code>Only on this account</code></li> </ol> </li> <li>Click on <code>Create GitHub App</code></li> </ol> <p>The page you are at is the GitHub Application administrative page. On the page at the top, you should see a field called <code>App ID</code>. Keep note of the App ID - you will need it later when creating the worker payload.</p> <p>Note</p> <p>You will need to keep track of the GitHub App ID, Private Key (will get stored in Secrets Manager), and the Installation ID. We will note these as we continue in the instructions.</p>"},{"location":"userGuide/GitHubSync/ConfigureGitHubApp/#prepare-the-secret","title":"Prepare the Secret","text":"<p>Once your GitHub App is created, you will need to generate a Private Key for it. This is where Secrets Manager comes in.</p> <ol> <li>On the App page, click on <code>Generate a private key</code></li> <li>You will be prompted to download a <code>.cer</code> file. This file contains the RSA private key. This is sensitive!</li> <li>You will need to find and replace all the newlines with a <code>\\n</code>. We recommend using VS Code for this. In VS Code, open the find menu, click on the <code>.*</code> icon at the right to enable regular expression search, and type in <code>\\n</code>. You will want to replace that with <code>\\\\n</code>. You will then click on the <code>Replace All</code> button. Here is what your find menu should look like:This will make the private key all on one line with the actual new lines replaced with a <code>\\n</code> separating the lines. This is the string value that needs to be coped over into the secret.</li> <li>You will need to prepare the JSON for Secrets Manager. The dictionary needs a top-level dictionary field named <code>GitHubSyncWorker</code>, and within that is a dictionary of the organization name, and the App's corresponding Private Key as a string. Paste in the private key above such that you have something that looks like this:     <pre><code>{\n    \"STARFLEET\": {...},\n    \"GitHubSyncWorker\": {\n        \"YOUR-GITHUB-ORG-NAME-HERE\": \"-----BEGIN RSA PRIVATE KEY-----\\nREDACTED\\nREDACTED\\nREDACTED\\n...\\n-----END RSA PRIVATE KEY-----\",\n        \"ADD MORE GITHUB ORGS HERE IF REQUIRED\": \"-----BEGIN RSA PRIVATE KEY-----\\nTHIS IS THE KEY FOR YOUR OTHER ORG'S APP -- ONE APP PER ORG\\n-----END RSA PRIVATE KEY-----\"\n    }\n}\n</code></pre>     ^^ This assumes that you haven't yet created a secret. If you already have a secret, then fetch that out of Secrets Manager, copy it to your text editor, and modify it with the required GitHub details added into it.</li> <li>Update the Secrets Manager entry in the AWS console with the all the details added to it</li> </ol> <p>Feel free to make other adjustments to your app, like configuring a fun icon for it.</p>"},{"location":"userGuide/GitHubSync/ConfigureGitHubApp/#install-the-app","title":"Install the App","text":"<p>The last step is to \"Install\" the GitHub app to your organization. Right now the GitHub app exists, but can't actually do anything on your organization yet. You need to install it to the organization and give it access to the repositories in question.</p> <ol> <li>At the top of the App administrative page, click on <code>Install App</code></li> <li>On the next page, you should see your Organization listed and a green <code>Install</code> button at the right. Click on <code>Install</code></li> <li>On the next page, you can select <code>All repositories</code> or <code>Only select repositories</code>. We recommend only selecting the repositories that you want to sync. Click the <code>Install</code> button. You should see something that looks something like this:</li> </ol>"},{"location":"userGuide/GitHubSync/ConfigureGitHubApp/#fetch-the-installation-id","title":"Fetch the Installation ID","text":"<p>After the application is installed, you now need to fetch the Installation ID. To do this:</p> <ol> <li>Go back to your organization settings page (<code>https://github.com/ORGNAME/settings</code>)</li> <li>Click on <code>GitHub Apps</code> under <code>Third-party Access</code></li> <li>On the page, locate the app you created and click on the <code>Configure</code> button</li> <li>Note the address at the URL bar. You should see something along the lines of <code>https://github.com/organizations/ORGNAME/settings/installations/SOME-ID</code>. The numbers in the <code>SOME-ID</code> part is the Installation ID. You will need to keep track of this for configuring the payload.</li> </ol>"},{"location":"userGuide/GitHubSync/ConfigureGitHubApp/#making-changes","title":"Making Changes","text":"<p>If you need to make changes in the future to support different repos in the same org, then you need to go to the App's installation and configure it to support more repos.</p> <p>Note</p> <p>If you need to support more private repos that are not in the same GitHub organization, then you need to repeat ALL of the steps here in the org in question and update the secret with that org's version of the GitHub App's private key as depicted in the secret JSON above.</p>"},{"location":"userGuide/GitHubSync/ConfigureGitHubApp/#next-steps","title":"Next Steps","text":"<p>At this point, you should have:</p> <ul> <li> The GitHub app created for the org you need to fetch repos for</li> <li> The GitHub app and configured with the correct permissions in the org</li> <li> The Private Key generated for the app</li> <li> The Secrets Manager secret has been updated with the Private Key set for the worker as depicted above</li> <li> The App is installed to the org</li> <li> You have App ID, and Installation ID</li> </ul> <p>Once all that is completed, then move onto the next section for configuration and worker installation.</p>"},{"location":"userGuide/GitHubSync/InstallationAndConfiguration/","title":"GitHub Repo Sync Worker: Installation &amp; Configuration","text":"<p>This page outlines the installation and configuration for the GitHub Repo Sync worker ship.</p>"},{"location":"userGuide/GitHubSync/InstallationAndConfiguration/#installation","title":"Installation","text":"<p>To install this, you need the following prerequisites:</p> <ol> <li>You need to follow the instructions on the previous page to configure the GitHub application first</li> <li>You need to have Secrets Manager configured with the secrets as documented on the previous page</li> <li> <p>You will need to have a GitHub repo that you want to perform the syncing on and also the S3 bucket in question</p> <p>Note</p> <p>The bucket to sync the repository with does not need to reside in the same account as the Starfleet worker. If you have a cross-account use case, you will need to update the bucket policy to permit the cross-account write. We strongly recommend either disabling ACLs on the bucket or setting the object owner ship flag to <code>Bucket Owner Preferred</code>. The worker will upload all objects with the <code>bucket-owner-full-control</code> canned-acl so either disabling ACLs or setting <code>Bucket Owner Preferred</code> will work perfectly.</p> </li> </ol>"},{"location":"userGuide/GitHubSync/InstallationAndConfiguration/#aws-sam-template","title":"AWS SAM Template","text":"<p>The AWS SAM template is below to get this worker deployed. The templates for testing and production are mostly the same. How each of them work is determined by the configuration of the worker and the corresponding templates. That is to say, the worker configuration specifies which path in the template S3 bucket to locate the GitHub Repo Sync worker payloads. The payloads outline the repository and target S3 bucket to sync to. This will be explained more in the template section. You can also turn off modification to files in S3 by setting the <code>STARFLEET_COMMIT</code> environment variable set to <code>False</code>.</p> <p>Tip</p> <p>We have included the below SAM details in the <code>test_sam_template.yaml</code> file that is included with this repo. All you need to do is uncomment the sections labeled <code>Uncomment for the GitHub Repo Sync Worker</code> with the details outlined.</p> <pre><code>Resources:\n  # ...\n\n  GitHubSyncWorkerDLQ:\n    Type: AWS::SQS::Queue\n    Properties:\n      QueueName: starfleet-github-sync-worker-dlq\n      RedriveAllowPolicy:\n        redrivePermission: allowAll\n\n  GitHubSyncWorkerQueue:\n    Type: AWS::SQS::Queue\n    Properties:\n      QueueName: starfleet-github-sync-worker\n      VisibilityTimeout: 300  # This needs to be the same as the Lambda function timeout.\n      RedrivePolicy:\n        deadLetterTargetArn: !GetAtt GitHubSyncWorkerDLQ.Arn\n        maxReceiveCount: 4\n\n  GitHubSyncWorker:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: ./src\n      Handler: starfleet.worker_ships.plugins.github_sync.ship.lambda_handler\n      Runtime: python3.10\n      Architectures:\n        - arm64\n      MemorySize: 128\n      Events:\n        SQSEvent:\n          Type: SQS\n          Properties:\n            Queue: !GetAtt GitHubSyncWorkerQueue.Arn\n            BatchSize: 2\n      Environment:\n        Variables:\n          STARFLEET_COMMIT: True\n      Policies:\n        # Grant permissions to read and write to the templates bucket, so you can do CI/CD!\n        - S3CrudPolicy:\n            BucketName: !Ref StarfleetTemplateBucket\n        # Add any additional S3 policies here!\n\n  # ...\n  AssumeRoleManagedPolicy:\n    # ...\n    PolicyDocument:\n      Version: \"2012-10-17\"\n      Statement:\n        # ...\n        # Add the secrets manager permissions as well for Slack alerts and GitHub access\n        - Effect: Allow\n          Action: secretsmanager:GetSecretValue\n          Resource: arn:aws:secretsmanager:REGION:ACCOUNTNUMBER:secret:STARFLEET-SECRET-ID-HERE\n    Roles:\n      # ...\n      - !Ref GitHubSyncWorkerRole  # GitHubSyncWorkerRole is created automatically by SAM and can be referenced\n\n# ...\nOutputs:\n  # ...\n  GitHubSyncWorkerQueue:\n    Description: The Queue URL for the GitHub Sync Worker invocation queue\n    Value: !GetAtt GitHubSyncWorkerQueue.QueueUrl\n  GitHubSyncWorkerDLQ:\n    Description: The Queue URL for the GitHub Sync Worker invocation DLQ\n    Value: !GetAtt GitHubSyncWorkerDLQ.QueueUrl\n  GitHubSyncWorker:\n    Description: The GitHub Sync Worker ship function that syncs a GitHub repo with S3\n    Value: !GetAtt GitHubSyncWorker.Arn\n</code></pre>"},{"location":"userGuide/GitHubSync/InstallationAndConfiguration/#configuration","title":"Configuration","text":"<p>The last part of the installation process is to make sure that we have the correct configuration in place. Because this worker requires AWS Secrets Manager to be used, you need to make sure that the <code>STARFLEET</code> stanza of the configuration contains the details about Secrets Manager, by defining the <code>SecretsManager</code> part.</p> <p>No other unique fields exist for this worker ship. Here is an example of it all together:</p> <pre><code>STARFLEET:\n  # ... All the other stuff here ...\n  SecretsManager:\n    SecretId: Starfleet        # This is the name of the AWS Secrets Manager secret. The secret must reside in the same AWS account as Starfleet.\n    SecretRegion: REGION       # This is the AWS region for where the secret resides.\n\nGitHubSyncWorkerShip:\n  Enabled: True\n  TemplatePrefix: GitHubSyncWorkerShip/\n  InvocationQueueUrl: https://sqs.REGION.amazonaws.com/ACCOUNT-ID/starfleet-github-sync-worker\n  InvocationSources:\n    - EVENTBRIDGE_TIMED_EVENT\n    - S3\n  EventBridgeTimedFrequency: FIVE_MIN  # We recommend every 5 minutes\n  # Optional for Slack Alerts:\n#   AlertConfiguration:\n#     ChannelId: SLACK CHANNEL ID\n#     AlertPriority: INFORMATIONAL\n</code></pre> <p>Testing and Production paths for Starfleet payload templates</p> <p>We strongly recommend using this worker for syncing the Starfleet templates from git to the S3 templates bucket. The recommended strategy is to have the <code>TemplatePrefix</code> for testing set to <code>testing/GitHubSyncWorkerShip/</code> and production to be set to <code>GitHubSyncWorkerShip/</code>, which is what's outlined in the example above.</p> <p>Later, in the payload templates, we will configure the testing payload to only care about items in the <code>testing/</code> path vs. production which will be configured to ignore the <code>testing/</code> path.</p>"},{"location":"userGuide/GitHubSync/Overview/","title":"GitHub Repository Sync Worker User Guide","text":"<p>This is the main user guide for the GitHub Repository Sync Worker ship. This page documents all that there is to know about this worker ship.</p>"},{"location":"userGuide/GitHubSync/Overview/#what-does-it-do","title":"What does it do?","text":"<p>This worker ship periodically syncs a GitHub repository with an S3 bucket. The primary purpose of this worker is to enable CI/CD capabilities in Starfleet. CI/CD happens when a repository on GitHub with the Starfleet payload template YAML files are synced with Starfleet's template S3 bucket. Whenever objects are placed into the bucket, a notification is sent out to the Starbase FanOut function, which will then fetch the updated template YAML and task the corresponding worker ship for processing.</p> <p>However, this can be used for many GitHub -&gt; S3 use cases.</p>"},{"location":"userGuide/GitHubSync/Overview/#how-it-works","title":"How it works","text":"<p>The GitHub Sync worker is a <code>SINGLE_INVOCATION</code> worker, no AWS account or region context is required. This works by:</p> <ol> <li>Authenticating as a GitHub App to your GitHub organization</li> <li>Downloading the .zip of the specified repository's branch</li> <li>Optionally - extract the .zip file</li> <li>Compare the downloaded data (either the raw .zip or the extracted files) with the data in S3. If the files are different, then it will upload them.</li> <li>It will optionally delete files on the bucket that are not present in the repository</li> </ol> <p>The worker will determine that a file needs to be uploaded if the file is missing in S3 or if the file in S3 has a checksum (S3 ETag) that is not the same as the file in the repo.</p>"},{"location":"userGuide/GitHubSync/Overview/#recommended-use-cases","title":"Recommended use cases","text":"<p>This worker is optimal for the use case of syncing small text files to S3. I.e. the case of syncing Starfleet payload YAML templates. It is not recommended for syncing very large files or syncing a very large number of files. Keep in mind that this runs in a Lambda function so anything that can be accomplished by Lambda is what this is optimal for.</p> <p>This worker could be a good use case for syncing static files to an S3 bucket to source a CloudFront distribution.</p> <p>We also recommend that you run this worker with an EventBridge schedule set to <code>FIVE_MINUTES</code>.</p>"},{"location":"userGuide/GitHubSync/Overview/#alerting","title":"Alerting","text":"<p>The GitHub Sync worker supports alerts to Slack. It will alert on any errors that are encountered during execution. It will also emit <code>IMPORTANT</code> notices if it makes any changes to S3.</p>"},{"location":"userGuide/GitHubSync/Template/","title":"GitHub Repo Sync Worker: Payload Template Schema","text":"<p>In this section, we discuss the GitHub Repo Sync worker templates. The GitHub Repo Sync worker is a <code>SINGLE_INVOCATION</code> worker, and does not require any AWS account on the account index.</p>"},{"location":"userGuide/GitHubSync/Template/#template-schema","title":"Template Schema","text":"<p>Here is an example of the schema: <pre><code>TemplateName: NameOfYourTemplate\nTemplateDescription: Syncs the REPO-NAME to the BUCKET-NAME\nOrganization: YOUR-ORG-NAME-HERE\nRepository: THE-REPO-HERE\nBranchName: THE-BRANCH-NAME-HERE\nGitHubAppId: \"The GitHub App Id -- need to wrap in quotes as it's technically a number but this needs to be a string\"\nGitHubInstallationId: \"The GitHub Installation ID -- ditto about wrapping in quotes\"\nBucketName: YOUR-S3-BUCKET\nBucketRegion: S3 BUCKET REGION HERE\nExtractZipContents: True  # See below for details\nDeleteMissingFiles: True  # See below for details\n\n# https://www.regexpal.com/ is your friend\nExcludeRepoPaths:\n  - \"^testing\\/.+$\"  # Excluding the `testing/` path\n  - \"^README.md$\"\n  - \"^.github\\/.+$\"\n  - \"^.gitignore$\"\n</code></pre></p> <p>Below are the required fields that this worker needs:</p> <ol> <li><code>Organization</code> - This is the name of the GitHub organization that the repository resides in. Note: This must be the same exact value (case sensitive) that is in the Secret to reference the GitHub App private key.</li> <li><code>Repository</code> - This is the name of the repository to sync. You need to make sure that the GitHub App has permissions to download this repo.</li> <li><code>BranchName</code> - This is the name of the branch that you want to sync. Typically, this would be <code>main</code> or <code>master</code>.</li> <li><code>GitHubAppId</code> - This is the Application ID (documented in the GitHub App Configuration page). Wrap it in quotes because it's a numerical string.</li> <li><code>GitHubInstallationId</code> - This is the Installation ID (documented in the GitHub App Configuration page). Wrap it in quotes because it's a numerical string.</li> <li><code>BucketName</code> - This is the name of the S3 bucket you want to sync with</li> <li><code>BucketRegion</code> - This is the region that the bucket resides in</li> <li><code>ExtractZipContents</code> - Boolean - This indicates whether or not the downloaded <code>.zip</code> file from GitHub should be extracted or not. That is to say, if this field is <code>False</code>, then the downloaded <code>.zip</code> file itself is what will be synced with S3. If this is set to <code>True</code>, then the <code>.zip</code> is extracted and the extracted files is what will be compared with S3. This being set to <code>False</code> is useful if you wanted to have the entire repository itself be the artifact that you want stored in S3 for downstream processing. For the use case of syncing payload templates to the templates S3 bucket, you want this to be set to <code>True</code> so that each template is individually synced with S3.</li> </ol> <p>Here are the optional fields:</p> <ol> <li><code>IncludeRepoPaths</code> - List of Regex Strings - This is a list of regex strings indicate the paths on the local disk that should be synced with S3. By default, this value is set to: <code>[\"^.+$\"]</code>, which will match on everything. As mentioned on the previous page, if you wanted to sync the templates repository with S3, then for the testing deployment, you could have this set to <code>- \"^testing\\/.+$\"</code>, which would only sync repository files that exist in the <code>testing\\</code> path.</li> <li><code>ExcludeRepoPaths</code> - List of Regex Strings - This is a list of regex strings that indicate the paths on the local disk that should not be synced with S3. This takes precedence over the <code>IncludeRepoPaths</code>. In the included example above, we are ignoring specific files that we don't want synced with S3, like the <code>.gitignore</code> file. By default, this field is an empty list: <code>[]</code>.</li> <li><code>KeyPrefix</code> - This is the starting prefix in the S3 bucket that should be assessed. By default, the root of the S3 bucket is what the worker examines. If you wanted to only sync files that reside within the <code>foo/</code> prefix of the bucket, then you would want to set this value to <code>foo/</code>. All repo files would then be set to reside in <code>foo/filename...</code> on the bucket.</li> <li><code>DeleteMissingFiles</code> - Boolean - By default, this is set to <code>False</code>. If this is set to <code>True</code>, then the worker will delete any object in the S3 bucket that is not found in the GitHub repository. This flag being enabled keeps the S3 bucket contents 1:1 in sync with the repository.</li> </ol>"},{"location":"userGuide/IAM/Roles/CLI/","title":"IAM Role Worker CLI","text":"<p>The IAM Role worker CLI resides under the <code>iam role</code> sub-command. Below are the CLI options</p> <pre><code>starfleet iam role\nUsage: starfleet iam role [OPTIONS] COMMAND [ARGS]...\n\n  This is the worker ship for processing a Starfleet-wrapped iambic.org IAM\n  role template.\n\n  Note: The account index is utilized for these commands and as such, AWS\n  credentials may be required to run them.\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  sync             This will invoke iambic to sync out the IAM role.\n  validate-iambic  This will validate the supplied Starfleet-wrapped...\n</code></pre>"},{"location":"userGuide/IAM/Roles/CLI/#the-iam-role-validate-iambic-command","title":"The <code>iam role validate-iambic</code> command","text":"<p>This command is used to ensure that template itself is mostly well formed. This will not perform any account resolution logic and is mostly used to confirm that the template will make its way to IAMbic and that IAMbic is satisfied with the template.</p> <p>This command does not require AWS credentials and does not take in any arguments other than the path to the file to validate. The <code>commit</code> flag has no effect on this command. Example:</p> <pre><code>starfleet iam role --payload some/path/to/the/payload.yaml\n</code></pre> <p>The output will inform you if there are any problems or not and what fixes should be performed if there are any issues.</p>"},{"location":"userGuide/IAM/Roles/CLI/#the-iam-role-sync-command","title":"The <code>iam role sync</code> command","text":"<p>This is analogous to all the other <code>sync</code> commands for the other workers. This command does require AWS credentials and will perform both the validation for a given AWS account and if the <code>commit</code> flag is supplied, it will perform any changes required.</p> <p>Here is an example of how to run it in commit mode on account ID <code>111111111111</code>:</p> <pre><code>starfleet iam role sync --payload some/path/to/the/payload.yaml --account-id 111111111111 --commit\n</code></pre>"},{"location":"userGuide/IAM/Roles/Installation/","title":"Installing &amp; Configuring the IAM Role Worker","text":"<p>Installing the IAM Role worker requires the following components:</p> <ol> <li>The Starfleet worker role with permissions to perform IAM changes in all your accounts.</li> <li>Update to the AWS SAM template to include all the additional components to deploy the worker</li> <li>Updated configuration</li> <li>Payload templates</li> </ol> <p>Security Sensitive</p> <p>As previously mentioned throughout the documentation, Starfleet is a privileged security application given that it has powerful permissions to mutate resources throughout your infrastructure. As such, this should be deployed in a security sensitive account with limited access.</p>"},{"location":"userGuide/IAM/Roles/Installation/#update-the-starfleet-account-resident-roles","title":"Update the Starfleet Account-Resident Roles","text":"<p>In the installation guide, we discussed the creation of the Starfleet account resident roles that the workers will assume to perform their tasks. You will need to update these roles with the required IAM permissions. We are going to assume that for Test accounts, you will want read-only permissions, and for Prod accounts, you will want read/write permissions:</p>"},{"location":"userGuide/IAM/Roles/Installation/#test-role-read-only","title":"Test Role - Read Only","text":"<p>Add the following to the <code>starfleet-worker-basic-test-role</code> permissions:</p> <pre><code>ManagedPolicyArns:\n    - arn:aws:iam::aws:policy/IAMReadOnlyAccess\n</code></pre>"},{"location":"userGuide/IAM/Roles/Installation/#prod-role-readwrite","title":"Prod Role - Read/Write","text":"<p>Add the following to the <code>starfleet-worker-basic-prod-role</code> permissions:</p> <pre><code>ManagedPolicyArns:\n    - arn:aws:iam::aws:policy/IAMFullAccess\n</code></pre>"},{"location":"userGuide/IAM/Roles/Installation/#aws-sam-template","title":"AWS SAM Template","text":"<p>For the AWS SAM template, you will need to add in this worker's components to it. The templates for testing and production are mostly the same. The only difference is that for production, we have the <code>STARFLEET_COMMIT</code> environment variable set to <code>True</code>. See the special note below about setting the <code>GIT_PYTHON_REFRESH</code> environment variable, which is required for the IAMbic library to work.</p> <p>Tip</p> <p>We have included the below SAM details in the <code>test_sam_template.yaml</code> file that is included with this repo. All you need to do is uncomment the sections labeled <code>Uncomment for the IAM Role Worker</code> with the details outlined.</p> <p>Global Environment Variable Required!</p> <p>The IAMbic library requires that you set the following environment variable in the SAM configuration:</p> <p><pre><code>Globals:\n  Function:\n    Timeout: 300\n    Environment:\n      Variables:\n        GIT_PYTHON_REFRESH: quiet  # Required for IAMbic in the IAM Role Worker\n</code></pre> We recommend that this be globally as it impacts both the worker and the Starbase.</p>"},{"location":"userGuide/IAM/Roles/Installation/#test-template-no-commit","title":"Test Template: No Commit","text":"<p>Here is a sample of what should be in your test template:</p> <pre><code>Globals:\n  Function:\n    Timeout: 300\n    Environment:\n      Variables:\n        GIT_PYTHON_REFRESH: quiet  # Required for IAMbic in the IAM Role Worker\n\n# ...\n\nResources:\n  # ...\n\nIamRoleWorkerDLQ:\n   Type: AWS::SQS::Queue\n   Properties:\n     QueueName: starfleet-iam-role-worker-dlq\n     RedriveAllowPolicy:\n       redrivePermission: allowAll\n\n IamRoleWorkerQueue:\n   Type: AWS::SQS::Queue\n   Properties:\n     QueueName: starfleet-iam-role-worker\n     VisibilityTimeout: 300  # This needs to be the same as the Lambda function timeout.\n     RedrivePolicy:\n       deadLetterTargetArn: !GetAtt IamRoleWorkerDLQ.Arn\n       maxReceiveCount: 4\n\n IamRoleWorker:\n   Type: AWS::Serverless::Function\n   Properties:\n     CodeUri: ./starfleet/src\n     Handler: starfleet.worker_ships.plugins.iam.role_ship.lambda_handler\n     Runtime: python3.10\n     Architectures:\n       - arm64\n     MemorySize: 128\n     Events:\n       SQSEvent:\n         Type: SQS\n         Properties:\n           Queue: !GetAtt IamRoleWorkerQueue.Arn\n           BatchSize: 4\n     Environment:\n       Variables:\n         STARFLEET_COMMIT: False\n         GIT_PYTHON_REFRESH: quiet  # Iambic\n     Policies:\n       # Grant permissions to read from the Account Inventory S3 bucket:\n       - S3ReadPolicy:\n             BucketName: !Ref AccountIndexBucket\n\n\n# ...\n  AssumeRoleManagedPolicy:\n    # ...\n      Roles:\n        - !Ref AccountIndexGeneratorRole  # AccountIndexGeneratorRole is created automatically by SAM and can be referenced\n        # ...\n        - !Ref IamRoleWorkerRole  # IamRoleWorkerRole is created automatically by SAM and can be referenced\n\n# ...\nOutputs:\n  # ...\n IamRoleWorkerQueue:\n   Description: The Queue URL for the IAM Role Worker invocation queue\n   Value: !GetAtt IamRoleWorkerQueue.QueueUrl\n IamRoleWorkerDLQ:\n   Description: The Queue URL for the IAM Role Worker invocation DLQ\n   Value: !GetAtt IamRoleWorkerDLQ.QueueUrl\n IamRoleWorker:\n   Description: The IAM Role Worker ship function that uses iambic to sync IAM roles in our infrastructure\n   Value: !GetAtt IamRoleWorker.Arn\n</code></pre>"},{"location":"userGuide/IAM/Roles/Installation/#prod-template-commit","title":"Prod Template: Commit","text":"<p>The Prod template and the test template should look exactly the same, except you should set the <code>STARFLEET_COMMIT</code> environment variable to <code>True</code>.</p>"},{"location":"userGuide/IAM/Roles/Installation/#the-configuration","title":"The Configuration","text":"<p>The last part of the installation process is to make sure that we have the correct configuration in place. Here is what that would generally look like:</p> <pre><code>IamRoleWorkerShip:\n  Enabled: True\n  TemplatePrefix: IAM/Roles/  # We recommend this prefix in S3 for your payload templates\n  InvocationQueueUrl: https://sqs.YOUR-REGION.amazonaws.com/YOUR-ACCOUNT-ID/starfleet-iam-role-worker\n  InvocationSources:\n    - EVENTBRIDGE_TIMED_EVENT\n    - S3\n  EventBridgeTimedFrequency: THIRTY_MIN\n  WorkerRoleToAssume: starfleet-worker-basic-test-role  # swap for `starfleet-worker-basic-prod-role` in prod\n</code></pre> <p>There are 2 fields in the configuration that is defined for this worker:</p> <ol> <li><code>WorkerRoleToAssume</code> - This is the IAM role that the IAM Role worker needs to assume in all AWS accounts to perform it's job function. If you follow the instructions, this will be <code>starfleet-worker-basic-test|prod-role</code> depending on if this is the Test or Prod deployment.</li> <li><code>WorkerRoleSessionName</code> - optional - this is an optional string for what the assume role session name would be. By default this is <code>StarfleetIamRoleWorkerShip</code>.</li> </ol> <p>Once you have all the components all set, you will want to use the SAM CLI to build and deploy everything.</p>"},{"location":"userGuide/IAM/Roles/Overview/","title":"Starfleet IAM Role Worker","text":"<p>This is the main user guide for the IAM Role Worker ship.</p>"},{"location":"userGuide/IAM/Roles/Overview/#what-does-it-do","title":"What does it do?","text":"<p>This is a Starfleet worker that makes it possible to sync IAM roles across all accounts in your infrastructure with both drift detection and prevention. This worker wraps the excellent IAMbic library to perform the heavy lifting of the actual IAM work. If you haven't checked out IAMbic yet, please take a look at it. It's a full-featured IaC that unifies IAM management across the AWS world (and other identity providers) with lots of features and capabilities.</p> <p>The long and short of it is that this worker embeds an IAMbic IAM role template within a Starfleet template to leverage Starfleet's account tasking capabilities to have IAMbic sync a role where you need it and how you need it configured.</p> <p>Please familiarize yourself with the IAMbic IAM role template schema, as that is used here.</p>"},{"location":"userGuide/IAM/Roles/Overview/#what-does-it-not-do","title":"What does it NOT do?","text":"<p>This only syncs IAM roles, it does not sync the other IAM primitives. We may consider adding additional IAM capabilities in the future. This also does not support all of the IAMbic capabilities, but does support the majority of the IAM capabilities. That is detailed more below.</p>"},{"location":"userGuide/IAM/Roles/Overview/#how-it-works","title":"How it works","text":"<p>The long and the short of it, we are simply embedding an IAMbic template within a Starfleet template. Starfleet performs the heavy lifting of tasking worker lambdas with the AWS account context to operate in. Starfleet then embeds the current account context within the IAMbic template that gets passed into the IAMbic library to sync the role.</p> <p>Here is a sample role template:</p> <pre><code>TemplateName: DevOpsAutomationRole\nTemplateDescription: This is a role for DevOps automation to do DevOps things\nIncludeAccounts:\n  ByNames:\n    - DevOpsTest\n    - DevOpsProd\nIambicRoleTemplate:  # &lt;----- The IAMbic template gets embedded into here\n  properties:\n    role_name: DevOpsAutomationRole\n    description: 'The DevOpsRole for DevOpsAutomation in {{ var.account_name }}'\n    assume_role_policy_document:\n      statement:\n        - action: sts:AssumeRole\n          effect: Allow\n          principal:\n            service: ec2.amazonaws.com\n      version: '2012-10-17'\n    managed_policies:\n      - policy_arn: arn:aws:iam::aws:policy/ReadOnlyAccess\n    inline_policies:\n      - policy_name: DevOpsThings\n        statement:\n          - sid: DevOpsThings\n            effect: Allow\n            action:\n              - ec2:*\n              - elasticloadbalancing:*\n              - iam:PassRole\n            resource: '*'\n            version: '2012-10-17'\n\n      # Give the DevOpsTest account access to the DevOpsTest S3 Bucket:\n      - StarfleetIncludeAccounts:\n          ByNames:\n            - DevOpsTest\n        policy_name: ArtifactBucket\n        statement:\n          - effect: allow\n            action:\n              - s3:Get*\n              - s3:List*\n              - s3:PutObject\n            resource:\n              - aws:s3:::some-devops-bucket-devopstest\n              - aws:s3:::some-devops-bucket-devopstest/*\n        version: '2012-10-17'\n\n      # Give the DevOpsProd account access to the DevOpsProd S3 Bucket:\n      - StarfleetIncludeAccounts:\n          ByNames:\n            - DevOpsProd\n        policy_name: ArtifactBucket\n        statement:\n          - effect: allow\n            action:\n              - s3:Get*\n              - s3:List*\n              - s3:PutObject\n            resource:\n              - aws:s3:::some-devops-bucket-devopsprod\n              - aws:s3:::some-devops-bucket-devopsprod/*\n        version: '2012-10-17'\n</code></pre>"},{"location":"userGuide/IAM/Roles/Overview/#what-is-different-between-this-and-vanilla-iambic","title":"What is different between this and vanilla IAMbic?","text":"<p>Starfleet is simply wrapping the IAMbic library so that you use Starfleet instead of vanilla IAMbic. The primary benefit is that if you are already using Starfleet, then you can start rolling out IAM roles where you need it with drift prevention. You just need to familiarize yourself with the IAMbic template format to begin using it.</p>"},{"location":"userGuide/IAM/Roles/Overview/#caveats","title":"Caveats","text":"<p>There are some caveats between using the Starfleet IAM worker vs. vanilla IAMbic. All of the IAMbic specific syntax around account inclusion/exclusion is replaced with Starfleet's account resolution capabilities. Also, the expiration capability is not yet supported.</p> <p>For example, instead of:</p> <pre><code>   #...\n      - included_accounts:\n          - DevOpsProd\n        policy_name: ArtifactBucket\n        statement:\n          - effect: allow\n            action:\n              - s3:Get*\n              - s3:List*\n              - s3:PutObject\n            resource:\n              - aws:s3:::some-devops-bucket-devopsprod\n              - aws:s3:::some-devops-bucket-devopsprod/*\n  # ...\n</code></pre> <p>You would use: <pre><code>  # ...\n      # This uses the same syntax as other Starfleet templates. Simply swap `included/excluded_accounts` with `StarfleetInclude/ExcludeAccounts`\n      - StarfleetIncludeAccounts:\n          ByNames:\n            - DevOpsProd\n        policy_name: ArtifactBucket\n        statement:\n          - effect: allow\n            action:\n              - s3:Get*\n              - s3:List*\n              - s3:PutObject\n            resource:\n              - aws:s3:::some-devops-bucket-devopsprod\n              - aws:s3:::some-devops-bucket-devopsprod/*\n  # ...\n</code></pre></p> <p>Starfleet will render out the IAMbic templates with the proper account IDs and pass that onto IAMbic to complete the work.</p>"},{"location":"userGuide/IAM/Roles/Overview/#alerting","title":"Alerting","text":"<p>The IAM Role Worker supports alerts to Slack. It will emit alerts regarding the changes that IAMbic made to the given role in the AWS account in question.</p>"},{"location":"userGuide/IAM/Roles/Template/","title":"IAM Role Worker Templates","text":"<p>In this section, we discuss the IAM Role worker templates. The IAM Role worker is an <code>ACCOUNT</code> worker, and thus relies on the base account template components that is discussed here. In addition to the base account details, there are some unique fields defined below:</p>"},{"location":"userGuide/IAM/Roles/Template/#template-schema","title":"Template Schema","text":"<p>The IAM Role worker leverages the IAMbic library for syncing IAM roles. An IAMbic IAM role template is wrapped withing a Starfleet template. Most of the capabilities are supported, but there are some caveats as some features are not supported and for other features, you need to use Starfleet primitives instead.</p> <p>Below is a sample template:</p> <pre><code>TemplateName: SomeSampleRole\nTemplateDescription: This is a sample role that is rolled out by Starfleet and IAMbic\nIncludeAccounts:\n  ByNames:\n    - DevOpsTest\n    - DevOpsProd\nIambicVariables:\n  - Key: some_key\n    Value: some_value\nIambicRoleTemplate:\n  properties:\n    role_name: some_sample_role\n    description: A sample role that will be rolled out to {{ var.account_name }} with {{ var.some_key }} set\n    assume_role_policy_document:\n      statement:\n        - action: sts:AssumeRole\n          effect: Allow\n          principal:\n            service: ec2.amazonaws.com\n      version: '2012-10-17'\n    managed_policies:\n      - policy_arn: arn:aws:iam::aws:policy/IAMReadOnlyAccess  # Grant read-only access to IAM\n    inline_policies:\n      - StarfleetIncludeAccounts:  # In DevOpsTest, grant access to the test S3 bucket\n          ByNames:\n            - DevOpsTest\n        policy_name: s3\n        statement:\n          - effect: Allow\n            action:\n              - s3:List*\n              - s3:Get*\n              - s3:PutObject\n              - s3:DeleteObject\n            resource:\n              - arn:aws:s3:::devops-test-bucket\n              - arn:aws:s3:::devops-test-bucket/*\n        version: '2012-10-17'\n      - StarfleetIncludeAccounts:  # In DevOpsProd, grant access to the prod S3 bucket\n          ByNames:\n            - DevOpsProd\n        policy_name: s3\n        statement:\n          - effect: Allow\n            action:\n              - s3:List*\n              - s3:Get*\n              - s3:PutObject\n              - s3:DeleteObject\n            resource:\n              - arn:aws:s3:::devops-prod-bucket\n              - arn:aws:s3:::devops-prod-bucket/*\n        version: '2012-10-17'\n    tags:\n      - key: jira\n        value: DEVOPS-01\n</code></pre> <p>In the example above, the role deployed to the <code>DevOpsTest</code> account will get a different <code>s3</code> policy than the role deployed to the <code>DevOpsProd</code> account.</p>"},{"location":"userGuide/IAM/Roles/Template/#components","title":"Components","text":"<p>There are only 2 high level fields and they are defined as:</p> <ol> <li><code>IambicVariables</code> - Optional List of Dictionaries - This is for defining variables that you want IAMbic to reference throughout the template. These are just <code>Key</code> and <code>Value</code> pairs.</li> <li><code>IambicRoleTemplate</code> - Dictionary - This is the embedded IAMbic template with some fields removed. More on that below.</li> </ol>"},{"location":"userGuide/IAM/Roles/Template/#account-inclusion-and-exclusion","title":"Account Inclusion and Exclusion","text":"<p>IAMBic has it's own primitives for declaring which accounts to include or exclude. When Starfleet renders the IAMbic template it adds these in. As such, instead of using the IAMbic <code>included_accounts</code>, <code>excluded_accounts</code>, <code>included_orgs</code>, <code>excluded_orgs</code>, you will want to use:</p> <ol> <li><code>StarfleetIncludeAccounts</code> - This is the exact same schema as <code>IncludeAccounts</code> in the primary template. It works the exact same way an uses the exact same account resolution capabilities.</li> <li><code>StarfleetExcludeAccounts</code> - This is the exact same schema as <code>ExcludeAccounts</code> in the primary template. It works the exact same way an uses the exact same account resolution capabilities.</li> </ol> <p>For example, instead of:</p> <pre><code>   #...\n      - included_accounts:\n          - DevOpsProd\n        policy_name: ArtifactBucket\n        statement:\n          - effect: allow\n            action:\n              - s3:Get*\n              - s3:List*\n              - s3:PutObject\n            resource:\n              - aws:s3:::some-devops-bucket-devopsprod\n              - aws:s3:::some-devops-bucket-devopsprod/*\n  # ...\n</code></pre> <p>You would use: <pre><code>  # ...\n      # This uses the same syntax as other Starfleet templates. Simply swap `included/excluded_accounts` with `StarfleetInclude/ExcludeAccounts`\n      - StarfleetIncludeAccounts:\n          ByNames:\n            - DevOpsProd\n        policy_name: ArtifactBucket\n        statement:\n          - effect: allow\n            action:\n              - s3:Get*\n              - s3:List*\n              - s3:PutObject\n            resource:\n              - aws:s3:::some-devops-bucket-devopsprod\n              - aws:s3:::some-devops-bucket-devopsprod/*\n  # ...\n</code></pre></p>"},{"location":"userGuide/IAM/Roles/Template/#unsupported-and-forbidden-fields","title":"Unsupported and Forbidden Fields","text":"<p>Because Starfleet is wrapping IAMbic, Starfleet is deciding which fields are allowed (or not allowed) to appear in the IAMbic template. The following are the fields that you cannot use:</p> <pre><code>- included_accounts  # Use StarfleetIncludeAccounts\n- excluded_accounts  # Use StarfleetExcludeAccounts\n- included_orgs  # Use StarfleetIncludeAccounts\n- excluded_orgs  # Use StarfleetExcludeAccounts\n- iambic_managed  # This is managed by Starfleet\n</code></pre> <p>If you have an IAMbic template, you'll need to strip out and/or swap (<code>include/exclude</code>) with the proper values.</p> <p>Also, at this time, Starfleet does not support the vanilla <code>expires_at</code> field. We have an open issue to address this in the future.</p>"},{"location":"userGuide/IAM/Roles/Template/#some-examples","title":"Some Examples","text":"<p>Here is an example of an IAM role that should be deployed in each and every account, including the organization management account:</p> <pre><code>TemplateName: DeployEverywhere\nTemplateDescription: This is a sample role that is in all the accounts\nIncludeAccounts:\n  AllAccounts: True\nOperateInOrgRoot: True\nIambicVariables:\n  - Key: some_key\n    Value: some_value\nIambicRoleTemplate:\n  properties:\n    role_name: deploy_everywhere\n    description: A sample role that will be rolled out to {{ var.account_name }} with {{ var.some_key }} set\n    assume_role_policy_document:\n      statement:\n        - action: sts:AssumeRole\n          effect: Allow\n          principal:\n            aws: arn:aws:iam::000000000000:role/some-imaginary-role\n      version: '2012-10-17'\n    managed_policies:\n      - policy_arn: arn:aws:iam::aws:policy/IAMReadOnlyAccess  # Grant read-only access to IAM\n</code></pre> <p>Here is that same example above, but this time, we will exclude the <code>IAMReadOnlyAccess</code> managed policy in the <code>DevOpsProd</code> account: <pre><code>TemplateName: DeployEverywhere\nTemplateDescription: This is a sample role that is in all the accounts\nIncludeAccounts:\n  AllAccounts: True\nOperateInOrgRoot: True\nIambicVariables:\n  - Key: some_key\n    Value: some_value\nIambicRoleTemplate:\n  properties:\n    role_name: deploy_everywhere\n    description: A sample role that will be rolled out to {{ var.account_name }} with {{ var.some_key }} set\n    assume_role_policy_document:\n      statement:\n        - action: sts:AssumeRole\n          effect: Allow\n          principal:\n            aws: arn:aws:iam::000000000000:role/some-imaginary-role\n      version: '2012-10-17'\n    managed_policies:\n      - StarfleetExcludeAccounts:\n          ByNames:\n            - DevOpsProd\n        policy_arn: arn:aws:iam::aws:policy/IAMReadOnlyAccess  # Grant read-only access to IAM for all accounts except DevOpsProd\n</code></pre></p> <p>Here is that same example above, but this time, we are going to include the ability to create S3 buckets in the <code>DevOps</code> organization unit: <pre><code>TemplateName: DeployEverywhere\nTemplateDescription: This is a sample role that is in all the accounts\nIncludeAccounts:\n  AllAccounts: True\nOperateInOrgRoot: True\nIambicVariables:\n  - Key: some_key\n    Value: some_value\nIambicRoleTemplate:\n  properties:\n    role_name: deploy_everywhere\n    description: A sample role that will be rolled out to {{ var.account_name }} with {{ var.some_key }} set\n    assume_role_policy_document:\n      statement:\n        - action: sts:AssumeRole\n          effect: Allow\n          principal:\n            aws: arn:aws:iam::000000000000:role/some-imaginary-role\n      version: '2012-10-17'\n    managed_policies:\n      - StarfleetExcludeAccounts:\n          ByNames:\n            - DevOpsProd\n        policy_arn: arn:aws:iam::aws:policy/IAMReadOnlyAccess  # Grant read-only access to IAM for all accounts except DevOpsProd\n    inline_policies:\n      - StarfleetIncludeAccounts:  # Only allow S3 bucket creation in the DevOps organization unit\n          ByOrgUnits:\n            - DevOps\n        policy_name: CreateBuckets\n        statement:\n          - effect: allow\n            action: s3:CreateBucket\n            resource: '*'\n</code></pre></p>"},{"location":"userGuide/awsConfig/AWSConfigWorker/","title":"AWS Config Worker Ship User Guide","text":"<p>This is the main user guide for the AWS Config worker ship. This page documents all that there is to know about this worker ship.</p> <p>Schema Change June 2023</p> <p>The initial schema for this worker was changed in June 2023 to introduce support for AWS Config's resource exclusion feature in the recorders. See the Payload Templates section for details on what the current schema is.</p>"},{"location":"userGuide/awsConfig/AWSConfigWorker/#what-does-it-do","title":"What does it do?","text":"<p>This is a very important worker ship as it allows you to easily enable AWS Config to all accounts and regions in your infrastructure. AWS Config will also be used with other workers to act as a cache of AWS resources. This is done to avoid API rate limiting when describing resources.</p>"},{"location":"userGuide/awsConfig/AWSConfigWorker/#why-did-we-make-this","title":"Why did we make this?","text":"<p>AWS Config is a very important visibility tool in AWS. It is also a very effective cache of resource state that can be queried without causing rate limits for the respective services. However, AWS Config recorder enablement is not simple to do without this tool. AWS Organizations lacks the ability to enable AWS Config recorders across your environment, and more importantly, you will likely need the ability to customize how AWS Config is configured throughout your accounts and regions. Being able to customize how AWS Config is enabled across your infrastructure is highly desireable. This is because AWS Config bills you for each configuration change that is recorded. If you have an AWS account and region with a lot of changes being made to a given resource type, then you may incur a lot of charges for those resources being recorded. In such a case, you may still want to enable it for the resource types that don't frequently change so you can still have reasonable configuration history coverage. With this worker, you can have it all, as you can define in one place how AWS Config should be configured, and you can specify account/region specific overrides. Starfleet will task the workers accordingly to implement the changes throughout very quickly. This will also do both, detect and correct any drift that appears with AWS Config recorders.</p>"},{"location":"userGuide/awsConfig/AWSConfigWorker/#what-does-it-not-do","title":"What does it NOT do?","text":"<p>It's important that we discuss what this does not do, and that is the aggregator setup. That is not performed by this worker, because AWS Organizations does this for you exceptionally well. We strongly recommend that you follow the instructions here to set up AWS Config aggregators for your entire Organization.</p>"},{"location":"userGuide/awsConfig/AWSConfigWorker/#how-it-works","title":"How it works","text":"<p>The AWS Config worker is an <code>ACCOUNT_REGION</code> worker, that is to say that it schedules a task for every account and region that the payload template outlines. This will go out and verify that:</p> <ol> <li>The AWS Config Recorder is configured to the template's spec</li> <li>The Delivery Channel is configured to the template's spec</li> <li>The Retention Configuration is configured to the template's spec</li> <li>The Recorder is either On or Off based on the template's spec</li> </ol> <p>This worker ship plugin can be invoked on any EventBridge timed event and/or by updating the S3 template. We recommend that at a minimum, you run this once daily. As mentioned above, we do not set up aggregators because AWS Organizations does this very nicely for you. See the documentation above for more details on how to set that up.</p> <p>The next sections describe how to configure, set up, and use this worker ship plugin.</p>"},{"location":"userGuide/awsConfig/AWSConfigWorker/#alerting","title":"Alerting","text":"<p>The Config worker supports alerts to Slack. It will alert on any errors that are encountered during execution. It will also emit <code>SUCCESS</code> notices if it makes a change to the AWS Config configuration.</p>"},{"location":"userGuide/awsConfig/CLI/","title":"AWS Config Worker CLI","text":"<p>The AWS Config worker has just 1 CLI command (<code>sync</code>), which syncs the AWS Config template to the given AWS Account ID and region in question.</p> <p>Below is the CLI options:</p> <pre><code>Usage: starfleet aws-config sync [OPTIONS]\n\n  This will sync the AWS Config payload in the desired account and region.\n\nOptions:\n  --payload FILENAME  This is the worker payload YAML  [required]\n  --account-id TEXT   The AWS account ID to operate in  [required]\n  --region TEXT       The AWS region to operate in  [required]\n  --commit            Must be supplied for changes to be made\n  --help              Show this message and exit.\n</code></pre>"},{"location":"userGuide/awsConfig/CLI/#the-aws-config-sync-command","title":"The <code>aws-config sync</code> command","text":"<p>Running the sync command requires that you have the required Starfleet AWS credentials exported in the environment. Here is an example of how to run it in commit mode on account ID <code>111111111111</code> in <code>us-east-1</code>:</p> <pre><code>starfleet aws-config sync --payload some/path/to/the/payload.yaml --account-id 111111111111 --region us-east-1 --commit\n</code></pre>"},{"location":"userGuide/awsConfig/Installation/","title":"Installing &amp; Configuring the AWS Config Worker","text":"<p>Installing the Config worker requires the following components:</p> <ol> <li>The AWS Config requirements:<ul> <li>An IAM role in every AWS account that AWS Config needs to use for describing all your resources. This is not used by Starfleet, this is used by AWS Config itself.</li> <li>An S3 bucket to hold your AWS Config details</li> </ul> </li> <li>The Starfleet worker role with permissions to make changes to AWS Config in all your accounts</li> <li>Update to the AWS SAM template to include all the additional components to deploy the worker</li> <li>Updated configuration</li> <li>Payload templates</li> </ol>"},{"location":"userGuide/awsConfig/Installation/#aws-config-requirements","title":"AWS Config Requirements","text":"<p>You will need to perform some work that is required for AWS Config to be set up properly to function. You will need the AWS Config role set up everywhere, and also set up an S3 bucket to hold the Config data.</p>"},{"location":"userGuide/awsConfig/Installation/#the-aws-config-role","title":"The AWS Config Role","text":"<p>AWS Config needs to be able to assume an IAM role in your accounts that permit it to describe resources. This role needs to be resident in all accounts, and the role itself is quite simple. This role needs both access to the S3 bucket that holds all the AWS Config details, and permissions to describe the resources that AWS Config monitors. Below is a sample CloudFormation template syntax for this role:</p> <pre><code>AWSConfigRole:\n  Type: AWS::IAM::Role\n  Properties:\n    AssumeRolePolicyDocument:\n      Version: '2012-10-17'\n      Statement:\n        - Effect: Allow\n          Principal:\n            Service: config.amazonaws.com\n          Action: sts:AssumeRole\n          Condition:\n            StringEquals:\n              AWS:SourceAccount: !Ref 'AWS::AccountId'\n    Description: Account-resident role for AWS Config\n    RoleName: AWSConfigRole  # Feel free to name this whatever you want\n    Policies:\n      - Version: '2012-10-17'\n        Statement:\n          - Effect: Allow\n            Action:\n              - s3:GetBucket*\n              - s3:ListBucket*\n              - s3:PutObject*\n            Resource:\n              - arn:aws:s3:::YOUR-CONFIG-BUCKET-HERE\n              - arn:aws:s3:::YOUR-CONFIG-BUCKET-HERE/*\n    ManagedPolicyArns:\n      - arn:aws:iam::aws:policy/service-role/AWS_ConfigRole  # Required - this gives AWS Config all the permissions required\n</code></pre> <p>We recommend creating this as part of a CloudFormation StackSet applied to all accounts in your org (place this in the same template as the Starfleet account resident roles). You will want to have this created in all newly-created accounts in your organization as well. This role leverages the <code>arn:aws:iam::aws:policy/service-role/AWS_ConfigRole</code> managed policy to grant AWS Config the required permissions to describe all the resources that it monitors. Feel free to make changes to this as you see fit should you want or need to.</p> <p>The Root Account</p> <p>Unfortunately, because StackSets doesn't support your organization root account, you either have to make this role in that account, or make a separate CloudFormation stack based on the template above in that account.</p> <p>KMS</p> <p>If you choose to use KMS (we don't recommend using KMS for this purpose; it provides zero security value for this use case), then you will need to make sure that the AWS Config IAM role also has access to the KMS key that is used for encrypting the S3 bucket. We strongly recommend using SSE-S3 instead of KMS for AWS Config.</p>"},{"location":"userGuide/awsConfig/Installation/#the-config-s3-bucket","title":"The Config S3 Bucket","text":"<p>You will want to follow the AWS Config documentation for setting up an S3 bucket to hold your AWS Config details. This S3 bucket should reside in a security sensitive account and will need to permit AWS Config to access it. The AWS documentation here is a good starting point, however, you will want to make your S3 bucket accessible by your organization.</p> <p>This is a suggested S3 bucket policy: <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"AWSConfigBucketChecks\",\n            \"Effect\": \"Allow\",\n            \"Principal\": \"*\",\n            \"Action\": [\"s3:GetBucketAcl\", \"s3:ListBucket\"],\n            \"Resource\": \"arn:aws:s3:::YOUR-BUCKET-HERE\",\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"aws:PrincipalOrgID\": \"YOUR-ORG-ID\"\n                },\n                \"ArnLike\": {\n                    \"aws:PrincipalArn\": [\n                        \"arn:aws:iam::*:role/YOUR-CONFIG-ROLE-ABOVE\"\n                    ]\n                }\n            }\n        },\n        {\n            \"Sid\": \"AWSConfigBucketDelivery\",\n            \"Effect\": \"Allow\",\n            \"Principal\": \"*\",\n            \"Action\": [\"s3:PutObject\", \"s3:PutObjectAcl\"],\n            \"Resource\": \"arn:aws:s3:::YOUR-BUCKET-HERE/*\",\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"s3:x-amz-acl\": \"bucket-owner-full-control\",\n                    \"aws:PrincipalOrgID\": \"YOUR-ORG-ID\"\n                },\n                \"ArnLike\": {\n                    \"aws:PrincipalArn\": [\n                        \"arn:aws:iam::*:role/YOUR-CONFIG-ROLE-ABOVE\"\n                    ]\n                }\n            }\n        }\n    ]\n}\n</code></pre></p>"},{"location":"userGuide/awsConfig/Installation/#update-the-starfleet-account-resident-roles","title":"Update the Starfleet Account-Resident Roles","text":"<p>In the installation guide, we discussed the creation of the Starfleet account resident roles that the workers will assume to perform their tasks. You will need to update these roles with AWS Config permissions. We are going to assume that for Test accounts, you will want read-only permissions, and for Prod accounts, you will want read/write permissions:</p>"},{"location":"userGuide/awsConfig/Installation/#test-role-read-only","title":"Test Role - Read Only","text":"<p>Add the following to the <code>starfleet-worker-basic-test-role</code> permissions:</p> <pre><code>Policies:\n  # ...\n  - PolicyName: config\n    PolicyDocument:\n      Version: '2012-10-17'\n      Statement:\n        - Sid: ReadOnly\n          Effect: Allow\n          Action:\n            - config:Describe*\n            - config:Get*\n            - config:List*\n          Resource: '*'\n    # ...\n</code></pre>"},{"location":"userGuide/awsConfig/Installation/#prod-role-readwrite","title":"Prod Role - Read/Write","text":"<p>Add the following to the <code>starfleet-worker-basic-prod-role</code> permissions:</p> <pre><code>Policies:\n  # ...\n  - PolicyName: config\n    PolicyDocument:\n      Version: '2012-10-17'\n      Statement:\n        - Sid: ReadWrite\n          Effect: Allow\n          Action: config:*\n          Resource: '*'\n  - PolicyName: IAM\n    PolicyDocument:\n      Version: '2012-10-17'\n        - Sid: PassRole\n          Effect: Allow\n          Action: iam:PassRole\n          Resource:\n            - arn:aws:iam::*:role/AWSConfigRole  # The name of your Config role above\n</code></pre> <p>For production, you will need the <code>iam:PassRole</code> permissions since the worker will be informing Config on which IAM role to make use of.</p>"},{"location":"userGuide/awsConfig/Installation/#aws-sam-template","title":"AWS SAM Template","text":"<p>For the AWS SAM template, you will need to add in this worker's components to it. The templates for testing and production are mostly the same. The only difference is that for production, we operate off of a larger batch size to reduce costs, increase the RAM amount, and have the <code>STARFLEET_COMMIT</code> environment variable set to <code>True</code>.</p> <p>Tip</p> <p>We have included the below SAM details in the <code>test_sam_template.yaml</code> file that is included with this repo. All you need to do is uncomment the sections labeled <code>Uncomment for the AWS Config worker</code> with the details outlined.</p>"},{"location":"userGuide/awsConfig/Installation/#test-template-no-commit","title":"Test Template: No Commit","text":"<p>Here is a sample of what should be in your test template:</p> <pre><code>Resources:\n  # ...\n\n  AWSConfigWorkerDLQ:\n    Type: AWS::SQS::Queue\n    Properties:\n      QueueName: starfleet-aws-config-worker-dlq\n      RedriveAllowPolicy:\n        redrivePermission: allowAll\n\n  AWSConfigWorkerQueue:\n    Type: AWS::SQS::Queue\n    Properties:\n      QueueName: starfleet-aws-config-worker\n      VisibilityTimeout: 300  # This needs to be the same as the Lambda function timeout.\n      RedrivePolicy:\n        deadLetterTargetArn: !GetAtt AWSConfigWorkerDLQ.Arn\n        maxReceiveCount: 4\n\n  AWSConfigWorker:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: ./src\n      Handler: starfleet.worker_ships.plugins.aws_config.ship.lambda_handler\n      Runtime: python3.10\n      Architectures:\n        - arm64\n      MemorySize: 128\n      Events:\n        SQSEvent:\n          Type: SQS\n          Properties:\n            Queue: !GetAtt AWSConfigWorkerQueue.Arn\n            BatchSize: 2\n      Environment:\n        Variables:\n          STARFLEET_COMMIT: False\n      Policies:\n        # Grant permissions to read from the inventory S3 bucket:\n        - S3ReadPolicy:\n            BucketName: !FindInMap\n              - EnvMap\n              - !Ref 'EnvironmentName'\n              - AccountInventoryBucket\n\n# ...\n  AssumeRoleManagedPolicy:\n    # ...\n      Roles:\n        - !Ref AccountIndexGeneratorRole  # AccountIndexGeneratorRole is created automatically by SAM and can be referenced\n        - !Ref AWSConfigWorkerRole  # AWSConfigWorkerRole is created automatically by SAM and can be referenced\n\n# ...\nOutputs:\n  # ...\n  AWSConfigWorkerQueue:\n    Description: The Queue URL for the AWS Config Worker invocation queue\n    Value: !GetAtt AWSConfigWorkerQueue.QueueUrl\n  AWSConfigWorkerDLQ:\n    Description: The Queue URL for the AWS Config Worker invocation DLQ\n    Value: !GetAtt AWSConfigWorkerDLQ.QueueUrl\n  AWSConfigWorker:\n    Description: The AWS Config Worker ship function that enables AWS Config everywhere\n    Value: !GetAtt AWSConfigWorker.Arn\n</code></pre>"},{"location":"userGuide/awsConfig/Installation/#prod-template-commit","title":"Prod Template: Commit","text":"<p>Here is a sample of what should be in your prod template:</p> <pre><code>Resources:\n\n  # ...\n  AWSConfigWorkerDLQ:\n    Type: AWS::SQS::Queue\n    Properties:\n      QueueName: starfleet-aws-config-worker-dlq\n      RedriveAllowPolicy:\n        redrivePermission: allowAll\n\n  AWSConfigWorkerQueue:\n    Type: AWS::SQS::Queue\n    Properties:\n      QueueName: starfleet-aws-config-worker\n      VisibilityTimeout: 300  # This needs to be the same as the Lambda function timeout.\n      RedrivePolicy:\n        deadLetterTargetArn: !GetAtt StarbaseFanoutDLQ.Arn\n        maxReceiveCount: 4\n\n  AWSConfigWorker:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: ./starfleet/src\n      Handler: starfleet.worker_ships.plugins.aws_config.ship.lambda_handler\n      Runtime: python3.10\n      Architectures:\n        - arm64\n      MemorySize: 256\n      Events:\n        SQSEvent:\n          Type: SQS\n          Properties:\n            Queue: !GetAtt AWSConfigWorkerQueue.Arn\n            BatchSize: 4\n      Environment:\n        Variables:\n          STARFLEET_COMMIT: True\n      Policies:\n        # Grant permissions to read from the inventory S3 bucket:\n        - S3ReadPolicy:\n            BucketName: !FindInMap\n              - EnvMap\n              - !Ref 'EnvironmentName'\n              - AccountInventoryBucket\n\n# ...\n  AssumeRoleManagedPolicy:\n    # ...\n      Roles:\n        - !Ref AccountIndexGeneratorRole  # AccountIndexGeneratorRole is created automatically by SAM and can be referenced\n        - !Ref AWSConfigWorkerRole  # AWSConfigWorkerRole is created automatically by SAM and can be referenced\n\n# ...\nOutputs:\n  # ...\n  AWSConfigWorkerQueue:\n    Description: The Queue URL for the AWS Config Worker invocation queue\n    Value: !GetAtt AWSConfigWorkerQueue.QueueUrl\n  AWSConfigWorkerDLQ:\n    Description: The Queue URL for the AWS Config Worker invocation DLQ\n    Value: !GetAtt AWSConfigWorkerDLQ.QueueUrl\n  AWSConfigWorker:\n    Description: The AWS Config Worker ship function that enables AWS Config everywhere\n    Value: !GetAtt AWSConfigWorker.Arn\n</code></pre>"},{"location":"userGuide/awsConfig/Installation/#the-configuration","title":"The Configuration","text":"<p>The last part of the installation process is to make sure that we have the correct configuration in place. Here is what that would generally look like:</p> <pre><code>AwsConfigWorkerShip:\n  Enabled: True\n  TemplatePrefix: AwsConfigWorkerShip/\n  InvocationQueueUrl: https://sqs.YOUR-REGION.amazonaws.com/YOUR-ACCOUNT-ID/starfleet-aws-config-worker\n  InvocationSources:\n    - EVENTBRIDGE_TIMED_EVENT\n    - S3\n  EventBridgeTimedFrequency: SIX_HOURLY  # Feel free to alter this\n  WorkerRoleToAssume: starfleet-worker-basic-test-role  # for test -- in PROD, make this starfleet-worker-basic-prod-role\n</code></pre> <p>There are 2 fields in the configuration that is defined for this worker:</p> <ol> <li><code>WorkerRoleToAssume</code> - This is the IAM role that the AWS Config Worker needs to assume in all AWS accounts to perform it's job function. If you follow the instructions, this will be <code>starfleet-worker-basic-test|prod-role</code> depending on if this is the Test or Prod deployment.</li> <li><code>WorkerRoleSessionName</code> - optional - this is an optional string for what the assume role session name would be. By default this is <code>StarfleetAwsConfigWorkerShip</code>.</li> </ol> <p>Once you have all the components all set, you will want to use the SAM CLI to build and deploy everything.</p>"},{"location":"userGuide/awsConfig/Template/","title":"AWS Config Worker Templates","text":"<p>In this section, we discuss the AWS Config worker templates. The Config Worker is an <code>ACCOUNT_REGION</code> worker, and thus relies on the base account/region template components that is discussed here. In addition to the base account/region details, there are some unique fields defined below:</p>"},{"location":"userGuide/awsConfig/Template/#template-schema","title":"Template Schema","text":"<p>The only required field is a very important one and that is the <code>DefaultConfiguration</code> section. Below is a sample template where this is defined:</p> <p>Schema Change June 2023</p> <p>The initial schema for this worker was changed in June 2023 to introduce support for AWS Config's resource exclusion feature in the recorders. The original schema is no longer functional. The main change is in the <code>RecordingGroup</code> section, which is defined in detail below.</p> <p>Below is the most realistic example. We are not going to record EC2 instances anywhere because in this sample environment, they change too much and are too costly to have recorded. Thus, by default, we are recording all resources except EC2 instances and global resources like IAM. For IAM and other global resources, we only want to record them in us-east-1 to avoid duplicate resource recording and the associated costs with that.</p> <pre><code>TemplateName: AWSConfigEnablement\nTemplateDescription: Enabling AWS Config\nIncludeAccounts:\n    AllAccounts: True\nOperateInOrgRoot: True\nIncludeRegions:\n    - ALL\nDefaultConfiguration:\n    DeliveryChannelDetails:\n        BucketName: your-s3-bucket-here\n        S3DeliveryFrequency: Twelve_Hours\n    RecorderConfiguration:\n        ConfigRoleName: AWSConfigRole\n        RecordingEnabled: True\n        RecordingGroup:\n            RecordEverythingExcept:\n                - AWS::EC2::Instance\n                - AWS::IAM::Role    # Record IAM in us-east-1 only -- see below\n                - AWS::IAM::Group\n                - AWS::IAM::User\n    RetentionPeriodInDays: 2557\nAccountOverrideConfigurations:\n    -\n        IncludeAccounts:\n            AllAccounts: True\n        IncludeRegions:\n            - us-east-1\n        DeliveryChannelDetails:\n            BucketName: your-s3-bucket-here\n            S3DeliveryFrequency: Twelve_Hours\n        RecorderConfiguration:\n            ConfigRoleName: AWSConfigRole\n            RecordingEnabled: True\n            RecordingGroup:\n                RecordEverythingExcept:  # IAM will only be in us-east-1 to avoid recording global resources as they would be duplicated and increase recording cost\n                    - AWS::EC2::Instance\n        RetentionPeriodInDays: 2557\n</code></pre> <p>The <code>DefaultConfiguration</code> defines how AWS Config should be configured by default. That is to say, how it should be configured for all non-excluded (and not overridden -- see next section) <code>IncludeAccounts</code> and <code>IncludeRegions</code> that the worker is tasked for. This outlines how we need to configure each component.</p> <p>There are 3 major components of the <code>DefaultConfiguration</code>. Each section is then defined in more detail below with examples.</p> <ol> <li><code>RecorderConfiguration</code> - This defines how the in-account/region AWS Config recorder is configured. This specifies whether the recorder is enabled, and which resource types to record for, to name a few.</li> <li><code>DeliveryChannelDetails</code> - This defines the delivery channel. This is where you set the S3 bucket properties (and optionally SNS topic details).</li> <li><code>RetentionPeriodInDays</code> - This defines how long AWS config should retain configuration change data. The maximum value is 7 years including leap days (2557 days). We require this to be set. The minimum value is 30 days.</li> </ol>"},{"location":"userGuide/awsConfig/Template/#recorderconfiguration","title":"<code>RecorderConfiguration</code>","text":"<p>The <code>RecorderConfiguration</code> section has the following fields (if not specified as optional, it's required):</p> <ol> <li><code>ConfigRoleName</code> - This is the name of the IAM role that AWS Config will use to describe resources in your account. If you followed the instructions on the previous page, this would be <code>AWSConfigRole</code>.</li> <li><code>RecordingEnabled</code> - Boolean that indicates if the recorder should be enabled or not</li> <li><code>RecordingGroup</code> - Dictionary that defines the <code>RecordingGroup</code> section.</li> <li><code>PreferredName</code> - optional - This is a preferred name that you want to have set for the Config recorder. By default, this is set to <code>default</code>. Note: Starfleet cannot rename an existing named recorder. Starfleet will use whatever existing recorder is present and update it to conform to the spec. More details on this is below.</li> </ol> <p>The <code>RecordingGroup</code> is defined as:</p> <ol> <li><code>RecordEverything</code> - This is used if you want to record ALL AWS Config supported resources, including any new ones that get introduced. This is a dictionary - see more below.</li> <li><code>RecordSpecificResources</code> - This is an enumerated list of AWS resources that you want to record</li> <li><code>RecordEverythingExcept</code> - This is an enumerated list of AWS resources that you don't want to record. All other resource types are recorded including any new ones that AWS Config supports in the future.</li> </ol>"},{"location":"userGuide/awsConfig/Template/#the-recordinggroup-details","title":"The <code>RecordingGroup</code> details","text":"<p>The <code>RecordingGroup</code> allows you to specify which resources to record (or not record). There are 3 possible values (stated above: <code>RecordEverything</code>, <code>RecordSpecificResources</code>, or <code>RecordEverythingExcept</code>) that this can have. You can only define 1 of these.</p>"},{"location":"userGuide/awsConfig/Template/#recommended-record-all-resources-except-for-specific-resources","title":"RECOMMENDED: Record all resources except for specific resources","text":"<p>If you want to record all resources except for specific resources, then the schema for that looks like this:</p> <pre><code>RecordingGroup:\n    RecordEverythingExcept:\n        - AWS::EC2::Instance\n        - AWS::EC2::Volume\n        - AWS::EC2::NetworkInterface\n</code></pre> <p>We recommend this approach since it will record all resources except for the ones you specify. This is useful to avoid recording resources that change a lot, since that can jack up your AWS Config bill. This allows you to record all the resources that don't excessively change a lot in your environment, which gives you the benefit of being able to track changes for the majority of your resources while keeping your bill in check. In the example above, we will record all resources except for EC2 Instances, EBS Volumes, and ENIs.</p> <p>We would also recommend having an override region where you do track the globals in.</p>"},{"location":"userGuide/awsConfig/Template/#record-specific-resources","title":"Record specific resources","text":"<p>If you want to record specific resources, then the schema for that looks like this:</p> <pre><code>RecordingGroup:\n    RecordSpecificResources:\n        - AWS::IAM::Role\n        - AWS::IAM::Group\n        - AWS::S3::Bucket\n</code></pre> <p>In this example, this will record only the resources specified, which in this case, are IAM Roles, IAM Groups, and S3 Buckets.</p>"},{"location":"userGuide/awsConfig/Template/#record-all-aws-config-supported-resources","title":"Record ALL AWS Config supported resources","text":"<p>If you want to record ALL resources, then the schema for that looks like this:</p> <pre><code>RecordingGroup:\n    RecordEverything:\n        RecordGlobalsInTheseRegions:\n            - us-east-1\n</code></pre> <p>Under <code>RecordEverything</code> there is list called <code>RecordGlobalsInTheseRegions</code>. This is a list of regions that you want to record global resources in. There are 3 possible values for this:</p> <ol> <li><code>- ALL</code> - If you want to record global resource types in all regions, then you can set this list to one item with the value of <code>- ALL</code>. This is not recommended since it will duplicate the recorded global resources in all the regions. This can result in a higher AWS Config bill.</li> <li><code>- NONE</code> - If you do not want to record global resource types in any region, then you can set this list to one item with the value of <code>- NONE</code>. This is not recommended since you will definitely want to record things like IAM, which is global.</li> <li>A list of regions - If you want to record global resource types in a specific region, then you can set this list to any number of supported AWS Config regions.</li> </ol> <p>Examples for all resources:</p> <p>Record all resources including global resources in all regions: <pre><code>RecordingGroup:\n    RecordEverything:\n        RecordGlobalsInTheseRegions:\n            - ALL\n</code></pre></p> <p>All resources except for global resources (i.e. don't record global resources anywhere): <pre><code>RecordingGroup:\n    RecordEverything:\n        RecordGlobalsInTheseRegions:\n            - NONE\n</code></pre></p> <p>All resources, but only record global resources in <code>us-east-1</code> and <code>us-west-2</code>: <pre><code>RecordingGroup:\n    RecordEverything:\n        RecordGlobalsInTheseRegions:\n            - us-east-1\n            - us-west-2\n</code></pre></p>"},{"location":"userGuide/awsConfig/Template/#deliverychanneldetails","title":"<code>DeliveryChannelDetails</code>","text":"<p>The <code>DeliveryChannelDetails</code> section defines how the delivery channel should be configured. The following fields are present (if not specified as optional, it's required):</p> <ol> <li><code>BucketName</code> - This is the name of the S3 bucket that AWS Config needs to have configured. This was discussed on the previous page.</li> <li><code>S3DeliveryFrequency</code> - An enumerated string for the frequency of when AWS Config should deliver data to the S3 bucket. The following are the valid values:   <pre><code>One_Hour\nThree_Hours\nSix_Hours\nTwelve_Hours\nTwentyFour_Hours\n</code></pre></li> <li><code>PreferredName</code> - optional - This is a preferred name that you want to have set for the Delivery Channel. By default, this is set to <code>default</code>. Note: Starfleet cannot rename an existing named delivery channel. Starfleet will use whatever existing delivery channel is present and update it to conform to the spec. More details on this is below.</li> <li><code>BucketKeyPrefix</code> - optional - This is the optional prefix in the S3 bucket that AWS Config should dump the data under. By default this is not set and is placed where AWS Config would by default place it. See the AWS Config documentation for where that is.</li> <li><code>S3KmsKeyArn</code> - maybe optional - If you are using KMS with S3 to encrypt your S3 data, then you need to specify the KMS Key ARN here. This is REQUIRED if you use KMS with S3, otherwise this should not be set.</li> <li><code>SnsTopicArn</code> - optional - This is the optional SNS topic to send notifications to whenever configuration changes are recorded. If you don't want to use this, then don't set this. See the AWS documentation for details on how this works and what it does.</li> </ol>"},{"location":"userGuide/awsConfig/Template/#retentionconfigindays","title":"<code>RetentionConfigInDays</code>","text":"<p>This is documented above. Basically, this is how long (in days) that AWS Config should retain configuration history. The maximum value is 2557 days, the minimum is 30. This field is required.</p>"},{"location":"userGuide/awsConfig/Template/#overriding-account-defaults","title":"Overriding Account Defaults","text":"<p>We provide you the ability to provide Account/Region level overrides. This is useful if you need to opt-out or opt-in resource level configurations for a given set of accounts. This is set via the OPTIONAL <code>AccountOverrideConfigurations</code> field. The <code>AccountOverrideConfigurations</code> is a list of all the items in the <code>DefaultConfiguration</code> schema but also has the ability to specify the account and region to run in.</p> <p>Here is an example of what a full template with this would look like:</p> <pre><code>TemplateName: AWSConfigEnablement\nTemplateDescription: Enabling AWS Config\nIncludeAccounts:\n    AllAccounts: True\nOperateInOrgRoot: True\nIncludeRegions:\n    - ALL\nDefaultConfiguration:\n    DeliveryChannelDetails:\n        BucketName: your-s3-bucket-here\n        S3DeliveryFrequency: Twelve_Hours\n    RecorderConfiguration:\n        ConfigRoleName: AWSConfigRole\n        RecordingEnabled: True\n        RecordingGroup:\n            RecordEverything:\n                RecordGlobalsInTheseRegions:\n                    - us-east-1\n    RetentionPeriodInDays: 2557\nAccountOverrideConfigurations:\n    -\n        IncludeAccounts:\n            ByNames:\n                - 'Account One'\n        IncludeRegions:\n            - us-west-2\n        DeliveryChannelDetails:\n            BucketName: some-other-bucket\n            BucketKeyPrefix: some/prefix/\n            S3DeliveryFrequency: TwentyFour_Hours\n            S3KmsKeyArn: arn:aws:kms:us-west-1:000000000001:key/1234-1445-1919232\n            SnsTopicArn: arn:aws:sns:us-west-1:000000000001:topic/sometopic\n            PreferredName: overridden\n        RecorderConfiguration:\n            PreferredName: overridden\n            ConfigRoleName: SomeOtherRole\n            RecordingEnabled: True\n            RecordingGroup:\n                RecordSpecificResources:\n                    - AWS::S3::Bucket\n                    - AWS::EC2::SecurityGroup\n        RetentionPeriodInDays: 30\n</code></pre> <p>With the above template, when running in <code>Account One</code>/us-west-2 it will not use the <code>DefaultConfiguration</code>, it will instead use the overridden configuration. Here are the additional fields for account and regional specificity:</p> <ol> <li><code>IncludeAccounts</code> - Required - the accounts to override</li> <li><code>IncludeRegions</code> - Required - the regions to override</li> <li><code>ExcludeAccounts</code> - optional - The accounts to explicitly not apply the override to</li> <li><code>ExcludeRegions</code> - optional - The regions to explicitly not apply the override to</li> </ol> <p>This is the same exact schema component that is used for the <code>ACCOUNT_REGION</code> worker base template as documented here. Everything else about this is the same as for the <code>DefaultConfiguration</code>.</p> <p>Overlapping</p> <p>The worker will check for overlapping Account/Region overrides. If one is located then it will raise an error and fail to apply the template.</p> <p>If no overrides are found for an account/region pair, then the <code>DefaultConfiguration</code> is applied.</p>"},{"location":"userGuide/awsConfig/Template/#special-details","title":"Special Details","text":"<p>This section outlines some special details regarding the worker's behavior.</p> <ol> <li>As mentioned above, <code>PreferredName</code> is a field that will opportunistically set a name for a recorder or delivery channel if the field is set, and there isn't already a recorder or delivery channel present. AWS Config does not allow you to update this field. To update the field, you need to delete the recorder or delivery channel and re-create it. Starfleet will not delete the recorder or delivery channel, and instead will find the one that is there and update it to conform to the rest of the spec.</li> <li>A quick note is that when thinking about how this template is applied, you should think of it as the main template's <code>Include/Exclude</code> mostly applies to the <code>DefaultConfiguration</code>. Overrides are there to provide exceptions in specific accounts/regions under the main <code>Include*</code>. You can always create multiple templates and store them in the template S3 bucket path (default path is <code>AwsConfigWorker/</code>), however, we would recommend that you use just 1 template so everything is in one place.</li> </ol>"},{"location":"userGuide/awsConfig/Template/#some-examples","title":"Some examples","text":"<p>The most realistic example is at the top. This section shows other examples you may or may not care about.</p> <p>This is an example template that will enable AWS Config to all accounts and regions, including the Organization root, for all regions, for all resource types. Global resources will only be recorded in us-east-1:</p> <pre><code>TemplateName: AWSConfigEnablement\nTemplateDescription: Enabling AWS Config\nIncludeAccounts:\n    AllAccounts: True\nOperateInOrgRoot: True\nIncludeRegions:\n    - ALL\nDefaultConfiguration:\n    DeliveryChannelDetails:\n        BucketName: your-s3-bucket-here\n        S3DeliveryFrequency: Twelve_Hours\n    RecorderConfiguration:\n        ConfigRoleName: AWSConfigRole\n        RecordingEnabled: True\n        RecordingGroup:\n            RecordEverything:\n                RecordGlobalsInTheseRegions:\n                    - us-east-1\n    RetentionPeriodInDays: 2557\n</code></pre> <p>This is an example that will enable AWS Config to all accounts and regions except <code>Account One</code>. In <code>Account Two</code>, only S3 buckets, and security groups will be recorded in regions not us-east-1. In <code>Account Two</code>/us-east-1, it will record S3 buckets, security groups, and IAM roles. For all other account/region pairs, it will record all resources except EC2 instances: <pre><code>TemplateName: AWSConfigEnablement\nTemplateDescription: Enabling AWS Config\nIncludeAccounts:\n    AllAccounts: True\nExcludeAccounts:\n    ByNames:\n        - \"Account One\"\nOperateInOrgRoot: True\nIncludeRegions:\n    - ALL\nDefaultConfiguration:\n    DeliveryChannelDetails:\n        BucketName: your-s3-bucket-here\n        S3DeliveryFrequency: Twelve_Hours\n    RecorderConfiguration:\n        ConfigRoleName: AWSConfigRole\n        RecordingEnabled: True\n        RecordingGroup:\n            RecordEverythingExcept:\n                - AWS::EC2::Instance\n    RetentionPeriodInDays: 2557\nAccountOverrideConfigurations:\n  -\n    IncludeAccounts:\n        ByNames:\n            - \"Account Two\"\n    IncludeRegions:\n        - ALL\n    ExcludeRegions:\n        - us-east-1\n    DeliveryChannelDetails:\n        BucketName: your-s3-bucket-here\n        S3DeliveryFrequency: Twelve_Hours\n    RecorderConfiguration:\n        ConfigRoleName: AWSConfigRole\n        RecordingEnabled: True\n        RecordingGroup:\n            RecordSpecificResources:\n                - AWS::S3::Bucket\n                - AWS::EC2::SecurityGroup\n    RetentionPeriodInDays: 2557\n  -\n    IncludeAccounts:\n        ByNames:\n            - \"Account Two\"\n    IncludeRegions:\n        - us-east-1\n    DeliveryChannelDetails:\n        BucketName: your-s3-bucket-here\n        S3DeliveryFrequency: Twelve_Hours\n    RecorderConfiguration:\n        ConfigRoleName: AWSConfigRole\n        RecordingEnabled: True\n        RecordingGroup:\n            RecordSpecificResources:\n                - AWS::S3::Bucket\n                - AWS::EC2::SecurityGroup\n                - AWS::IAM::Role\n    RetentionPeriodInDays: 2557\n</code></pre></p>"},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/category/general-announcement/","title":"General Announcement","text":""},{"location":"blog/category/workers/","title":"Workers","text":""},{"location":"blog/category/iam/","title":"IAM","text":""},{"location":"blog/category/new-features/","title":"New Features","text":""}]}